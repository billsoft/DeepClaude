"""DeepClaude æœåŠ¡ï¼Œç”¨äºåè°ƒ DeepSeek å’Œ Claude API çš„è°ƒç”¨

ä¸»è¦åŠŸèƒ½ï¼š
1. é›†æˆ DeepSeek å’Œ Claude ä¸¤ä¸ªå¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›
2. æ”¯æŒæµå¼å’Œéæµå¼ä¸¤ç§è¾“å‡ºæ¨¡å¼
3. å®ç° DeepSeek æ¨ç†ç»“æœä½œä¸º Claude è¾“å…¥çš„ä¸²è”è°ƒç”¨
4. æä¾›ç¬¦åˆ OpenAI API æ ¼å¼çš„æ ‡å‡†è¾“å‡º

å·¥ä½œæµç¨‹ï¼š
1. æ¥æ”¶ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯å’Œæ¨¡å‹å‚æ•°
2. è°ƒç”¨ DeepSeek è¿›è¡Œæ¨ç†ï¼Œè·å–æ¨ç†è¿‡ç¨‹
3. å°†æ¨ç†ç»“æœä¼ é€’ç»™ Claude è¿›è¡Œå¤„ç†
4. æ•´åˆè¾“å‡ºç»“æœå¹¶è¿”å›ç»™ç”¨æˆ·

æŠ€æœ¯ç‰¹ç‚¹ï¼š
1. ä½¿ç”¨å¼‚æ­¥ç¼–ç¨‹æé«˜å¹¶å‘æ€§èƒ½
2. é‡‡ç”¨é˜Ÿåˆ—æœºåˆ¶å®ç°æ•°æ®æµè½¬
3. æ”¯æŒæµå¼è¾“å‡ºæå‡ç”¨æˆ·ä½“éªŒ
4. å®Œå–„çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
"""
import json
import time
import tiktoken
import asyncio
import uuid
from typing import AsyncGenerator, Dict, List, Any, Optional, Tuple
from app.utils.logger import logger
from app.clients import DeepSeekClient, ClaudeClient, OllamaR1Client
from app.utils.message_processor import MessageProcessor
import aiohttp
import os
from dotenv import load_dotenv
import re
import sys
import logging
import requests
from datetime import datetime

# æ•°æ®åº“ç›¸å…³å¯¼å…¥
from app.database.db_operations import DatabaseOperations
from app.database.db_utils import add_reasoning_column_if_not_exists

load_dotenv()

class DeepClaude:
    """å¤„ç† DeepSeek å’Œ Claude API çš„æµå¼è¾“å‡ºè¡”æ¥
    
    è¯¥ç±»è´Ÿè´£åè°ƒ DeepSeek å’Œ Claude ä¸¤ä¸ªæ¨¡å‹çš„è°ƒç”¨è¿‡ç¨‹ï¼Œä¸»è¦ç‰¹ç‚¹ï¼š
    1. æ”¯æŒæµå¼å’Œéæµå¼ä¸¤ç§è¾“å‡ºæ¨¡å¼
    2. å®ç° DeepSeek æ¨ç†å’Œ Claude å›ç­”çš„ä¸²è”è°ƒç”¨
    3. æä¾›æ ‡å‡†çš„ OpenAI æ ¼å¼è¾“å‡º
    4. æ”¯æŒå¤šç§ API æä¾›å•†é…ç½®
    
    ä¸»è¦ç»„ä»¶ï¼š
    - DeepSeekå®¢æˆ·ç«¯ï¼šè´Ÿè´£è°ƒç”¨ DeepSeek API è·å–æ¨ç†è¿‡ç¨‹
    - Claudeå®¢æˆ·ç«¯ï¼šè´Ÿè´£è°ƒç”¨ Claude API ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
    - å¼‚æ­¥é˜Ÿåˆ—ï¼šç”¨äºæ•°æ®æµè½¬å’Œä»»åŠ¡åè°ƒ
    - OllamaR1Clientï¼šè´Ÿè´£è°ƒç”¨ OllamaR1 API ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
    - å¼‚æ­¥é˜Ÿåˆ—ï¼šç”¨äºæ•°æ®æµè½¬å’Œä»»åŠ¡åè°ƒ
    
    å·¥ä½œæ¨¡å¼ï¼š
    1. æµå¼æ¨¡å¼ï¼šå®æ—¶è¿”å›æ¨ç†è¿‡ç¨‹å’Œç”Ÿæˆç»“æœ
    2. éæµå¼æ¨¡å¼ï¼šç­‰å¾…å®Œæ•´ç»“æœåä¸€æ¬¡æ€§è¿”å›
    """
    def __init__(self, **kwargs):
        """åˆå§‹åŒ–DeepClaudeæœåŠ¡
        
        Args:
            **kwargs: å…³é”®å­—å‚æ•°
                save_to_db: æ˜¯å¦ä¿å­˜åˆ°æ•°æ®åº“ï¼Œé»˜è®¤ä¸ºFalse
                db_ops: æ•°æ®åº“æ“ä½œå¯¹è±¡ï¼Œä»…åœ¨save_to_dbä¸ºTrueæ—¶ä½¿ç”¨
                clients: å®¢æˆ·ç«¯å¯¹è±¡ï¼Œç”¨äºæ‰‹åŠ¨æŒ‡å®šå®¢æˆ·ç«¯ï¼Œç”¨äºæµ‹è¯•
                enable_enhanced_reasoning: æ˜¯å¦å¯ç”¨å¢å¼ºæ¨ç†ï¼Œé»˜è®¤ä¸ºTrue
                claude_api_key: Claude APIå¯†é’¥
                claude_api_url: Claude API URL
                claude_provider: Claudeæä¾›å•†
                deepseek_api_key: DeepSeek APIå¯†é’¥
                deepseek_api_url: DeepSeek API URL
                deepseek_provider: DeepSeekæä¾›å•†
                ollama_api_url: Ollama API URL
                is_origin_reasoning: æ˜¯å¦ä½¿ç”¨åŸå§‹æ¨ç†æ ¼å¼
        """
        logger.info("åˆå§‹åŒ–DeepClaudeæœåŠ¡...")
        
        # ä¿å­˜ä¼ å…¥çš„é…ç½®å‚æ•°ï¼Œä»¥ä¾¿åœ¨å…¶ä»–æ–¹æ³•ä¸­ä½¿ç”¨
        self.claude_api_key = kwargs.get('claude_api_key', os.getenv('CLAUDE_API_KEY', ''))
        self.claude_api_url = kwargs.get('claude_api_url', os.getenv('CLAUDE_API_URL', 'https://api.anthropic.com/v1/messages'))
        self.claude_provider = kwargs.get('claude_provider', os.getenv('CLAUDE_PROVIDER', 'anthropic'))
        self.ollama_api_url = kwargs.get('ollama_api_url', os.getenv('OLLAMA_API_URL', ''))
        self.is_origin_reasoning = kwargs.get('is_origin_reasoning', os.getenv('IS_ORIGIN_REASONING', 'false').lower() == 'true')
        
        # æ¨ç†å†…å®¹å’Œæ¨¡å¼è®¾ç½®
        self.enable_enhanced_reasoning = kwargs.get('enable_enhanced_reasoning', True)
        self.min_reasoning_chars = 100  # æœ€å°æ¨ç†å­—ç¬¦æ•°é‡
        self.reasoning_modes = ["auto", "chain-of-thought", "zero-shot"]  # æ¨ç†æ¨¡å¼åˆ—è¡¨
        self.saved_reasoning = ""  # ä¿å­˜çš„æ¨ç†å†…å®¹ï¼Œç”¨äºè¯Šæ–­
        self.processor = MessageProcessor()  # æ¶ˆæ¯å¤„ç†å™¨
        
        # å®šä¹‰æ¨ç†æä¾›è€…
        self.reasoning_providers = {
            'deepseek': lambda: DeepSeekClient(
                api_key=kwargs.get('deepseek_api_key', os.getenv('DEEPSEEK_API_KEY', '')),
                api_url=kwargs.get('deepseek_api_url', os.getenv('DEEPSEEK_API_URL', '')),
                provider=os.getenv('DEEPSEEK_PROVIDER', 'deepseek')
            ),
            'siliconflow': lambda: DeepSeekClient(
                api_key=kwargs.get('deepseek_api_key', os.getenv('DEEPSEEK_API_KEY', '')),
                api_url=kwargs.get('deepseek_api_url', os.getenv('DEEPSEEK_API_URL', '')),
                provider='siliconflow'
            ),
            'nvidia': lambda: DeepSeekClient(
                api_key=kwargs.get('deepseek_api_key', os.getenv('DEEPSEEK_API_KEY', '')),
                api_url=kwargs.get('deepseek_api_url', os.getenv('DEEPSEEK_API_URL', '')),
                provider='nvidia'
            ),
            'ollama': lambda: OllamaR1Client(
                api_url=kwargs.get('ollama_api_url', os.getenv('OLLAMA_API_URL', ''))
            )
        }
        
        # æ”¯æŒçš„å·¥å…·åˆ—è¡¨ï¼Œä¸å®é™…æ‰§è¡Œè¿™äº›å·¥å…·ï¼Œåªè¿”å›æ ‡å‡†æ ¼å¼çš„å“åº”
        self.supported_tools = {
            "search": {
                "name": "search",
                "description": "æœç´¢ç½‘ç»œè·å–å®æ—¶ä¿¡æ¯",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "query": {
                            "type": "string",
                            "description": "æœç´¢æŸ¥è¯¢å†…å®¹"
                        }
                    },
                    "required": ["query"]
                }
            },
            "weather": {
                "name": "weather",
                "description": "è·å–å¤©æ°”ä¿¡æ¯",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "location": {
                            "type": "string",
                            "description": "åœ°ç‚¹åç§°ï¼Œå¦‚ï¼šåŒ—äº¬ã€ä¸Šæµ·"
                        },
                        "date": {
                            "type": "string",
                            "description": "æ—¥æœŸï¼Œå¦‚ï¼štodayã€tomorrow",
                            "enum": ["today", "tomorrow"]
                        }
                    },
                    "required": ["location"]
                }
            }
        }
        
        # æ·»åŠ å·¥å…·æ ¼å¼è½¬æ¢é…ç½®
        self.tool_format_mapping = {
            'gpt-4': {
                'type': 'function',
                'function_field': 'function'
            },
            'gpt-3.5-turbo': {
                'type': 'function',
                'function_field': 'function'
            },
            'claude-3': {
                'type': 'tool',
                'function_field': 'function'
            }
        }
        
        # æ•°æ®åº“ç›¸å…³è®¾ç½®
        self.save_to_db = kwargs.get('save_to_db', os.getenv('SAVE_TO_DB', 'false').lower() == 'true')
        if self.save_to_db:
            logger.info("å¯ç”¨æ•°æ®åº“å­˜å‚¨...")
            self.db_ops = kwargs.get('db_ops', DatabaseOperations())
            self.current_conversation_id = None
            # æ£€æŸ¥å¹¶æ·»åŠ reasoningåˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            add_reasoning_column_if_not_exists()
        else:
            logger.info("æ•°æ®åº“å­˜å‚¨å·²ç¦ç”¨")
            self.db_ops = None
            
        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        if 'clients' in kwargs:
            self.thinker_client = kwargs['clients'].get('thinker')
            self.claude_client = kwargs['clients'].get('claude')
        else:
            logger.info("åˆå§‹åŒ–æ€è€ƒè€…å®¢æˆ·ç«¯...")
            provider = self._get_reasoning_provider()
            self.thinker_client = provider
            
            logger.info("åˆå§‹åŒ–Claudeå®¢æˆ·ç«¯...")
            self.claude_client = ClaudeClient(
                api_key=self.claude_api_key,
                api_url=self.claude_api_url,
                provider=self.claude_provider
            )
        
        # éªŒè¯é…ç½®æœ‰æ•ˆæ€§
        self._validate_config()
        
        # é…ç½®æœç´¢å¢å¼º
        self.search_enabled = os.getenv('ENABLE_SEARCH_ENHANCEMENT', 'true').lower() == 'true'
        
        logger.info("DeepClaudeæœåŠ¡åˆå§‹åŒ–å®Œæˆ")
        
    def _get_reasoning_provider(self):
        """è·å–æ€è€ƒè€…å®ä¾‹"""
        provider = os.getenv('REASONING_PROVIDER', 'deepseek').lower()
        
        if provider not in self.reasoning_providers:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨ç†æä¾›è€…: {provider}")
            
        return self.reasoning_providers[provider]()

    async def _handle_stream_response(self, response_queue: asyncio.Queue, 
                                    chat_id: str, created_time: int, model: str) -> AsyncGenerator[bytes, None]:
        """å¤„ç†æµå¼å“åº”"""
        try:
            while True:
                item = await response_queue.get()
                if item is None:
                    break
                    
                content_type, content = item
                if content_type == "reasoning":
                    response = {
                        "id": chat_id,
                        "object": "chat.completion.chunk",
                        "created": created_time,
                        "model": model,
                        "is_reasoning": True,  # æ·»åŠ é¡¶å±‚æ ‡è®°
                        "choices": [{
                            "index": 0,
                            "delta": {
                                "role": "assistant",
                                "content": f"ğŸ¤” æ€è€ƒè¿‡ç¨‹:\n{content}\n",
                                "reasoning": True  # åœ¨deltaä¸­æ·»åŠ æ ‡è®°
                            }
                        }]
                    }
                elif content_type == "content":
                    response = {
                        "id": chat_id,
                        "object": "chat.completion.chunk",
                        "created": created_time,
                        "model": model,
                        "choices": [{
                            "index": 0,
                            "delta": {
                                "role": "assistant",
                                "content": f"\n\n---\næ€è€ƒå®Œæ¯•ï¼Œå¼€å§‹å›ç­”ï¼š\n\n{content}"
                            }
                        }]
                    }
                yield f"data: {json.dumps(response)}\n\n".encode('utf-8')
        except Exception as e:
            logger.error(f"å¤„ç†æµå¼å“åº”æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
            raise

    async def _handle_api_error(self, e: Exception) -> str:
        """å¤„ç† API é”™è¯¯"""
        if isinstance(e, aiohttp.ClientError):
            return "ç½‘ç»œè¿æ¥é”™è¯¯ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥"
        elif isinstance(e, asyncio.TimeoutError):
            return "è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•"
        elif isinstance(e, ValueError):
            return f"å‚æ•°é”™è¯¯: {str(e)}"
        else:
            return f"æœªçŸ¥é”™è¯¯: {str(e)}"

    async def chat_completions_with_stream(self, messages: list, tools: list = None, tool_choice: str = "auto", **kwargs):
        """æµå¼å¯¹è¯å®Œæˆï¼Œæ”¯æŒå·¥å…·è°ƒç”¨"""
        try:
            logger.info("å¼€å§‹æµå¼å¤„ç†è¯·æ±‚...")
            logger.debug(f"è¾“å…¥æ¶ˆæ¯: {messages}")
            
            # 1. å‡†å¤‡å‚æ•°å’Œå˜é‡
            chat_id = kwargs.get("chat_id", f"chatcmpl-{uuid.uuid4()}")
            created_time = kwargs.get("created_time", int(time.time()))
            model_name = kwargs.get("model", "deepclaude")
            has_tools = tools and len(tools) > 0
            
            # éªŒè¯å·¥å…·é…ç½®
            if has_tools:
                logger.info(f"è¯·æ±‚åŒ…å« {len(tools)} ä¸ªå·¥å…·")
                logger.info("åŸå§‹å·¥å…·æ ¼å¼:")
                logger.info(json.dumps(tools, ensure_ascii=False))
                
                # éªŒè¯å¹¶è½¬æ¢å·¥å…·
                tools = self._validate_and_convert_tools(tools, target_format='claude-3')
                if tools:
                    logger.info(f"éªŒè¯æˆåŠŸ {len(tools)} ä¸ªå·¥å…·")
                    logger.info("è½¬æ¢åçš„å·¥å…·æ ¼å¼:")
                    logger.info(json.dumps(tools, ensure_ascii=False))
                else:
                    logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„å·¥å…·å¯ç”¨ï¼Œå°†ä½œä¸ºæ™®é€šå¯¹è¯å¤„ç†")
                    has_tools = False
                
                logger.info(f"å·¥å…·é€‰æ‹©ç­–ç•¥: {tool_choice}")
            else:
                logger.info("è¯·æ±‚ä¸­ä¸åŒ…å«å·¥å…·ï¼Œå°†ä½œä¸ºæ™®é€šå¯¹è¯å¤„ç†")
            
            # æå–åŸå§‹é—®é¢˜
            original_question = ""
            if messages and messages[-1]["role"] == "user":
                original_question = messages[-1]["content"]
                logger.info(f"åŸå§‹é—®é¢˜: {original_question}")
                
                # åˆ†æé—®é¢˜æ˜¯å¦éœ€è¦å·¥å…·
                if has_tools:
                    logger.info("åˆ†æé—®é¢˜æ˜¯å¦éœ€è¦å·¥å…·...")
                    need_weather = any(word in original_question.lower() for word in ["å¤©æ°”", "æ°”æ¸©", "weather"])
                    need_search = any(word in original_question.lower() for word in ["æœç´¢", "æŸ¥è¯¢", "search"])
                    
                    if need_weather:
                        logger.info("æ£€æµ‹åˆ°å¤©æ°”æŸ¥è¯¢éœ€æ±‚")
                    if need_search:
                        logger.info("æ£€æµ‹åˆ°æœç´¢æŸ¥è¯¢éœ€æ±‚")
                    
                    if not (need_weather or need_search):
                        logger.info("æœªæ£€æµ‹åˆ°æ˜ç¡®çš„å·¥å…·éœ€æ±‚")
            
            # 2. æ€è€ƒé˜¶æ®µ
            logger.info("å¼€å§‹æ€è€ƒé˜¶æ®µ...")
            search_enhanced = False
            search_hint = ""
            
            if has_tools and self.search_enabled and original_question:
                search_hint = await self._enhance_with_search(original_question)
                if search_hint:
                    search_enhanced = True
                    logger.info("ä½¿ç”¨æœç´¢å¢å¼ºæ€è€ƒ")
                    yield self._format_stream_response(
                        f"ä½¿ç”¨æœç´¢å¢å¼ºæ€è€ƒ...\n{search_hint}",
                        content_type="reasoning",
                        is_first_thought=True,
                        **kwargs
                    )
            
            if not search_enhanced:
                yield self._format_stream_response(
                    "å¼€å§‹æ€è€ƒé—®é¢˜...",
                    content_type="reasoning",
                    is_first_thought=True,
                    **kwargs
                )
            
            # è·å–æ¨ç†å†…å®¹
            reasoning_content = []
            reasoning_success = False
            thought_complete = False
            full_reasoning = ""
            
            try:
                provider = self._get_reasoning_provider()
                logger.info(f"ä½¿ç”¨æ¨ç†æä¾›è€…: {provider.__class__.__name__}")
                
                for retry_count, reasoning_mode in enumerate(self.reasoning_modes):
                    if reasoning_success:
                        break
                        
                    if retry_count > 0:
                        logger.info(f"å°è¯•ä½¿ç”¨ä¸åŒçš„æ¨ç†æ¨¡å¼: {reasoning_mode}")
                        os.environ["DEEPSEEK_REASONING_MODE"] = reasoning_mode
                        provider = self._get_reasoning_provider()
                    
                    try:
                        async for content_type, content in provider.get_reasoning(
                            messages=messages,
                            **self._prepare_thinker_kwargs(kwargs)
                        ):
                            if content_type == "reasoning":
                                reasoning_content.append(content)
                                logger.debug(f"æ”¶åˆ°æ¨ç†å†…å®¹: {content[:50]}...")
                                yield self._format_stream_response(
                                    content,
                                    content_type="reasoning",
                                    is_first_thought=False,
                                    **kwargs
                                )
                            elif content_type == "content":
                                thought_complete = True
                                logger.debug("æ¨ç†é˜¶æ®µå®Œæˆ")
                        
                        if len("".join(reasoning_content)) > self.min_reasoning_chars:
                            reasoning_success = True
                            logger.info("æˆåŠŸè·å–è¶³å¤Ÿçš„æ¨ç†å†…å®¹")
                    except Exception as e:
                        logger.error(f"æ¨ç†è·å–å¤±è´¥ (æ¨¡å¼: {reasoning_mode}): {e}")
                        
                        if retry_count == len(self.reasoning_modes) - 1:
                            error_message = await self._handle_api_error(e)
                            logger.error(f"æ‰€æœ‰æ¨ç†æ¨¡å¼éƒ½å¤±è´¥: {error_message}")
                            yield self._format_stream_response(
                                f"æ€è€ƒè¿‡ç¨‹ä¸­é‡åˆ°é”™è¯¯: {error_message}",
                                content_type="error",
                                is_first_thought=False,
                                **kwargs
                            )
                
                full_reasoning = "\n".join(reasoning_content)
                logger.info(f"æ¨ç†å†…å®¹é•¿åº¦: {len(full_reasoning)} å­—ç¬¦")
                
                if search_hint:
                    full_reasoning = f"{search_hint}\n\n{full_reasoning}"
                    logger.debug("å·²æ·»åŠ æœç´¢æç¤ºåˆ°æ¨ç†å†…å®¹")
                
                # 3. å·¥å…·è°ƒç”¨é˜¶æ®µ
                if has_tools and reasoning_success:
                    logger.info(f"å¼€å§‹å·¥å…·è°ƒç”¨å†³ç­– - å·¥å…·æ•°é‡: {len(tools)}")
                    
                    # å†³å®šæ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·
                    decision_prompt = self._format_tool_decision_prompt(
                        original_question=original_question,
                        reasoning=full_reasoning,
                        tools=tools
                    )
                    logger.debug(f"å·¥å…·å†³ç­–æç¤º: {decision_prompt[:200]}...")
                    
                    # å‘Claudeå‘é€å†³ç­–è¯·æ±‚
                    tool_decision_response = await self.claude_client.chat(
                        messages=[{"role": "user", "content": decision_prompt}],
                        tools=tools,
                        tool_choice=tool_choice,
                        **self._prepare_answerer_kwargs(kwargs)
                    )
                    
                    # å¦‚æœå†³å®šä½¿ç”¨å·¥å…·ï¼Œè¿”å›å·¥å…·è°ƒç”¨å“åº”
                    if "tool_calls" in tool_decision_response.get("choices", [{}])[0].get("message", {}):
                        tool_calls = tool_decision_response["choices"][0]["message"]["tool_calls"]
                        if tool_calls:
                            tool_names = [t.get("function", {}).get("name", "æœªçŸ¥å·¥å…·") for t in tool_calls]
                            logger.info(f"å·¥å…·è°ƒç”¨å†³ç­–ç»“æœ: ä½¿ç”¨å·¥å…· {', '.join(tool_names)}")
                            
                            for tool_call in tool_calls:
                                logger.info(f"ç”Ÿæˆå·¥å…·è°ƒç”¨å“åº”: {tool_call.get('function', {}).get('name', 'æœªçŸ¥å·¥å…·')}")
                                yield self._format_tool_call_response(
                                    tool_call=tool_call,
                                    chat_id=chat_id,
                                    created_time=created_time,
                                    model=model_name
                                )
                            
                            logger.info("å·¥å…·è°ƒç”¨æµç¨‹ç»“æŸï¼Œç­‰å¾…å®¢æˆ·ç«¯æ‰§è¡Œå·¥å…·")
                            yield b'data: [DONE]\n\n'
                            return
                        else:
                            logger.info("å·¥å…·è°ƒç”¨å†³ç­–ç»“æœ: ä¸ä½¿ç”¨å·¥å…·")
                    else:
                        logger.info("å·¥å…·è°ƒç”¨å†³ç­–ç»“æœ: ä¸ä½¿ç”¨å·¥å…·")
                
                # 4. å›ç­”é˜¶æ®µ
                logger.info("å¼€å§‹ç”Ÿæˆæœ€ç»ˆå›ç­”...")
                yield self._format_stream_response(
                    "\n\n---\næ€è€ƒå®Œæ¯•ï¼Œå¼€å§‹å›ç­”ï¼š\n\n",
                    content_type="separator",
                    is_first_thought=False,
                    **kwargs
                )
                
                # æ„é€ Claudeçš„è¾“å…¥æ¶ˆæ¯
                combined_content = f"""
è¿™æ˜¯æˆ‘è‡ªå·±åŸºäºé—®é¢˜çš„æ€è€ƒè¿‡ç¨‹:\n{full_reasoning}\n\n
ä¸Šé¢æ˜¯æˆ‘è‡ªå·±çš„æ€è€ƒè¿‡ç¨‹ä¸ä¸€å®šå®Œå…¨æ­£ç¡®è¯·å€Ÿé‰´æ€è€ƒè¿‡ç¨‹å’ŒæœŸä¸­ä½ ä¹Ÿè®¤ä¸ºæ­£ç¡®çš„éƒ¨åˆ†ï¼ˆ1000% æƒé‡ï¼‰
ï¼Œç°åœ¨è¯·ç»™å‡ºè¯¦ç»†å’Œç»†è‡´çš„ç­”æ¡ˆï¼Œä¸è¦çœç•¥æ­¥éª¤å’Œæ­¥éª¤ç»†èŠ‚
ï¼Œè¦åˆ†è§£åŸé¢˜ç¡®ä¿ä½ ç†è§£äº†åŸé¢˜çš„æ¯ä¸ªéƒ¨åˆ†ï¼Œä¹Ÿè¦æŒæ¡æ•´ä½“æ„æ€
ï¼Œæœ€ä½³è´¨é‡ï¼ˆ1000% æƒé‡ï¼‰ï¼Œæœ€è¯¦ç»†è§£ç­”ï¼ˆ1000% æƒé‡ï¼‰ï¼Œä¸è¦å›ç­”å¤ªç®€å•è®©æˆ‘èƒ½å‚è€ƒä¸€æ­¥æ­¥åº”ç”¨ï¼ˆ1000% æƒé‡ï¼‰:"""
                
                claude_messages = [{"role": "user", "content": combined_content}]
                logger.debug("å‘Claudeå‘é€æœ€ç»ˆæç¤º")
                
                # æµå¼è·å–Claudeå›ç­”
                answer_content = []
                async for content_type, content in self.claude_client.stream_chat(
                    messages=claude_messages,
                    **self._prepare_answerer_kwargs(kwargs)
                ):
                    if content_type in ["answer", "content"]:
                        answer_content.append(content)
                        logger.debug(f"æ”¶åˆ°å›ç­”å†…å®¹: {content[:50]}...")
                        yield self._format_stream_response(
                            content,
                            content_type="content",
                            is_first_thought=False,
                            **kwargs
                        )
                
                logger.info("å›ç­”ç”Ÿæˆå®Œæˆ")
                
                # å‘é€æµå¼å“åº”ç»“æŸæ ‡å¿—
                yield b'data: [DONE]\n\n'
                
            except Exception as e:
                logger.error(f"æµå¼å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}", exc_info=True)
                error_message = await self._handle_api_error(e)
                yield self._format_stream_response(
                    f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {error_message}",
                    content_type="error",
                    is_first_thought=False,
                    **kwargs
                )
                
        except Exception as outer_e:
            logger.error(f"æµå¼å¤„ç†å¤–å±‚é”™è¯¯: {outer_e}", exc_info=True)
            yield self._format_stream_response(
                f"æœåŠ¡å™¨é”™è¯¯: {str(outer_e)}",
                content_type="error",
                is_first_thought=False,
                **kwargs
            )

    def _prepare_thinker_kwargs(self, kwargs: dict) -> dict:
        """å‡†å¤‡æ€è€ƒè€…å‚æ•°"""
        provider_type = os.getenv('REASONING_PROVIDER', 'deepseek').lower()
        
        if provider_type == 'ollama':
            model = "deepseek-r1:32b"
        else:
            # ä¸å†ä½¿ç”¨kwargsä¸­ä¼ å…¥çš„modelå‚æ•°ï¼Œä»¥é¿å…ä½¿ç”¨ä¸å…¼å®¹çš„æ¨¡å‹åç§°
            # è€Œæ˜¯ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é»˜è®¤çš„DeepSeekæ¨¡å‹åç§°
            model = os.getenv('DEEPSEEK_MODEL', 'deepseek-reasoner')
            
            # æ ¹æ®providerè¿›è¡Œç‰¹å®šå¤„ç†
            if provider_type == 'deepseek':
                model = 'deepseek-reasoner'  # ä½¿ç”¨ç¡®å®šå¯ç”¨çš„æ¨¡å‹
            elif provider_type == 'siliconflow':
                model = 'deepseek-ai/DeepSeek-R1'
            elif provider_type == 'nvidia':
                model = 'deepseek-ai/deepseek-r1'
            
        return {
            'model': model,
            'temperature': kwargs.get('temperature', 0.7),
            'top_p': kwargs.get('top_p', 0.9)
        }
        
    def _prepare_answerer_kwargs(self, kwargs: dict) -> dict:
        """å‡†å¤‡å›ç­”è€…å‚æ•°"""
        return {
            'model': os.getenv('CLAUDE_MODEL', 'claude-3-7-sonnet-20250219'),
            'temperature': kwargs.get('temperature', 0.7),
            'top_p': kwargs.get('top_p', 0.9)
        }

    def _chunk_content(self, content: str, chunk_size: int = 3) -> list[str]:
        """å°†å†…å®¹åˆ†å‰²æˆå°å—ä»¥å®ç°æ›´ç»†ç²’åº¦çš„æµå¼è¾“å‡º
        
        Args:
            content: è¦åˆ†å‰²çš„å†…å®¹
            chunk_size: æ¯ä¸ªå—çš„å¤§å°ï¼Œé»˜è®¤ä¸º3ä¸ªå­—ç¬¦
            
        Returns:
            list[str]: åˆ†å‰²åçš„å†…å®¹å—åˆ—è¡¨
        """
        return [content[i:i+chunk_size] for i in range(0, len(content), chunk_size)]

    def _format_claude_prompt(self, original_question: str, reasoning: str) -> str:
        """æ ¼å¼åŒ–ç»™Claudeçš„æç¤ºè¯"""
        return f"""
åŸå§‹é—®é¢˜:
{original_question}

æ€è€ƒè¿‡ç¨‹:
{reasoning}

è¯·åŸºäºä»¥ä¸Šæ€è€ƒè¿‡ç¨‹å’ŒåŸå§‹é—®é¢˜,ç»™å‡ºè¯¦ç»†çš„ç­”æ¡ˆã€‚è¦æ±‚:
1. åˆ†æ­¥éª¤è¯¦ç»†è§£ç­”
2. ç¡®ä¿ç†è§£é—®é¢˜çš„æ¯ä¸ªéƒ¨åˆ†
3. ç»™å‡ºå®Œæ•´çš„è§£å†³æ–¹æ¡ˆ
4. å¦‚æœæ€è€ƒè¿‡ç¨‹æœ‰é”™è¯¯æˆ–ä¸å®Œæ•´ï¼Œè¯·æŒ‡å‡ºå¹¶è¡¥å……æ­£ç¡®çš„è§£ç­”
5. ä¿æŒå›ç­”çš„ä¸“ä¸šæ€§å’Œå‡†ç¡®æ€§
"""

    async def chat_completions_without_stream(
        self,
        messages: list,
        model_arg: tuple[float, float, float, float],
        tools: list = None,
        tool_choice: str = "auto",
        deepseek_model: str = "deepseek-reasoner",
        claude_model: str = os.getenv('CLAUDE_MODEL', 'claude-3-7-sonnet-20250219'),
        **kwargs
    ) -> dict:
        """éæµå¼å¯¹è¯å®Œæˆ
        
        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
            model_arg: æ¨¡å‹å‚æ•°å…ƒç»„
            tools: å·¥å…·åˆ—è¡¨
            tool_choice: å·¥å…·é€‰æ‹©ç­–ç•¥
            deepseek_model: DeepSeek æ¨¡å‹åç§°
            claude_model: Claude æ¨¡å‹åç§°
            
        Returns:
            dict: åŒ…å«å›ç­”å†…å®¹çš„å“åº”å­—å…¸
        """
        logger.info("å¼€å§‹å¤„ç†è¯·æ±‚...")
        logger.debug(f"è¾“å…¥æ¶ˆæ¯: {messages}")
        
        # åˆ›å»ºæˆ–è·å–å¯¹è¯ID
        if self.save_to_db:
            try:
                # æå–ç”¨æˆ·IDï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                user_id = None  # éæµå¼æ¨¡å¼é€šå¸¸ä¸ä¼ é€’ç”¨æˆ·IDï¼Œä½¿ç”¨é»˜è®¤ç®¡ç†å‘˜ç”¨æˆ·
                
                # ä»æœ€åä¸€æ¡æ¶ˆæ¯ä¸­æå–æ ‡é¢˜ï¼ˆå–å‰20ä¸ªå­—ç¬¦ä½œä¸ºå¯¹è¯æ ‡é¢˜ï¼‰
                if messages and 'content' in messages[-1]:
                    title = messages[-1]['content'][:20] + "..."
                    # ä¿å­˜ç”¨æˆ·é—®é¢˜
                    user_question = messages[-1]['content']
                else:
                    title = None
                    user_question = "æœªæä¾›é—®é¢˜å†…å®¹"
                    
                # åˆ›å»ºæ–°å¯¹è¯
                self.current_conversation_id = self.db_ops.create_conversation(
                    user_id=user_id, 
                    title=title
                )
                logger.info(f"åˆ›å»ºæ–°å¯¹è¯ï¼ŒID: {self.current_conversation_id}")
                
                # ä¿å­˜ç”¨æˆ·é—®é¢˜
                self.db_ops.add_conversation_history(
                    conversation_id=self.current_conversation_id,
                    role="user",
                    content=user_question
                )
                logger.info("ç”¨æˆ·é—®é¢˜å·²ä¿å­˜åˆ°æ•°æ®åº“")
            except Exception as db_e:
                logger.error(f"ä¿å­˜å¯¹è¯æ•°æ®å¤±è´¥: {db_e}")
        
        # 1. è·å–æ¨ç†å†…å®¹
        logger.info("æ­£åœ¨è·å–æ¨ç†å†…å®¹...")
        try:
            reasoning = await self._get_reasoning_content(
                messages=messages,
                model=deepseek_model,
                model_arg=model_arg
            )
        except Exception as e:
            logger.error(f"è·å–æ¨ç†å†…å®¹å¤±è´¥: {e}")
            reasoning = "æ— æ³•è·å–æ¨ç†å†…å®¹"
            
            # å°è¯•ä½¿ç”¨ä¸åŒçš„æ¨ç†æ¨¡å¼é‡è¯•
            for reasoning_mode in self.reasoning_modes[1:]:  # è·³è¿‡ç¬¬ä¸€ä¸ªå·²ä½¿ç”¨çš„æ¨¡å¼
                try:
                    logger.info(f"å°è¯•ä½¿ç”¨ä¸åŒçš„æ¨ç†æ¨¡å¼è·å–å†…å®¹: {reasoning_mode}")
                    os.environ["DEEPSEEK_REASONING_MODE"] = reasoning_mode
                    reasoning = await self._get_reasoning_content(
                        messages=messages,
                        model=deepseek_model,
                        model_arg=model_arg
                    )
                    if reasoning and len(reasoning) > self.min_reasoning_chars:
                        logger.info(f"ä½¿ç”¨æ¨ç†æ¨¡å¼ {reasoning_mode} æˆåŠŸè·å–æ¨ç†å†…å®¹")
                        break
                except Exception as retry_e:
                    logger.error(f"ä½¿ç”¨æ¨ç†æ¨¡å¼ {reasoning_mode} é‡è¯•å¤±è´¥: {retry_e}")
        
        logger.debug(f"è·å–åˆ°æ¨ç†å†…å®¹: {reasoning[:min(500, len(reasoning))]}...")
        
        original_question = messages[-1]["content"] if messages and messages[-1]["role"] == "user" else ""
        has_tool_decision = False
        tool_calls = []
        
        # å¦‚æœæä¾›äº†å·¥å…·å‚æ•°ï¼Œç¡®å®šæ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·
        if tools and len(tools) > 0:
            try:
                # å¦‚æœå¯ç”¨äº†æœç´¢å¢å¼ºï¼Œå¯ä»¥æ·»åŠ æç¤º
                search_hint = ""
                if self.search_enabled and messages and messages[-1]["role"] == "user":
                    search_hint = await self._enhance_with_search(messages[-1]["content"])
                    if search_hint:
                        reasoning = f"{search_hint}\n\n{reasoning}"
                
                # é’ˆå¯¹å·¥å…·çš„å†³ç­–æç¤º
                decision_prompt = self._format_tool_decision_prompt(original_question, reasoning, tools)
                logger.debug(f"å·¥å…·å†³ç­–æç¤º: {decision_prompt[:200]}...")
                
                # å‘Claudeå‘é€å†³ç­–è¯·æ±‚
                tool_decision_response = await self.claude_client.chat(
                    messages=[{"role": "user", "content": decision_prompt}],
                    model=claude_model,
                    tools=tools,
                    tool_choice=tool_choice,
                    model_arg=model_arg
                )
                
                # å¦‚æœClaudeå†³å®šä½¿ç”¨å·¥å…·ï¼Œè¿”å›å·¥å…·è°ƒç”¨å“åº”
                if "tool_calls" in tool_decision_response:
                    tool_calls = tool_decision_response.get("tool_calls", [])
                    has_tool_decision = True
                    logger.info(f"Claudeå†³å®šä½¿ç”¨å·¥å…·: {len(tool_calls)}ä¸ªå·¥å…·è°ƒç”¨")
                    
                    # æ„é€ OpenAIæ ¼å¼çš„å“åº”
                    response = {
                        "id": f"chatcmpl-{uuid.uuid4()}",
                        "object": "chat.completion",
                        "created": int(time.time()),
                        "model": kwargs.get("model", "deepclaude"),
                        "choices": [{
                            "index": 0,
                            "message": {
                                "role": "assistant",
                                "content": None,
                                "tool_calls": tool_calls
                            },
                            "finish_reason": "tool_calls"
                        }]
                    }
                    
                    return response
            except Exception as tool_e:
                logger.error(f"å·¥å…·è°ƒç”¨æµç¨‹å¤±è´¥: {tool_e}")
                # å¦‚æœå·¥å…·è°ƒç”¨å¤±è´¥ï¼Œå›é€€åˆ°æ™®é€šå›ç­”
        
        # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨æˆ–å†³ç­–ä¸ä½¿ç”¨å·¥å…·ï¼Œç”Ÿæˆæ™®é€šå›ç­”
        if not has_tool_decision:
            # æ„é€  Claude çš„è¾“å…¥æ¶ˆæ¯
            combined_content = f"""
è¿™æ˜¯æˆ‘è‡ªå·±åŸºäºé—®é¢˜çš„æ€è€ƒè¿‡ç¨‹:\n{reasoning}\n\n
ä¸Šé¢æ˜¯æˆ‘è‡ªå·±çš„æ€è€ƒè¿‡ç¨‹ä¸ä¸€å®šå®Œå…¨æ­£ç¡®è¯·å€Ÿé‰´æ€è€ƒè¿‡ç¨‹å’ŒæœŸä¸­ä½ ä¹Ÿè®¤ä¸ºæ­£ç¡®çš„éƒ¨åˆ†ï¼ˆ1000% æƒé‡ï¼‰
ï¼Œç°åœ¨è¯·ç»™å‡ºè¯¦ç»†å’Œç»†è‡´çš„ç­”æ¡ˆï¼Œä¸è¦çœç•¥æ­¥éª¤å’Œæ­¥éª¤ç»†èŠ‚
ï¼Œè¦åˆ†è§£åŸé¢˜ç¡®ä¿ä½ ç†è§£äº†åŸé¢˜çš„æ¯ä¸ªéƒ¨åˆ†ï¼Œä¹Ÿè¦æŒæ¡æ•´ä½“æ„æ€
ï¼Œæœ€ä½³è´¨é‡ï¼ˆ1000% æƒé‡ï¼‰ï¼Œæœ€è¯¦ç»†è§£ç­”ï¼ˆ1000% æƒé‡ï¼‰ï¼Œä¸è¦å›ç­”å¤ªç®€å•è®©æˆ‘èƒ½å‚è€ƒä¸€æ­¥æ­¥åº”ç”¨ï¼ˆ1000% æƒé‡ï¼‰:"""
            
            claude_messages = [{"role": "user", "content": combined_content}]
            
            # 3. è·å– Claude å›ç­”
            logger.info("æ­£åœ¨è·å– Claude å›ç­”...")
            try:
                full_content = ""
                async for content_type, content in self.claude_client.stream_chat(
                    messages=claude_messages,
                    model_arg=model_arg,
                    model=claude_model,
                    stream=False
                ):
                    if content_type in ["answer", "content"]:
                        logger.debug(f"è·å–åˆ° Claude å›ç­”: {content}")
                        full_content += content
                
                # ä¿å­˜AIå›ç­”åˆ°æ•°æ®åº“
                if self.save_to_db and self.current_conversation_id:
                    try:
                        # ä¼°ç®—tokenæ•°é‡
                        tokens = len(reasoning.split()) + len(full_content.split())
                        
                        # ä¿å­˜AIå›ç­”
                        self.db_ops.add_conversation_history(
                            conversation_id=self.current_conversation_id,
                            role="ai",
                            content=full_content,
                            reasoning=reasoning,
                            model_name=claude_model,
                            tokens=tokens
                        )
                        logger.info("AIå›ç­”å’Œæ€è€ƒè¿‡ç¨‹å·²ä¿å­˜åˆ°æ•°æ®åº“")
                    except Exception as db_e:
                        logger.error(f"ä¿å­˜AIå›ç­”æ•°æ®å¤±è´¥: {db_e}")
                
                # è¿”å›OpenAIæ ¼å¼çš„å“åº”
                response = {
                    "id": f"chatcmpl-{uuid.uuid4()}",
                    "object": "chat.completion",
                    "created": int(time.time()),
                    "model": kwargs.get("model", "deepclaude"),
                    "choices": [{
                        "index": 0,
                        "message": {
                            "role": "assistant",
                            "content": full_content
                        },
                        "finish_reason": "stop"
                    }]
                }
                
                return response
            except Exception as e:
                logger.error(f"è·å– Claude å›ç­”å¤±è´¥: {e}")
                raise

    async def _get_reasoning_content(self, messages: list, model: str, **kwargs) -> str:
        """è·å–æ¨ç†å†…å®¹
        
        1. é¦–å…ˆå°è¯•ä½¿ç”¨é…ç½®çš„æ¨ç†æä¾›è€…
        2. å¦‚æœå¤±è´¥åˆ™å°è¯•åˆ‡æ¢åˆ°å¤‡ç”¨æä¾›è€…
        3. æ”¯æŒå¤šç§æ¨ç†æ¨¡å¼é‡è¯•
        """
        try:
            provider = self._get_reasoning_provider()
            reasoning_content = []
            content_received = False
            
            logger.info(f"å¼€å§‹è·å–æ€è€ƒå†…å®¹ï¼Œæ¨¡å‹: {model}, æ¨ç†æ¨¡å¼: {os.getenv('DEEPSEEK_REASONING_MODE', 'auto')}")
            
            async for content_type, content in provider.get_reasoning(
                messages=messages,
                model=model,
                model_arg=kwargs.get('model_arg')  # åªä¼ é€’å¿…è¦çš„å‚æ•°
            ):
                if content_type == "reasoning":
                    reasoning_content.append(content)
                    logger.debug(f"æ”¶åˆ°æ¨ç†å†…å®¹ï¼Œå½“å‰é•¿åº¦: {len(''.join(reasoning_content))}")
                elif content_type == "content" and not reasoning_content:
                    # å¦‚æœæ²¡æœ‰æ”¶é›†åˆ°æ¨ç†å†…å®¹ï¼Œä½†æ”¶åˆ°äº†å†…å®¹ï¼Œå°†å…¶ä¹Ÿè§†ä¸ºæ¨ç†
                    logger.info("æœªæ”¶é›†åˆ°æ¨ç†å†…å®¹ï¼Œå°†æ™®é€šå†…å®¹è§†ä¸ºæ¨ç†")
                    reasoning_content.append(f"åˆ†æ: {content}")
                    logger.debug(f"æ™®é€šå†…å®¹è½¬ä¸ºæ¨ç†å†…å®¹ï¼Œå½“å‰é•¿åº¦: {len(''.join(reasoning_content))}")
                elif content_type == "content":
                    # è®°å½•æ”¶åˆ°æ™®é€šå†…å®¹ï¼Œè¿™é€šå¸¸è¡¨ç¤ºæ¨ç†é˜¶æ®µç»“æŸ
                    content_received = True
                    logger.info("æ”¶åˆ°æ™®é€šå†…å®¹ï¼Œæ¨ç†é˜¶æ®µå¯èƒ½å·²ç»“æŸ")
                
            result = "\n".join(reasoning_content)
            
            # å¦‚æœå·²æ”¶åˆ°æ™®é€šå†…å®¹ä¸”æ¨ç†å†…å®¹é•¿åº¦è¶³å¤Ÿï¼Œç›´æ¥è¿”å›
            if content_received and len(result) > self.min_reasoning_chars:
                logger.info(f"å·²æ”¶åˆ°æ™®é€šå†…å®¹ä¸”æ¨ç†å†…å®¹é•¿åº¦è¶³å¤Ÿ ({len(result)}å­—ç¬¦)ï¼Œç»“æŸè·å–æ¨ç†")
                return result
            
            # å¦‚æœå†…å®¹ä¸è¶³ï¼Œå°è¯•åˆ‡æ¢æ¨¡å¼é‡è¯•
            if not result or len(result) < self.min_reasoning_chars:
                current_mode = os.getenv('DEEPSEEK_REASONING_MODE', 'auto')
                logger.warning(f"ä½¿ç”¨æ¨¡å¼ {current_mode} è·å–çš„æ¨ç†å†…å®¹ä¸è¶³ï¼Œå°è¯•åˆ‡æ¢æ¨¡å¼")
                
                # å°è¯•ä¸‹ä¸€ä¸ªæ¨ç†æ¨¡å¼
                for reasoning_mode in self.reasoning_modes:
                    if reasoning_mode == current_mode:
                        continue
                    
                    logger.info(f"å°è¯•ä½¿ç”¨æ¨ç†æ¨¡å¼: {reasoning_mode}")
                    os.environ["DEEPSEEK_REASONING_MODE"] = reasoning_mode
                    provider = self._get_reasoning_provider()  # é‡æ–°åˆå§‹åŒ–æä¾›è€…
                    
                    reasoning_content = []
                    async for content_type, content in provider.get_reasoning(
                        messages=messages,
                        model=model,
                        model_arg=kwargs.get('model_arg')
                    ):
                        if content_type == "reasoning":
                            reasoning_content.append(content)
                        elif content_type == "content" and not reasoning_content:
                            reasoning_content.append(f"åˆ†æ: {content}")
                    
                    retry_result = "\n".join(reasoning_content)
                    if retry_result and len(retry_result) > self.min_reasoning_chars:
                        logger.info(f"ä½¿ç”¨æ¨ç†æ¨¡å¼ {reasoning_mode} æˆåŠŸè·å–è¶³å¤Ÿçš„æ¨ç†å†…å®¹")
                        return retry_result
            
            return result or "æ— æ³•è·å–è¶³å¤Ÿçš„æ¨ç†å†…å®¹"
        except Exception as e:
            logger.error(f"ä¸»è¦æ¨ç†æä¾›è€…å¤±è´¥: {e}")
            if isinstance(provider, DeepSeekClient):
                # è·å–å½“å‰æä¾›å•†åç§°
                current_provider = getattr(provider, 'provider', 'unknown')
                logger.info(f"ä» {current_provider} æä¾›å•†åˆ‡æ¢åˆ° Ollama æ¨ç†æä¾›è€…")
                try:
                    provider = OllamaR1Client(api_url=os.getenv('OLLAMA_API_URL'))
                    # é‡è¯•ä½¿ç”¨ Ollama
                    reasoning_content = []
                    async for content_type, content in provider.get_reasoning(
                        messages=messages,
                        model="deepseek-r1:32b"
                    ):
                        if content_type == "reasoning":
                            reasoning_content.append(content)
                    return "\n".join(reasoning_content)
                except Exception as e:
                    logger.error(f"å¤‡ç”¨æ¨ç†æä¾›è€…ä¹Ÿå¤±è´¥: {e}")
                
            return "æ— æ³•è·å–æ¨ç†å†…å®¹"

    async def _retry_operation(self, operation, max_retries=3):
        """é€šç”¨é‡è¯•æœºåˆ¶"""
        for i in range(max_retries):
            try:
                return await operation()
            except Exception as e:
                if i == max_retries - 1:
                    raise
                logger.warning(f"æ“ä½œå¤±è´¥ï¼Œæ­£åœ¨é‡è¯• ({i+1}/{max_retries}): {str(e)}")
                await asyncio.sleep(1 * (i + 1))  # æŒ‡æ•°é€€é¿

    def _validate_model_names(self, deepseek_model: str, claude_model: str):
        """éªŒè¯æ¨¡å‹åç§°çš„æœ‰æ•ˆæ€§"""
        if not deepseek_model or not isinstance(deepseek_model, str):
            raise ValueError("æ— æ•ˆçš„ DeepSeek æ¨¡å‹åç§°")
        
        if not claude_model or not isinstance(claude_model, str):
            raise ValueError("æ— æ•ˆçš„ Claude æ¨¡å‹åç§°")

    def _validate_messages(self, messages: list) -> None:
        """éªŒè¯æ¶ˆæ¯åˆ—è¡¨çš„æœ‰æ•ˆæ€§"""
        if not messages:
            raise ValueError("æ¶ˆæ¯åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
        
        for msg in messages:
            if not isinstance(msg, dict):
                raise ValueError("æ¶ˆæ¯å¿…é¡»æ˜¯å­—å…¸æ ¼å¼")
            if "role" not in msg or "content" not in msg:
                raise ValueError("æ¶ˆæ¯å¿…é¡»åŒ…å« role å’Œ content å­—æ®µ")
            if msg["role"] not in ["user", "assistant", "system"]:
                raise ValueError(f"ä¸æ”¯æŒçš„æ¶ˆæ¯è§’è‰²: {msg['role']}")

    async def _get_reasoning_with_fallback(
        self, 
        messages: list,
        model: str,
        model_arg: tuple[float, float, float, float] = None
    ) -> str:
        """è·å–æ¨ç†å†…å®¹ï¼Œå¸¦æœ‰å¤‡ç”¨æ–¹æ¡ˆ
        
        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°
            model_arg: æ¨¡å‹å‚æ•°å…ƒç»„
            
        Returns:
            str: æ¨ç†å†…å®¹
        """
        try:
            provider = self._get_reasoning_provider()
            reasoning_content = []
            
            # å°è¯•ä¸åŒçš„æ¨ç†æ¨¡å¼
            for reasoning_mode in self.reasoning_modes:
                if reasoning_content and len("".join(reasoning_content)) > self.min_reasoning_chars:
                    # å¦‚æœå·²ç»æ”¶é›†åˆ°è¶³å¤Ÿçš„å†…å®¹ï¼Œç»“æŸå¾ªç¯
                    logger.info(f"å·²æ”¶é›†åˆ°è¶³å¤Ÿæ¨ç†å†…å®¹ ({len(''.join(reasoning_content))}å­—ç¬¦)ï¼Œä¸å†å°è¯•å…¶ä»–æ¨¡å¼")
                    break
                    
                logger.info(f"å°è¯•ä½¿ç”¨æ¨ç†æ¨¡å¼: {reasoning_mode}")
                os.environ["DEEPSEEK_REASONING_MODE"] = reasoning_mode
                provider = self._get_reasoning_provider()  # é‡æ–°åˆå§‹åŒ–æä¾›è€…
                
                temp_content = []
                content_received = False  # æ ‡è®°æ˜¯å¦æ”¶åˆ°æ™®é€šå†…å®¹
                
                try:
                    async for content_type, content in provider.get_reasoning(
                        messages=messages,
                        model=model,
                        model_arg=model_arg
                    ):
                        if content_type == "reasoning":
                            temp_content.append(content)
                            logger.debug(f"æ”¶åˆ°æ¨ç†å†…å®¹ï¼Œå½“å‰ä¸´æ—¶å†…å®¹é•¿åº¦: {len(''.join(temp_content))}")
                        elif content_type == "content" and not temp_content and reasoning_mode in ['early_content', 'any_content']:
                            # åœ¨æŸäº›æ¨¡å¼ä¸‹ï¼Œä¹Ÿå°†æ™®é€šå†…å®¹è§†ä¸ºæ¨ç†
                            temp_content.append(f"åˆ†æ: {content}")
                            logger.debug(f"æ™®é€šå†…å®¹è½¬ä¸ºæ¨ç†å†…å®¹ï¼Œå½“å‰ä¸´æ—¶å†…å®¹é•¿åº¦: {len(''.join(temp_content))}")
                        elif content_type == "content":
                            # æ”¶åˆ°æ™®é€šå†…å®¹ï¼Œå¯èƒ½è¡¨ç¤ºæ¨ç†é˜¶æ®µç»“æŸ
                            content_received = True
                            logger.info("æ”¶åˆ°æ™®é€šå†…å®¹ï¼Œæ¨ç†é˜¶æ®µå¯èƒ½å·²ç»“æŸ")
                            
                        # å¦‚æœæ”¶åˆ°æ™®é€šå†…å®¹ä¸”å·²æœ‰è¶³å¤Ÿæ¨ç†å†…å®¹ï¼Œæå‰ç»ˆæ­¢
                        if content_received and len("".join(temp_content)) > self.min_reasoning_chars:
                            logger.info("æ”¶åˆ°æ™®é€šå†…å®¹ä¸”ä¸´æ—¶æ¨ç†å†…å®¹è¶³å¤Ÿï¼Œæå‰ç»“æŸæ¨ç†è·å–")
                            break
                            
                    if temp_content and len("".join(temp_content)) > len("".join(reasoning_content)):
                        # å¦‚æœæœ¬æ¬¡è·å–çš„å†…å®¹æ›´å¤šï¼Œåˆ™æ›´æ–°ç»“æœ
                        reasoning_content = temp_content
                        if content_received:
                            # å¦‚æœå·²æ”¶åˆ°æ™®é€šå†…å®¹ï¼Œè¡¨ç¤ºæ¨ç†é˜¶æ®µå·²å®Œæˆï¼Œä¸å†å°è¯•å…¶ä»–æ¨¡å¼
                            logger.info("æ¨ç†é˜¶æ®µå·²ç»“æŸä¸”å†…å®¹è¶³å¤Ÿï¼Œåœæ­¢å°è¯•å…¶ä»–æ¨¡å¼")
                            break
                except Exception as mode_e:
                    logger.error(f"ä½¿ç”¨æ¨ç†æ¨¡å¼ {reasoning_mode} æ—¶å‘ç”Ÿé”™è¯¯: {mode_e}")
                    continue
            
            return "".join(reasoning_content) or "æ— æ³•è·å–æ¨ç†å†…å®¹"
        except Exception as e:
            logger.error(f"ä¸»è¦æ¨ç†æä¾›è€…å¤±è´¥: {e}")
            if isinstance(provider, DeepSeekClient):
                # è·å–å½“å‰æä¾›å•†åç§°
                current_provider = getattr(provider, 'provider', 'unknown')
                logger.info(f"ä» {current_provider} æä¾›å•†åˆ‡æ¢åˆ° Ollama æ¨ç†æä¾›è€…")
                try:
                    provider = OllamaR1Client(api_url=os.getenv('OLLAMA_API_URL'))
                    # é‡è¯•ä½¿ç”¨ Ollama
                    reasoning_content = []
                    async for content_type, content in provider.get_reasoning(
                        messages=messages,
                        model="deepseek-r1:32b"
                    ):
                        if content_type == "reasoning":
                            reasoning_content.append(content)
                    return "\n".join(reasoning_content)
                except Exception as e:
                    logger.error(f"å¤‡ç”¨æ¨ç†æä¾›è€…ä¹Ÿå¤±è´¥: {e}")
                
            return "æ— æ³•è·å–æ¨ç†å†…å®¹"

    def _validate_config(self):
        """éªŒè¯é…ç½®çš„å®Œæ•´æ€§"""
        provider = os.getenv('REASONING_PROVIDER', 'deepseek').lower()
        
        # æ£€æŸ¥provideræ˜¯å¦åœ¨æ”¯æŒåˆ—è¡¨ä¸­
        if provider not in self.reasoning_providers:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨ç†æä¾›è€…: {provider}")
            
        # é’ˆå¯¹ä¸åŒæä¾›è€…è¿›è¡ŒéªŒè¯
        if provider == 'deepseek':
            if not os.getenv('DEEPSEEK_API_KEY'):
                raise ValueError("ä½¿ç”¨ DeepSeek æ—¶å¿…é¡»æä¾› API KEY")
            if not os.getenv('DEEPSEEK_API_URL'):
                raise ValueError("ä½¿ç”¨ DeepSeek æ—¶å¿…é¡»æä¾› API URL")
        elif provider == 'ollama':
            if not os.getenv('OLLAMA_API_URL'):
                raise ValueError("ä½¿ç”¨ Ollama æ—¶å¿…é¡»æä¾› API URL")
        elif provider == 'siliconflow':
            if not os.getenv('DEEPSEEK_API_KEY'):
                raise ValueError("ä½¿ç”¨ ç¡…åŸºæµåŠ¨ æ—¶å¿…é¡»æä¾› DeepSeek API KEY")
            if not os.getenv('DEEPSEEK_API_URL'):
                raise ValueError("ä½¿ç”¨ ç¡…åŸºæµåŠ¨ æ—¶å¿…é¡»æä¾› DeepSeek API URL")
        elif provider == 'nvidia':
            if not os.getenv('DEEPSEEK_API_KEY'):
                raise ValueError("ä½¿ç”¨ NVIDIA æ—¶å¿…é¡»æä¾› DeepSeek API KEY")
            if not os.getenv('DEEPSEEK_API_URL'):
                raise ValueError("ä½¿ç”¨ NVIDIA æ—¶å¿…é¡»æä¾› DeepSeek API URL")
                
        # éªŒè¯Claudeé…ç½®
        if not os.getenv('CLAUDE_API_KEY'):
            raise ValueError("å¿…é¡»æä¾› CLAUDE_API_KEY ç¯å¢ƒå˜é‡")

    def _format_stream_response(self, content: str, content_type: str = "content", **kwargs) -> bytes:
        """æ ¼å¼åŒ–æµå¼å“åº”
        
        Args:
            content: è¦å‘é€çš„å†…å®¹
            content_type: å†…å®¹ç±»å‹ï¼Œå¯ä»¥æ˜¯ "reasoning"ã€"content" æˆ– "separator"
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            bytes: æ ¼å¼åŒ–çš„SSEå“åº”
        """
        # åŸºæœ¬å“åº”ç»“æ„
        response = {
            "id": kwargs.get("chat_id", f"chatcmpl-{int(time.time())}"),
            "object": "chat.completion.chunk",
            "created": kwargs.get("created_time", int(time.time())),
            "model": kwargs.get("model", "deepclaude"),
            "choices": [{
                "index": 0,
                "delta": {
                    "content": content
                }
            }]
        }
        
        # ä¸ºä¸åŒå†…å®¹ç±»å‹æ·»åŠ æ˜æ˜¾æ ‡è®°
        if content_type == "reasoning":
            # æ·»åŠ æ€è€ƒæ ‡è®° - åœ¨deltaä¸­å’Œresponseæ ¹çº§åˆ«éƒ½æ·»åŠ æ ‡è®°
            response["choices"][0]["delta"]["reasoning"] = True
            response["is_reasoning"] = True  # æ ¹çº§åˆ«æ·»åŠ æ ‡è®°ï¼Œæ–¹ä¾¿å‰ç«¯è¯†åˆ«
            
            # åªåœ¨é¦–ä¸ªtokenæ·»åŠ è¡¨æƒ…ç¬¦å·ï¼Œåç»­tokenä¿æŒåŸæ ·
            # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯ä»¥è¡¨æƒ…ç¬¦å·å¼€å¤´ï¼Œå¦‚æœä¸æ˜¯ï¼Œå¹¶ä¸”æ˜¯é¦–æ¬¡å‘é€æ€è€ƒå†…å®¹(å¯ä»kwargsä¸­è·å–æ ‡å¿—)ï¼Œåˆ™æ·»åŠ è¡¨æƒ…ç¬¦å·
            is_first_thought = kwargs.get("is_first_thought", False)
            if is_first_thought and not content.startswith("ğŸ¤”"):
                response["choices"][0]["delta"]["content"] = f"ğŸ¤” {content}"
        elif content_type == "separator":
            # åˆ†éš”ç¬¦ç‰¹æ®Šæ ‡è®°
            response["is_separator"] = True
        elif content_type == "error":
            # é”™è¯¯ä¿¡æ¯ç‰¹æ®Šæ ‡è®°
            response["is_error"] = True
            response["choices"][0]["delta"]["content"] = f"âš ï¸ {content}"
        
        return f"data: {json.dumps(response)}\n\n".encode('utf-8')

    def _validate_kwargs(self, kwargs: dict) -> None:
        """éªŒè¯å‚æ•°çš„æœ‰æ•ˆæ€§"""
        # éªŒè¯æ¸©åº¦å‚æ•°
        temperature = kwargs.get('temperature')
        if temperature is not None:
            if not isinstance(temperature, (int, float)) or temperature < 0 or temperature > 1:
                raise ValueError("temperature å¿…é¡»åœ¨ 0 åˆ° 1 ä¹‹é—´")
            
        # éªŒè¯ top_p å‚æ•°
        top_p = kwargs.get('top_p')
        if top_p is not None:
            if not isinstance(top_p, (int, float)) or top_p < 0 or top_p > 1:
                raise ValueError("top_p å¿…é¡»åœ¨ 0 åˆ° 1 ä¹‹é—´")
            
        # éªŒè¯æ¨¡å‹å‚æ•°
        model = kwargs.get('model')
        if model and not isinstance(model, str):
            raise ValueError("model å¿…é¡»æ˜¯å­—ç¬¦ä¸²ç±»å‹")

    def _split_into_tokens(self, text: str) -> list[str]:
        """å°†æ–‡æœ¬åˆ†å‰²æˆæ›´å°çš„token
        
        Args:
            text: è¦åˆ†å‰²çš„æ–‡æœ¬
            
        Returns:
            list[str]: tokenåˆ—è¡¨
        """
        # å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´åˆ†å‰²ç²’åº¦
        # 1. æŒ‰å­—ç¬¦åˆ†å‰²
        return list(text)
        
        # æˆ–è€…æŒ‰è¯åˆ†å‰²
        # return text.split()
        
        # æˆ–è€…ä½¿ç”¨æ›´å¤æ‚çš„åˆ†è¯ç®—æ³•
        # return some_tokenizer(text)

    # æœç´¢å¢å¼ºå‡½æ•°
    async def _enhance_with_search(self, query: str) -> str:
        """ä½¿ç”¨æœç´¢å¢å¼ºæŸ¥è¯¢ï¼Œè·å–æœ€æ–°ä¿¡æ¯
        æ³¨æ„ï¼šå®é™…æœç´¢æ“ä½œåº”ç”±Difyæ‰§è¡Œï¼Œè¿™é‡Œä»…è¿”å›æç¤ºæ–‡æœ¬
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢å†…å®¹
            
        Returns:
            str: æœç´¢ç»“æœæç¤ºæ–‡æœ¬
        """
        if not self.search_enabled:
            logger.info("æœç´¢å¢å¼ºåŠŸèƒ½æœªå¯ç”¨")
            return ""
        
        logger.info(f"å»ºè®®ä½¿ç”¨æœç´¢å¢å¼ºæŸ¥è¯¢: {query}")
        return "å»ºè®®ä½¿ç”¨æœç´¢å·¥å…·è·å–æœ€æ–°ä¿¡æ¯ã€‚"
    
    async def _handle_tool_results(self, original_question: str, reasoning: str, 
                                   tool_calls: List[Dict], tool_results: List[Dict], **kwargs) -> str:
        """å¤„ç†å·¥å…·è°ƒç”¨ç»“æœå¹¶ç”Ÿæˆæœ€ç»ˆå›ç­”
        
        Args:
            original_question: åŸå§‹ç”¨æˆ·é—®é¢˜
            reasoning: æ¨ç†å†…å®¹
            tool_calls: å·¥å…·è°ƒç”¨åˆ—è¡¨
            tool_results: å·¥å…·è°ƒç”¨ç»“æœåˆ—è¡¨
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            str: æœ€ç»ˆå›ç­”
        """
        logger.info(f"å¤„ç†å·¥å…·è°ƒç”¨ç»“æœ - å·¥å…·æ•°: {len(tool_calls)}, ç»“æœæ•°: {len(tool_results)}")
        
        # æ„å»ºå·¥å…·è°ƒç”¨åŠç»“æœçš„è¯¦ç»†æè¿°
        tools_info = ""
        for i, (tool_call, tool_result) in enumerate(zip(tool_calls, tool_results), 1):
            func = tool_call.get("function", {})
            tool_name = func.get("name", "æœªçŸ¥å·¥å…·")
            tool_args = func.get("arguments", "{}")
            
            # å°è¯•è§£æå‚æ•°ä¸ºæ›´å¯è¯»çš„æ ¼å¼
            try:
                args_dict = json.loads(tool_args) if isinstance(tool_args, str) else tool_args
                args_str = json.dumps(args_dict, ensure_ascii=False, indent=2)
            except:
                args_str = str(tool_args)
                
            # å¤„ç†ç»“æœ
            result_content = tool_result.get("content", "")
            
            tools_info += f"""
å·¥å…· {i}: {tool_name}
å‚æ•°:
{args_str}

ç»“æœ:
{result_content}
"""

        # æ„å»ºå®Œæ•´æç¤º
        prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆä¸€ä¸ªå®Œæ•´ã€å‡†ç¡®çš„å›ç­”ï¼š

ç”¨æˆ·é—®é¢˜: {original_question}

æ€è€ƒè¿‡ç¨‹:
{reasoning}

å·¥å…·è°ƒç”¨ç»“æœ:
{tools_info}

è¦æ±‚ï¼š
1. ç›´æ¥ä½¿ç”¨å·¥å…·è¿”å›çš„æ•°æ®å›ç­”é—®é¢˜
2. ç¡®ä¿å›ç­”å®Œå…¨è§£å†³ç”¨æˆ·çš„é—®é¢˜
3. ä½¿ç”¨æ¸…æ™°ã€æ˜“æ‡‚çš„è¯­è¨€
4. å¦‚æœå·¥å…·ç»“æœä¸å®Œæ•´æˆ–æœ‰é”™è¯¯ï¼Œè¦è¯´æ˜æƒ…å†µ
5. å›ç­”è¦æœ‰é€»è¾‘æ€§å’Œè¿è´¯æ€§
6. å¿…è¦æ—¶å¯ä»¥ç»“åˆå¤šä¸ªå·¥å…·çš„ç»“æœ"""
        
        logger.info("å‘Claudeå‘é€å·¥å…·ç»“æœæç¤ºç”Ÿæˆæœ€ç»ˆå›ç­”")
        
        # å‘Claudeå‘é€è¯·æ±‚ç”Ÿæˆæœ€ç»ˆå›ç­”
        response = await self.claude_client.chat(
            messages=[{"role": "user", "content": prompt}],
            **self._prepare_answerer_kwargs(kwargs)
        )
        
        if "choices" in response and response["choices"]:
            answer = response["choices"][0]["message"]["content"]
            logger.info(f"ç”Ÿæˆæœ€ç»ˆå›ç­”æˆåŠŸ: {answer[:100]}...")
            return answer
        else:
            logger.warning("ç”Ÿæˆæœ€ç»ˆå›ç­”å¤±è´¥")
            return "æŠ±æ­‰ï¼Œæ— æ³•å¤„ç†å·¥å…·è°ƒç”¨ç»“æœã€‚"

    def _format_tool_decision_prompt(self, original_question: str, reasoning: str, tools: List[Dict]) -> str:
        """æ ¼å¼åŒ–å·¥å…·å†³ç­–æç¤ºï¼Œç”¨äºClaudeåˆ¤æ–­æ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·
        
        Args:
            original_question: åŸå§‹ç”¨æˆ·é—®é¢˜
            reasoning: æ¨ç†å†…å®¹
            tools: å¯ç”¨å·¥å…·åˆ—è¡¨
            
        Returns:
            str: æ ¼å¼åŒ–çš„æç¤ºæ–‡æœ¬
        """
        # æå–å·¥å…·æè¿°
        tools_description = ""
        for i, tool in enumerate(tools, 1):
            if "function" in tool:
                function = tool["function"]
                name = function.get("name", "æœªå‘½åå·¥å…·")
                description = function.get("description", "æ— æè¿°")
                
                # æå–å‚æ•°ä¿¡æ¯
                parameters = function.get("parameters", {})
                required = parameters.get("required", [])
                properties = parameters.get("properties", {})
                
                param_desc = ""
                for param_name, param_info in properties.items():
                    is_required = "å¿…å¡«" if param_name in required else "å¯é€‰"
                    param_type = param_info.get("type", "æœªçŸ¥ç±»å‹")
                    param_description = param_info.get("description", "æ— æè¿°")
                    param_desc += f"  - {param_name} ({param_type}, {is_required}): {param_description}\n"
                
                tools_description += f"{i}. å·¥å…·åç§°: {name}\n   æè¿°: {description}\n   å‚æ•°:\n{param_desc}\n"
        
        # æ„é€ å†³ç­–æç¤º
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªå·¥å…·è°ƒç”¨å†³ç­–ä¸“å®¶ã€‚è¯·åˆ†æç”¨æˆ·é—®é¢˜å’Œæ¨ç†å†…å®¹ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·è·å–é¢å¤–ä¿¡æ¯ã€‚

ç”¨æˆ·é—®é¢˜: {original_question}

æ¨ç†å†…å®¹:
{reasoning}

å¯ç”¨å·¥å…·:
{tools_description}

åˆ¤æ–­æ ‡å‡†:
1. å¦‚æœé—®é¢˜éœ€è¦å®æ—¶æ•°æ®ï¼ˆå¦‚å¤©æ°”ã€æœç´¢ç­‰ï¼‰ï¼Œå¿…é¡»ä½¿ç”¨ç›¸åº”å·¥å…·
2. å¦‚æœé—®é¢˜æ˜¯å…³äºå¸¸è¯†æˆ–å¯ä»¥é€šè¿‡æ¨ç†è§£å†³ï¼Œåˆ™ä¸éœ€è¦å·¥å…·
3. å¦‚æœæ¨ç†å†…å®¹å·²æä¾›è¶³å¤Ÿä¿¡æ¯ï¼Œåˆ™ä¸éœ€è¦å·¥å…·

å¦‚æœéœ€è¦ä½¿ç”¨å·¥å…·ï¼Œè¯·ç›´æ¥è¿”å›å·¥å…·è°ƒç”¨è¯·æ±‚ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{{
  "tool_calls": [
    {{
      "id": "call_xxxxx",  // 8ä½å”¯ä¸€ID
      "type": "function",
      "function": {{
        "name": "å·¥å…·åç§°",
        "arguments": {{
          // å…·ä½“å‚æ•°
        }}
      }}
    }}
  ]
}}

æ³¨æ„äº‹é¡¹:
1. åªåœ¨ç¡®å®éœ€è¦é¢å¤–ä¿¡æ¯æ—¶æ‰ä½¿ç”¨å·¥å…·
2. å‚æ•°å€¼å¿…é¡»æ˜¯å…·ä½“çš„å€¼ï¼Œä¸è¦ä½¿ç”¨å ä½ç¬¦
3. å¿…é¡»æä¾›æ‰€æœ‰å¿…å¡«å‚æ•°
4. å‚æ•°å€¼è¦ç¬¦åˆå®é™…åœºæ™¯ï¼Œå¦‚åŸå¸‚åã€æ—¥æœŸç­‰
5. å·¥å…·è°ƒç”¨IDå¿…é¡»æ˜¯å”¯ä¸€çš„8ä½å­—ç¬¦ä¸²
6. è¿”å›çš„å¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼"""
        
        logger.info(f"ç”Ÿæˆå·¥å…·å†³ç­–æç¤º - é—®é¢˜: '{original_question[:30]}...'")
        return prompt

    def _format_tool_call_response(self, tool_call: Dict, **kwargs) -> bytes:
        """æ ¼å¼åŒ–å·¥å…·è°ƒç”¨å“åº”ï¼Œç¡®ä¿å®Œå…¨ç¬¦åˆOpenAI APIè§„èŒƒ
        
        Args:
            tool_call: å·¥å…·è°ƒç”¨ä¿¡æ¯
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            bytes: æ ¼å¼åŒ–çš„SSEå“åº”
        """
        try:
            # ç¡®ä¿å·¥å…·è°ƒç”¨IDå­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®
            tool_call_id = tool_call.get("id")
            if not tool_call_id or not isinstance(tool_call_id, str) or len(tool_call_id) < 8:
                tool_call_id = f"call_{uuid.uuid4().hex[:8]}"
            
            # ç¡®ä¿å‡½æ•°åå’Œå‚æ•°æ ¼å¼æ­£ç¡®
            function = tool_call.get("function", {})
            function_name = function.get("name", "")
            function_args = function.get("arguments", "{}")
            
            # å¦‚æœå‚æ•°ä¸æ˜¯å­—ç¬¦ä¸²æ ¼å¼ï¼Œè½¬æ¢ä¸ºæ­£ç¡®çš„JSONå­—ç¬¦ä¸²
            if not isinstance(function_args, str):
                try:
                    function_args = json.dumps(function_args, ensure_ascii=False)
                except Exception as e:
                    logger.error(f"å‚æ•°åºåˆ—åŒ–å¤±è´¥: {e}")
                    function_args = "{}"
            
            # æ„é€ æ ‡å‡†çš„OpenAI APIå“åº”æ ¼å¼
            response = {
                "id": kwargs.get("chat_id", f"chatcmpl-{uuid.uuid4()}"),
                "object": "chat.completion.chunk",
                "created": kwargs.get("created_time", int(time.time())),
                "model": kwargs.get("model", "deepclaude"),
                "choices": [{
                    "index": 0,
                    "delta": {
                        "role": "assistant",
                        "content": None,
                        "tool_calls": [
                            {
                                "index": 0,
                                "id": tool_call_id,
                                "type": "function",
                                "function": {
                                    "name": function_name,
                                    "arguments": function_args
                                }
                            }
                        ]
                    },
                    "finish_reason": "tool_calls"
                }]
            }
            
            logger.info(f"å·¥å…·è°ƒç”¨å“åº”æ ¼å¼åŒ–å®Œæˆ - å·¥å…·: {function_name}, ID: {tool_call_id}")
            return f"data: {json.dumps(response, ensure_ascii=False)}\n\n".encode('utf-8')
            
        except Exception as e:
            logger.error(f"å·¥å…·è°ƒç”¨å“åº”æ ¼å¼åŒ–å¤±è´¥: {e}")
            # è¿”å›ä¸€ä¸ªé”™è¯¯å“åº”
            error_response = {
                "id": kwargs.get("chat_id", f"chatcmpl-{uuid.uuid4()}"),
                "object": "chat.completion.chunk",
                "created": kwargs.get("created_time", int(time.time())),
                "model": kwargs.get("model", "deepclaude"),
                "choices": [{
                    "index": 0,
                    "delta": {
                        "role": "assistant",
                        "content": f"å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}"
                    },
                    "finish_reason": "error"
                }]
            }
            return f"data: {json.dumps(error_response, ensure_ascii=False)}\n\n".encode('utf-8')
    
    def _format_tool_result_response(self, tool_result: Dict, **kwargs) -> bytes:
        """æ ¼å¼åŒ–å·¥å…·ç»“æœå“åº”ï¼Œç”¨äºæµå¼è¾“å‡º
        
        Args:
            tool_result: å·¥å…·æ‰§è¡Œç»“æœ
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            bytes: æ ¼å¼åŒ–çš„SSEå“åº”
        """
        try:
            # éªŒè¯å·¥å…·ç»“æœæ ¼å¼
            if not isinstance(tool_result, dict):
                raise ValueError("å·¥å…·ç»“æœå¿…é¡»æ˜¯å­—å…¸æ ¼å¼")
            
            tool_call_id = tool_result.get("tool_call_id")
            if not tool_call_id:
                raise ValueError("å·¥å…·ç»“æœå¿…é¡»åŒ…å«tool_call_id")
            
            content = tool_result.get("content")
            if content is None:
                raise ValueError("å·¥å…·ç»“æœå¿…é¡»åŒ…å«content")
            
            # æ„é€ æ ‡å‡†çš„OpenAI APIå“åº”æ ¼å¼
            response = {
                "id": kwargs.get("chat_id", f"chatcmpl-{uuid.uuid4()}"),
                "object": "chat.completion.chunk",
                "created": kwargs.get("created_time", int(time.time())),
                "model": kwargs.get("model", "deepclaude"),
                "choices": [{
                    "index": 0,
                    "delta": {
                        "role": "tool",
                        "content": content,
                        "tool_call_id": tool_call_id
                    },
                    "finish_reason": None
                }]
            }
            
            logger.info(f"å·¥å…·ç»“æœå“åº”æ ¼å¼åŒ–å®Œæˆ - ID: {tool_call_id}")
            return f"data: {json.dumps(response, ensure_ascii=False)}\n\n".encode('utf-8')
            
        except Exception as e:
            logger.error(f"å·¥å…·ç»“æœå“åº”æ ¼å¼åŒ–å¤±è´¥: {e}")
            # è¿”å›ä¸€ä¸ªé”™è¯¯å“åº”
            error_response = {
                "id": kwargs.get("chat_id", f"chatcmpl-{uuid.uuid4()}"),
                "object": "chat.completion.chunk",
                "created": kwargs.get("created_time", int(time.time())),
                "model": kwargs.get("model", "deepclaude"),
                "choices": [{
                    "index": 0,
                    "delta": {
                        "role": "assistant",
                        "content": f"å·¥å…·ç»“æœå¤„ç†å¤±è´¥: {str(e)}"
                    },
                    "finish_reason": "error"
                }]
            }
            return f"data: {json.dumps(error_response, ensure_ascii=False)}\n\n".encode('utf-8')

    def _validate_tool(self, tool: Dict) -> Tuple[bool, str, Optional[Dict]]:
        """éªŒè¯å·¥å…·æ ¼å¼å¹¶å°è¯•ä¿®å¤
        
        Args:
            tool: å·¥å…·é…ç½®å­—å…¸
            
        Returns:
            Tuple[bool, str, Optional[Dict]]: 
                - æ˜¯å¦æœ‰æ•ˆ
                - é”™è¯¯ä¿¡æ¯
                - ä¿®å¤åçš„å·¥å…·é…ç½®ï¼ˆå¦‚æœå¯ä»¥ä¿®å¤ï¼‰
        """
        if not isinstance(tool, dict):
            return False, f"å·¥å…·å¿…é¡»æ˜¯å­—å…¸æ ¼å¼ï¼Œå½“å‰ç±»å‹: {type(tool)}", None
            
        # æ£€æŸ¥å¿…è¦å­—æ®µ
        if "function" not in tool and "type" not in tool:
            return False, "å·¥å…·ç¼ºå°‘å¿…è¦å­—æ®µ 'function' æˆ– 'type'", None
            
        # å¦‚æœæ˜¯ type æ ¼å¼ï¼Œå°è¯•è½¬æ¢ä¸º function æ ¼å¼
        if "type" in tool and tool["type"] in ["function", "tool"]:
            function_field = "function" if tool["type"] == "function" else "parameters"
            if function_field in tool:
                tool = {
                    "function": tool[function_field]
                }
                
        # éªŒè¯ function å­—æ®µ
        function = tool.get("function", {})
        if not isinstance(function, dict):
            return False, f"function å¿…é¡»æ˜¯å­—å…¸æ ¼å¼ï¼Œå½“å‰ç±»å‹: {type(function)}", None
            
        # æ£€æŸ¥å¿…è¦çš„ function å­—æ®µ
        if "name" not in function:
            return False, "function ç¼ºå°‘å¿…è¦å­—æ®µ 'name'", None
            
        # éªŒè¯å‚æ•°æ ¼å¼
        parameters = function.get("parameters", {})
        if not isinstance(parameters, dict):
            return False, f"parameters å¿…é¡»æ˜¯å­—å…¸æ ¼å¼ï¼Œå½“å‰ç±»å‹: {type(parameters)}", None
            
        # å°è¯•ä¿®å¤å¸¸è§é—®é¢˜
        fixed_tool = {
            "function": {
                "name": function.get("name", ""),
                "description": function.get("description", ""),
                "parameters": {
                    "type": parameters.get("type", "object"),
                    "properties": parameters.get("properties", {}),
                    "required": parameters.get("required", [])
                }
            }
        }
        
        return True, "", fixed_tool
        
    def _validate_and_convert_tools(self, tools: List[Dict], target_format: str = 'claude-3') -> List[Dict]:
        """éªŒè¯å¹¶è½¬æ¢å·¥å…·åˆ—è¡¨
        
        Args:
            tools: åŸå§‹å·¥å…·åˆ—è¡¨
            target_format: ç›®æ ‡æ ¼å¼
            
        Returns:
            List[Dict]: éªŒè¯å¹¶è½¬æ¢åçš„å·¥å…·åˆ—è¡¨
        """
        if not tools:
            return []
            
        valid_tools = []
        for tool in tools:
            # éªŒè¯å·¥å…·æ ¼å¼
            is_valid, error_msg, fixed_tool = self._validate_tool(tool)
            if not is_valid:
                logger.warning(f"å·¥å…·éªŒè¯å¤±è´¥: {error_msg}")
                continue
                
            tool_to_use = fixed_tool or tool
            
            # æ£€æŸ¥å·¥å…·æ˜¯å¦åœ¨æ”¯æŒåˆ—è¡¨ä¸­
            func = tool_to_use.get("function", {})
            if func.get("name") in self.supported_tools:
                # è½¬æ¢ä¸ºç›®æ ‡æ ¼å¼
                format_config = self.tool_format_mapping.get(target_format)
                if format_config:
                    converted_tool = {
                        'type': format_config['type'],
                        format_config['function_field']: func
                    }
                    valid_tools.append(converted_tool)
                    logger.info(f"å·¥å…· {func.get('name')} éªŒè¯æˆåŠŸå¹¶è½¬æ¢ä¸º {target_format} æ ¼å¼")
                else:
                    valid_tools.append(tool_to_use)
                    logger.info(f"å·¥å…· {func.get('name')} éªŒè¯æˆåŠŸï¼Œä¿æŒåŸå§‹æ ¼å¼")
            else:
                logger.warning(f"å·¥å…· {func.get('name')} ä¸åœ¨æ”¯æŒåˆ—è¡¨ä¸­")
                
        return valid_tools