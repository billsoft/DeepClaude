"""DeepClaude æœåŠ¡ï¼Œç”¨äºåè°ƒ DeepSeek å’Œ Claude API çš„è°ƒç”¨

ä¸»è¦åŠŸèƒ½ï¼š
1. é›†æˆ DeepSeek å’Œ Claude ä¸¤ä¸ªå¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›
2. æ”¯æŒæµå¼å’Œéæµå¼ä¸¤ç§è¾“å‡ºæ¨¡å¼
3. å®ç° DeepSeek æ¨ç†ç»“æœä½œä¸º Claude è¾“å…¥çš„ä¸²è”è°ƒç”¨
4. æä¾›ç¬¦åˆ OpenAI API æ ¼å¼çš„æ ‡å‡†è¾“å‡º

å·¥ä½œæµç¨‹ï¼š
1. æ¥æ”¶ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯å’Œæ¨¡å‹å‚æ•°
2. è°ƒç”¨ DeepSeek è¿›è¡Œæ¨ç†ï¼Œè·å–æ¨ç†è¿‡ç¨‹
3. å°†æ¨ç†ç»“æœä¼ é€’ç»™ Claude è¿›è¡Œå¤„ç†
4. æ•´åˆè¾“å‡ºç»“æœå¹¶è¿”å›ç»™ç”¨æˆ·

æŠ€æœ¯ç‰¹ç‚¹ï¼š
1. ä½¿ç”¨å¼‚æ­¥ç¼–ç¨‹æé«˜å¹¶å‘æ€§èƒ½
2. é‡‡ç”¨é˜Ÿåˆ—æœºåˆ¶å®ç°æ•°æ®æµè½¬
3. æ”¯æŒæµå¼è¾“å‡ºæå‡ç”¨æˆ·ä½“éªŒ
4. å®Œå–„çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
"""
import json
import time
import tiktoken
import asyncio
import uuid
import re  # æ·»åŠ æ­£åˆ™è¡¨è¾¾å¼æ¨¡å—
from typing import AsyncGenerator, Dict, List, Any, Optional, Tuple
from app.utils.logger import logger
from app.clients import DeepSeekClient, ClaudeClient, OllamaR1Client
from app.utils.message_processor import MessageProcessor
import aiohttp
import os
from dotenv import load_dotenv
import sys
import logging
import requests
from datetime import datetime

# æ•°æ®åº“ç›¸å…³å¯¼å…¥
from app.database.db_operations import DatabaseOperations
from app.database.db_utils import add_reasoning_column_if_not_exists

load_dotenv()

class DeepClaude:
    """å¤„ç† DeepSeek å’Œ Claude API çš„æµå¼è¾“å‡ºè¡”æ¥
    
    è¯¥ç±»è´Ÿè´£åè°ƒ DeepSeek å’Œ Claude ä¸¤ä¸ªæ¨¡å‹çš„è°ƒç”¨è¿‡ç¨‹ï¼Œä¸»è¦ç‰¹ç‚¹ï¼š
    1. æ”¯æŒæµå¼å’Œéæµå¼ä¸¤ç§è¾“å‡ºæ¨¡å¼
    2. å®ç° DeepSeek æ¨ç†å’Œ Claude å›ç­”çš„ä¸²è”è°ƒç”¨
    3. æä¾›æ ‡å‡†çš„ OpenAI æ ¼å¼è¾“å‡º
    4. æ”¯æŒå¤šç§ API æä¾›å•†é…ç½®
    
    ä¸»è¦ç»„ä»¶ï¼š
    - DeepSeekå®¢æˆ·ç«¯ï¼šè´Ÿè´£è°ƒç”¨ DeepSeek API è·å–æ¨ç†è¿‡ç¨‹
    - Claudeå®¢æˆ·ç«¯ï¼šè´Ÿè´£è°ƒç”¨ Claude API ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
    - å¼‚æ­¥é˜Ÿåˆ—ï¼šç”¨äºæ•°æ®æµè½¬å’Œä»»åŠ¡åè°ƒ
    - OllamaR1Clientï¼šè´Ÿè´£è°ƒç”¨ OllamaR1 API ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
    - å¼‚æ­¥é˜Ÿåˆ—ï¼šç”¨äºæ•°æ®æµè½¬å’Œä»»åŠ¡åè°ƒ
    
    å·¥ä½œæ¨¡å¼ï¼š
    1. æµå¼æ¨¡å¼ï¼šå®æ—¶è¿”å›æ¨ç†è¿‡ç¨‹å’Œç”Ÿæˆç»“æœ
    2. éæµå¼æ¨¡å¼ï¼šç­‰å¾…å®Œæ•´ç»“æœåä¸€æ¬¡æ€§è¿”å›
    """
    def __init__(self, **kwargs):
        """åˆå§‹åŒ–DeepClaudeæœåŠ¡
        
        Args:
            **kwargs: å…³é”®å­—å‚æ•°
                save_to_db: æ˜¯å¦ä¿å­˜åˆ°æ•°æ®åº“ï¼Œé»˜è®¤ä¸ºFalse
                db_ops: æ•°æ®åº“æ“ä½œå¯¹è±¡ï¼Œä»…åœ¨save_to_dbä¸ºTrueæ—¶ä½¿ç”¨
                clients: å®¢æˆ·ç«¯å¯¹è±¡ï¼Œç”¨äºæ‰‹åŠ¨æŒ‡å®šå®¢æˆ·ç«¯ï¼Œç”¨äºæµ‹è¯•
                enable_enhanced_reasoning: æ˜¯å¦å¯ç”¨å¢å¼ºæ¨ç†ï¼Œé»˜è®¤ä¸ºTrue
                claude_api_key: Claude APIå¯†é’¥
                claude_api_url: Claude API URL
                claude_provider: Claudeæä¾›å•†
                deepseek_api_key: DeepSeek APIå¯†é’¥
                deepseek_api_url: DeepSeek API URL
                deepseek_provider: DeepSeekæä¾›å•†
                ollama_api_url: Ollama API URL
                is_origin_reasoning: æ˜¯å¦ä½¿ç”¨åŸå§‹æ¨ç†æ ¼å¼
        """
        logger.info("åˆå§‹åŒ–DeepClaudeæœåŠ¡...")
        
        # ä¿å­˜ä¼ å…¥çš„é…ç½®å‚æ•°ï¼Œä»¥ä¾¿åœ¨å…¶ä»–æ–¹æ³•ä¸­ä½¿ç”¨
        self.claude_api_key = kwargs.get('claude_api_key', os.getenv('CLAUDE_API_KEY', ''))
        self.claude_api_url = kwargs.get('claude_api_url', os.getenv('CLAUDE_API_URL', 'https://api.anthropic.com/v1/messages'))
        self.claude_provider = kwargs.get('claude_provider', os.getenv('CLAUDE_PROVIDER', 'anthropic'))
        self.ollama_api_url = kwargs.get('ollama_api_url', os.getenv('OLLAMA_API_URL', ''))
        self.is_origin_reasoning = kwargs.get('is_origin_reasoning', os.getenv('IS_ORIGIN_REASONING', 'false').lower() == 'true')
        
        # æ¨ç†å†…å®¹å’Œæ¨¡å¼è®¾ç½®
        self.enable_enhanced_reasoning = kwargs.get('enable_enhanced_reasoning', True)
        self.min_reasoning_chars = 100  # æœ€å°æ¨ç†å­—ç¬¦æ•°é‡
        self.reasoning_modes = ["auto", "chain-of-thought", "zero-shot"]  # æ¨ç†æ¨¡å¼åˆ—è¡¨
        self.saved_reasoning = ""  # ä¿å­˜çš„æ¨ç†å†…å®¹ï¼Œç”¨äºè¯Šæ–­
        self.processor = MessageProcessor()  # æ¶ˆæ¯å¤„ç†å™¨
        
        # å®šä¹‰æ¨ç†æä¾›è€…
        self.reasoning_providers = {
            'deepseek': lambda: DeepSeekClient(
                api_key=kwargs.get('deepseek_api_key', os.getenv('DEEPSEEK_API_KEY', '')),
                api_url=kwargs.get('deepseek_api_url', os.getenv('DEEPSEEK_API_URL', '')),
                provider=os.getenv('DEEPSEEK_PROVIDER', 'deepseek')
            ),
            'siliconflow': lambda: DeepSeekClient(
                api_key=kwargs.get('deepseek_api_key', os.getenv('DEEPSEEK_API_KEY', '')),
                api_url=kwargs.get('deepseek_api_url', os.getenv('DEEPSEEK_API_URL', '')),
                provider='siliconflow'
            ),
            'nvidia': lambda: DeepSeekClient(
                api_key=kwargs.get('deepseek_api_key', os.getenv('DEEPSEEK_API_KEY', '')),
                api_url=kwargs.get('deepseek_api_url', os.getenv('DEEPSEEK_API_URL', '')),
                provider='nvidia'
            ),
            'ollama': lambda: OllamaR1Client(
                api_url=kwargs.get('ollama_api_url', os.getenv('OLLAMA_API_URL', ''))
            )
        }
        
        # æ”¯æŒçš„å·¥å…·åˆ—è¡¨ï¼Œä¸å®é™…æ‰§è¡Œè¿™äº›å·¥å…·ï¼Œåªè¿”å›æ ‡å‡†æ ¼å¼çš„å“åº”
        self.supported_tools = {
            "search": {
                "name": "search",
                "description": "æœç´¢ç½‘ç»œè·å–å®æ—¶ä¿¡æ¯",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "query": {
                            "type": "string",
                            "description": "æœç´¢æŸ¥è¯¢å†…å®¹"
                        }
                    },
                    "required": ["query"]
                }
            },
            "weather": {
                "name": "weather",
                "description": "è·å–å¤©æ°”ä¿¡æ¯",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "location": {
                            "type": "string",
                            "description": "åœ°ç‚¹åç§°ï¼Œå¦‚ï¼šåŒ—äº¬ã€ä¸Šæµ·"
                        },
                        "date": {
                            "type": "string",
                            "description": "æ—¥æœŸï¼Œå¦‚ï¼štodayã€tomorrow",
                            "enum": ["today", "tomorrow"]
                        }
                    },
                    "required": ["location"]
                }
            }
        }
        
        # æ·»åŠ å·¥å…·æ ¼å¼è½¬æ¢é…ç½®
        self.tool_format_mapping = {
            'gpt-4': {
                'type': 'function',
                'function_field': 'function'
            },
            'gpt-3.5-turbo': {
                'type': 'function',
                'function_field': 'function'
            },
            'claude-3': {
                'type': 'tool',
                'function_field': 'function'
            }
        }
        
        # æ•°æ®åº“ç›¸å…³è®¾ç½®
        self.save_to_db = kwargs.get('save_to_db', os.getenv('SAVE_TO_DB', 'false').lower() == 'true')
        if self.save_to_db:
            logger.info("å¯ç”¨æ•°æ®åº“å­˜å‚¨...")
            self.db_ops = kwargs.get('db_ops', DatabaseOperations())
            self.current_conversation_id = None
            # æ£€æŸ¥å¹¶æ·»åŠ reasoningåˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            add_reasoning_column_if_not_exists()
        else:
            logger.info("æ•°æ®åº“å­˜å‚¨å·²ç¦ç”¨")
            self.db_ops = None
            
        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        if 'clients' in kwargs:
            self.thinker_client = kwargs['clients'].get('thinker')
            self.claude_client = kwargs['clients'].get('claude')
        else:
            logger.info("åˆå§‹åŒ–æ€è€ƒè€…å®¢æˆ·ç«¯...")
            provider = self._get_reasoning_provider()
            self.thinker_client = provider
            
            logger.info("åˆå§‹åŒ–Claudeå®¢æˆ·ç«¯...")
            self.claude_client = ClaudeClient(
                api_key=self.claude_api_key,
                api_url=self.claude_api_url,
                provider=self.claude_provider
            )
        
        # éªŒè¯é…ç½®æœ‰æ•ˆæ€§
        self._validate_config()
        
        # é…ç½®æœç´¢å¢å¼º
        self.search_enabled = os.getenv('ENABLE_SEARCH_ENHANCEMENT', 'true').lower() == 'true'
        
        logger.info("DeepClaudeæœåŠ¡åˆå§‹åŒ–å®Œæˆ")
        
    def _get_reasoning_provider(self):
        """è·å–æ€è€ƒè€…å®ä¾‹"""
        provider = os.getenv('REASONING_PROVIDER', 'deepseek').lower()
        
        if provider not in self.reasoning_providers:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨ç†æä¾›è€…: {provider}")
            
        return self.reasoning_providers[provider]()

    async def _handle_stream_response(self, response_queue: asyncio.Queue, 
                                    chat_id: str, created_time: int, model: str) -> AsyncGenerator[bytes, None]:
        """å¤„ç†æµå¼å“åº”"""
        try:
            while True:
                item = await response_queue.get()
                if item is None:
                    break
                    
                content_type, content = item
                if content_type == "reasoning":
                    response = {
                        "id": chat_id,
                        "object": "chat.completion.chunk",
                        "created": created_time,
                        "model": model,
                        "is_reasoning": True,  # æ·»åŠ é¡¶å±‚æ ‡è®°
                        "choices": [{
                            "index": 0,
                            "delta": {
                                "role": "assistant",
                                "content": f"ğŸ¤” æ€è€ƒè¿‡ç¨‹:\n{content}\n",
                                "reasoning": True  # åœ¨deltaä¸­æ·»åŠ æ ‡è®°
                            }
                        }]
                    }
                elif content_type == "content":
                    response = {
                        "id": chat_id,
                        "object": "chat.completion.chunk",
                        "created": created_time,
                        "model": model,
                        "choices": [{
                            "index": 0,
                            "delta": {
                                "role": "assistant",
                                "content": f"\n\n---\næ€è€ƒå®Œæ¯•ï¼Œå¼€å§‹å›ç­”ï¼š\n\n{content}"
                            }
                        }]
                    }
                yield f"data: {json.dumps(response)}\n\n".encode('utf-8')
        except Exception as e:
            logger.error(f"å¤„ç†æµå¼å“åº”æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
            raise

    async def _handle_api_error(self, e: Exception) -> str:
        """å¤„ç† API é”™è¯¯"""
        if isinstance(e, aiohttp.ClientError):
            return "ç½‘ç»œè¿æ¥é”™è¯¯ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥"
        elif isinstance(e, asyncio.TimeoutError):
            return "è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•"
        elif isinstance(e, ValueError):
            return f"å‚æ•°é”™è¯¯: {str(e)}"
        else:
            return f"æœªçŸ¥é”™è¯¯: {str(e)}"

    async def chat_completions_with_stream(self, messages: list, tools: list = None, tool_choice = "auto", **kwargs):
        """å¤„ç†æµå¼è¯·æ±‚ï¼Œæ”¯æŒæ€è€ƒ-å›ç­”æ¨¡å¼å’Œå·¥å…·è°ƒç”¨

        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
            tools: å·¥å…·åˆ—è¡¨
            tool_choice: å·¥å…·é€‰æ‹©ç­–ç•¥
            **kwargs: å…¶ä»–å‚æ•°

        Yields:
            bytes: æµå¼å“åº”æ•°æ®
        """
        # åˆå§‹åŒ–å˜é‡
        chat_id = kwargs.get("chat_id", f"chatcmpl-{uuid.uuid4()}")
        created_time = kwargs.get("created_time", int(time.time()))
        model_name = kwargs.get("model", "deepclaude")
        claude_model = os.getenv('CLAUDE_MODEL', 'claude-3-7-sonnet-20250219')
        deepseek_model = kwargs.get("deepseek_model", "deepseek-reasoner")
        model_arg = tuple(map(float, os.getenv('MODEL_ARG', '1.0,1.0,0.7,0.1').split(',')))
        model = kwargs.get("model", "deepclaude")

        try:
            logger.info("å¼€å§‹æµå¼å¤„ç†è¯·æ±‚...")
            logger.debug(f"è¾“å…¥æ¶ˆæ¯: {messages}")
            
            # é…ç½®ç›´æ¥é€ä¼ æ¨¡å¼
            direct_tool_pass = os.getenv('CLAUDE_DIRECT_TOOL_PASS', 'true').lower() == 'true'
            
            # å¦‚æœå¯ç”¨ç›´æ¥é€ä¼ ä¸”æœ‰å·¥å…·ï¼Œç›´æ¥ä½¿ç”¨Claudeå¤„ç†
            if direct_tool_pass and tools and len(tools) > 0:
                logger.info(f"ç›´æ¥é€ä¼ æ¨¡å¼(éæµå¼): åŒ…å« {len(tools)} ä¸ªå·¥å…·")
                
                # è®°å½•å·¥å…·é€‰æ‹©ç­–ç•¥
                if isinstance(tool_choice, str):
                    logger.info(f"å·¥å…·é€‰æ‹©ç­–ç•¥: {tool_choice}")
                elif isinstance(tool_choice, dict):
                    logger.info(f"å·¥å…·é€‰æ‹©ç­–ç•¥: {json.dumps(tool_choice, ensure_ascii=False)}")
                else:
                    logger.info(f"å·¥å…·é€‰æ‹©ç­–ç•¥: {tool_choice}")
                
                # è½¬æ¢å·¥å…·æ ¼å¼
                converted_tools = self._validate_and_convert_tools(tools, target_format='claude-3')
                
                if not converted_tools:
                    logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„å·¥å…·å¯ç”¨ï¼Œå°†ä½œä¸ºæ™®é€šå¯¹è¯å¤„ç†")
                    result = {
                        "id": chat_id,
                        "object": "chat.completion",
                        "created": created_time,
                        "model": model,
                        "choices": [{
                            "index": 0,
                            "message": {
                                "role": "assistant",
                                "content": "æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å·¥å…·å®šä¹‰ï¼Œå°†ä½œä¸ºæ™®é€šå¯¹è¯å¤„ç†ã€‚"
                            },
                            "finish_reason": "stop"
                        }]
                    }
                    yield f"data: {json.dumps(result, ensure_ascii=False)}\n\ndata: [DONE]\n\n".encode("utf-8")
                    return
                
                logger.info(f"ç›´æ¥ä½¿ç”¨Claudeæ¨¡å‹: {claude_model}")
                
                # å‡†å¤‡Claudeè°ƒç”¨å‚æ•°
                claude_kwargs = {
                    "messages": messages,
                    "model": claude_model,
                    "temperature": kwargs.get("temperature", 0.7),
                    "top_p": kwargs.get("top_p", 0.9),
                    "tools": converted_tools
                }
                
                # å·¥å…·é€‰æ‹©ç­–ç•¥è½¬æ¢
                if isinstance(tool_choice, str):
                    if tool_choice == "auto":
                        claude_kwargs["tool_choice"] = {"type": "auto"}
                    elif tool_choice == "none":
                        # Claudeä¸æ”¯æŒnoneï¼Œå°†ä½¿ç”¨ç©ºå·¥å…·åˆ—è¡¨
                        logger.info("æ£€æµ‹åˆ°'none'å·¥å…·é€‰æ‹©ç­–ç•¥ï¼Œå°†ä¸ä½¿ç”¨å·¥å…·")
                        claude_kwargs.pop("tools")
                elif isinstance(tool_choice, dict):
                    if tool_choice.get("type") == "function" and "function" in tool_choice:
                        # OpenAIæ ¼å¼è½¬ä¸ºClaudeæ ¼å¼
                        func_name = tool_choice["function"].get("name")
                        if func_name:
                            logger.info(f"æŒ‡å®šä½¿ç”¨å·¥å…·: {func_name}")
                            claude_kwargs["tool_choice"] = {
                                "type": "tool",
                                "name": func_name
                            }
                    else:
                        # å·²æ˜¯Claudeæ ¼å¼æˆ–å…¶ä»–æ ¼å¼
                        claude_kwargs["tool_choice"] = tool_choice
                
                try:
                    # éæµå¼è°ƒç”¨Claude API
                    response = await self.claude_client.chat(**claude_kwargs)
                    
                    # å¤„ç†å·¥å…·è°ƒç”¨å“åº”
                    if "tool_calls" in response:
                        tool_calls = response["tool_calls"]
                        logger.info(f"Claudeè¿”å›äº† {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")
                        
                        # æ„é€ æ ‡å‡†çš„OpenAIæ ¼å¼å“åº”
                        result = {
                            "id": chat_id,
                            "object": "chat.completion",
                            "created": created_time,
                            "model": model,
                            "choices": [{
                                "index": 0,
                                "message": {
                                    "role": "assistant",
                                    "content": None,
                                    "tool_calls": tool_calls
                                },
                                "finish_reason": "tool_calls"
                            }],
                            "usage": {
                                "prompt_tokens": response.get("usage", {}).get("prompt_tokens", 0),
                                "completion_tokens": response.get("usage", {}).get("completion_tokens", 0),
                                "total_tokens": response.get("usage", {}).get("total_tokens", 0)
                            }
                        }
                        yield f"data: {json.dumps(result, ensure_ascii=False)}\n\ndata: [DONE]\n\n".encode("utf-8")
                        return
                    else:
                        # å¤„ç†æ™®é€šå›ç­”å“åº”
                        content = response.get("content", "")
                        if not content and "choices" in response and response["choices"]:
                            content = response["choices"][0].get("message", {}).get("content", "")
                            
                        result = {
                            "id": chat_id,
                            "object": "chat.completion",
                            "created": created_time,
                            "model": model,
                            "choices": [{
                                "index": 0,
                                "message": {
                                    "role": "assistant",
                                    "content": content
                                },
                                "finish_reason": "stop"
                            }],
                            "usage": {
                                "prompt_tokens": response.get("usage", {}).get("prompt_tokens", 0),
                                "completion_tokens": response.get("usage", {}).get("completion_tokens", 0),
                                "total_tokens": response.get("usage", {}).get("total_tokens", 0)
                            }
                        }
                        yield f"data: {json.dumps(result, ensure_ascii=False)}\n\ndata: [DONE]\n\n".encode("utf-8")
                        return
                except Exception as e:
                    logger.error(f"ç›´æ¥é€ä¼ æ¨¡å¼ä¸‹APIè°ƒç”¨å¤±è´¥: {e}", exc_info=True)
                    # æ­¤å¤„é€‰æ‹©å›é€€åˆ°æ¨ç†-å›ç­”æ¨¡å¼ï¼Œè€Œä¸æ˜¯ç«‹å³è¿”å›é”™è¯¯
                    logger.info("å°†å°è¯•ä½¿ç”¨æ¨ç†-å›ç­”æ¨¡å¼å¤„ç†è¯·æ±‚")
        except Exception as e:
            logger.error(f"å¤„ç†æµå¼è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
            error_response = {
                "error": {
                    "message": str(e),
                    "type": "server_error",
                    "code": "internal_error"
                }
            }
            yield f"data: {json.dumps(error_response, ensure_ascii=False)}\n\ndata: [DONE]\n\n".encode("utf-8")
            return
        
        # ä¿å­˜å¯¹è¯åˆ°æ•°æ®åº“ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.save_to_db:
            try:
                user_id = None
                if messages and 'content' in messages[-1]:
                    title = messages[-1]['content'][:20] + "..."
                    user_question = messages[-1]['content']
                else:
                    title = None
                    user_question = "æœªæä¾›é—®é¢˜å†…å®¹"
                    
                self.current_conversation_id = self.db_ops.create_conversation(
                    user_id=user_id,
                    title=title
                )
                logger.info(f"åˆ›å»ºæ–°å¯¹è¯ï¼ŒID: {self.current_conversation_id}")
                
                self.db_ops.add_conversation_history(
                    conversation_id=self.current_conversation_id,
                    role="user",
                    content=user_question
                )
                logger.info("ç”¨æˆ·é—®é¢˜å·²ä¿å­˜åˆ°æ•°æ®åº“")
            except Exception as db_e:
                logger.error(f"ä¿å­˜å¯¹è¯æ•°æ®å¤±è´¥: {db_e}")
        
        # è·å–åŸå§‹é—®é¢˜
        original_question = messages[-1]["content"] if messages and messages[-1]["role"] == "user" else ""
        
        # è·å–æ¨ç†å†…å®¹
        logger.info("æ­£åœ¨è·å–æ¨ç†å†…å®¹...")
        try:
            reasoning = await self._get_reasoning_content(
                messages=messages,
                model=deepseek_model,
                model_arg=model_arg
            )
        except Exception as e:
            logger.error(f"è·å–æ¨ç†å†…å®¹å¤±è´¥: {e}")
            reasoning = "æ— æ³•è·å–æ¨ç†å†…å®¹"
            
            # å°è¯•ä½¿ç”¨ä¸åŒçš„æ¨ç†æ¨¡å¼
            for reasoning_mode in self.reasoning_modes[1:]:
                try:
                    logger.info(f"å°è¯•ä½¿ç”¨ä¸åŒçš„æ¨ç†æ¨¡å¼è·å–å†…å®¹: {reasoning_mode}")
                    os.environ["DEEPSEEK_REASONING_MODE"] = reasoning_mode
                    reasoning = await self._get_reasoning_content(
                        messages=messages,
                        model=deepseek_model,
                        model_arg=model_arg
                    )
                    if reasoning and len(reasoning) > self.min_reasoning_chars:
                        logger.info(f"ä½¿ç”¨æ¨ç†æ¨¡å¼ {reasoning_mode} æˆåŠŸè·å–æ¨ç†å†…å®¹")
                        break
                except Exception as retry_e:
                    logger.error(f"ä½¿ç”¨æ¨ç†æ¨¡å¼ {reasoning_mode} é‡è¯•å¤±è´¥: {retry_e}")
        
        logger.debug(f"è·å–åˆ°æ¨ç†å†…å®¹: {reasoning[:min(500, len(reasoning))]}...")
        
        # å·¥å…·è°ƒç”¨å¤„ç†
        has_tool_decision = False
        tool_calls = []
        
        if tools and len(tools) > 0:
            try:
                # æœç´¢å¢å¼º
                search_hint = ""
                if self.search_enabled and messages and messages[-1]["role"] == "user":
                    search_hint = await self._enhance_with_search(messages[-1]["content"])
                if search_hint:
                    reasoning = f"{search_hint}\n\n{reasoning}"
                
                # å·¥å…·å†³ç­–
                decision_prompt = self._format_tool_decision_prompt(original_question, reasoning, tools)
                logger.debug(f"å·¥å…·å†³ç­–æç¤º: {decision_prompt[:200]}...")
                
                tool_decision_response = await self.claude_client.chat(
                    messages=[{"role": "user", "content": decision_prompt}],
                    model=claude_model,
                    tools=tools,
                    tool_choice=tool_choice,
                    temperature=model_arg[0],
                    top_p=model_arg[1]
                )
                
                # å¤„ç†å·¥å…·è°ƒç”¨å†³ç­–
                if "tool_calls" in tool_decision_response:
                    tool_calls = tool_decision_response.get("tool_calls", [])
                    has_tool_decision = True
                    logger.info(f"Claudeå†³å®šä½¿ç”¨å·¥å…·: {len(tool_calls)}ä¸ªå·¥å…·è°ƒç”¨")
                    
                    # æ„é€ å·¥å…·è°ƒç”¨å“åº”
                    response = {
                        "id": chat_id,
                        "object": "chat.completion",
                        "created": created_time,
                        "model": model,
                        "choices": [{
                            "index": 0,
                            "message": {
                                "role": "assistant",
                                "content": None,
                                "tool_calls": tool_calls
                            },
                            "finish_reason": "tool_calls"
                        }]
                    }
                    yield f"data: {json.dumps(response, ensure_ascii=False)}\n\ndata: [DONE]\n\n".encode("utf-8")
                    return
            except Exception as tool_e:
                logger.error(f"å·¥å…·è°ƒç”¨æµç¨‹å¤±è´¥: {tool_e}", exc_info=True)
        
        # ç”Ÿæˆæ™®é€šå›ç­”
        if not has_tool_decision:
            # æ„å»ºæœ€ç»ˆæç¤º
            combined_content = f"""è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜å’Œæ€è€ƒè¿‡ç¨‹æä¾›æœ€ä½³å›ç­”:

ç”¨æˆ·é—®é¢˜: {original_question}

æ€è€ƒè¿‡ç¨‹: 
{reasoning}

è¦æ±‚:
1. ç›´æ¥å›ç­”é—®é¢˜ï¼Œä¸è¦è¯´"æ ¹æ®æ€è€ƒè¿‡ç¨‹"ä¹‹ç±»çš„å¼•ç”¨
2. ä»¥æ¸…æ™°ã€å‡†ç¡®ã€æœ‰å¸®åŠ©çš„æ–¹å¼å›ç­”
3. å¦‚æœæ€è€ƒè¿‡ç¨‹ä¸­æœ‰ä¸ç¡®å®šæ€§ï¼Œè¦æ˜ç¡®æŒ‡å‡º
4. ä½¿ç”¨é€‚å½“çš„è¯­æ°”å’Œç»“æ„
5. ä¸è¦é‡å¤æˆ–è§£é‡Šæ€è€ƒè¿‡ç¨‹"""

            # å‘é€æœ€ç»ˆæç¤ºåˆ°Claude
            claude_messages = [{"role": "user", "content": combined_content}]
            logger.info("æ­£åœ¨è·å– Claude å›ç­”...")
            
            try:
                # è·å–å®Œæ•´å›ç­”
                full_content = ""
                async for content_type, content in self.claude_client.stream_chat(
                    messages=claude_messages,
                    model=claude_model,
                    temperature=model_arg[0],
                    top_p=model_arg[1],
                    stream=False
                ):
                    if content_type in ["answer", "content"]:
                        logger.debug(f"è·å–åˆ° Claude å›ç­”: {content}")
                        full_content += content
                
                # ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if self.save_to_db and self.current_conversation_id:
                    try:
                        tokens = len(reasoning.split()) + len(full_content.split())
                        self.db_ops.add_conversation_history(
                            conversation_id=self.current_conversation_id,
                            role="ai",
                            content=full_content,
                            reasoning=reasoning,
                            model_name=claude_model,
                            tokens=tokens
                        )
                        logger.info("AIå›ç­”å’Œæ€è€ƒè¿‡ç¨‹å·²ä¿å­˜åˆ°æ•°æ®åº“")
                    except Exception as db_e:
                        logger.error(f"ä¿å­˜AIå›ç­”æ•°æ®å¤±è´¥: {db_e}")
                
                # æ„é€ å®Œæ•´å“åº”
                response = {
                    "id": chat_id,
                    "object": "chat.completion",
                    "created": created_time,
                    "model": model,
                    "choices": [{
                        "index": 0,
                        "message": {
                            "role": "assistant",
                            "content": full_content
                        },
                        "finish_reason": "stop"
                    }]
                }
                
                yield f"data: {json.dumps(response, ensure_ascii=False)}\n\ndata: [DONE]\n\n".encode("utf-8")
                return
            except Exception as e:
                logger.error(f"è·å– Claude å›ç­”å¤±è´¥: {e}")
                error_message = await self._handle_api_error(e)
                result = {
                    "id": chat_id,
                    "object": "chat.completion",
                    "created": created_time,
                    "model": model,
                    "choices": [{
                        "index": 0,
                        "message": {
                            "role": "assistant",
                            "content": f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {error_message}"
                        },
                        "finish_reason": "error"
                    }]
                }
                yield f"data: {json.dumps(result, ensure_ascii=False)}\n\ndata: [DONE]\n\n".encode("utf-8")
                return

    async def _get_reasoning_content(self, messages: list, model: str, **kwargs) -> str:
        """è·å–æ¨ç†å†…å®¹
        
        1. é¦–å…ˆå°è¯•ä½¿ç”¨é…ç½®çš„æ¨ç†æä¾›è€…
        2. å¦‚æœå¤±è´¥åˆ™å°è¯•åˆ‡æ¢åˆ°å¤‡ç”¨æä¾›è€…
        3. æ”¯æŒå¤šç§æ¨ç†æ¨¡å¼é‡è¯•
        """
        try:
            provider = self._get_reasoning_provider()
            reasoning_content = []
            content_received = False
            
            logger.info(f"å¼€å§‹è·å–æ€è€ƒå†…å®¹ï¼Œæ¨¡å‹: {model}, æ¨ç†æ¨¡å¼: {os.getenv('DEEPSEEK_REASONING_MODE', 'auto')}")
            
            async for content_type, content in provider.get_reasoning(
                messages=messages,
                model=model,
                model_arg=kwargs.get('model_arg')  # åªä¼ é€’å¿…è¦çš„å‚æ•°
            ):
                if content_type == "reasoning":
                    reasoning_content.append(content)
                    logger.debug(f"æ”¶åˆ°æ¨ç†å†…å®¹ï¼Œå½“å‰é•¿åº¦: {len(''.join(reasoning_content))}")
                elif content_type == "content" and not reasoning_content:
                    # å¦‚æœæ²¡æœ‰æ”¶é›†åˆ°æ¨ç†å†…å®¹ï¼Œä½†æ”¶åˆ°äº†å†…å®¹ï¼Œå°†å…¶ä¹Ÿè§†ä¸ºæ¨ç†
                    logger.info("æœªæ”¶é›†åˆ°æ¨ç†å†…å®¹ï¼Œå°†æ™®é€šå†…å®¹è§†ä¸ºæ¨ç†")
                    reasoning_content.append(f"åˆ†æ: {content}")
                    logger.debug(f"æ™®é€šå†…å®¹è½¬ä¸ºæ¨ç†å†…å®¹ï¼Œå½“å‰é•¿åº¦: {len(''.join(reasoning_content))}")
                elif content_type == "content":
                    # è®°å½•æ”¶åˆ°æ™®é€šå†…å®¹ï¼Œè¿™é€šå¸¸è¡¨ç¤ºæ¨ç†é˜¶æ®µç»“æŸ
                    content_received = True
                    logger.info("æ”¶åˆ°æ™®é€šå†…å®¹ï¼Œæ¨ç†é˜¶æ®µå¯èƒ½å·²ç»“æŸ")
                
            result = "\n".join(reasoning_content)
            
            # å¦‚æœå·²æ”¶åˆ°æ™®é€šå†…å®¹ä¸”æ¨ç†å†…å®¹é•¿åº¦è¶³å¤Ÿï¼Œç›´æ¥è¿”å›
            if content_received and len(result) > self.min_reasoning_chars:
                logger.info(f"å·²æ”¶åˆ°æ™®é€šå†…å®¹ä¸”æ¨ç†å†…å®¹é•¿åº¦è¶³å¤Ÿ ({len(result)}å­—ç¬¦)ï¼Œç»“æŸè·å–æ¨ç†")
                return result
            
            # å¦‚æœå†…å®¹ä¸è¶³ï¼Œå°è¯•åˆ‡æ¢æ¨¡å¼é‡è¯•
            if not result or len(result) < self.min_reasoning_chars:
                current_mode = os.getenv('DEEPSEEK_REASONING_MODE', 'auto')
                logger.warning(f"ä½¿ç”¨æ¨¡å¼ {current_mode} è·å–çš„æ¨ç†å†…å®¹ä¸è¶³ï¼Œå°è¯•åˆ‡æ¢æ¨¡å¼")
                
                # å°è¯•ä¸‹ä¸€ä¸ªæ¨ç†æ¨¡å¼
                for reasoning_mode in self.reasoning_modes:
                    if reasoning_mode == current_mode:
                        continue
                    
                    logger.info(f"å°è¯•ä½¿ç”¨æ¨ç†æ¨¡å¼: {reasoning_mode}")
                    os.environ["DEEPSEEK_REASONING_MODE"] = reasoning_mode
                    provider = self._get_reasoning_provider()  # é‡æ–°åˆå§‹åŒ–æä¾›è€…
                    
                    reasoning_content = []
                    async for content_type, content in provider.get_reasoning(
                        messages=messages,
                        model=model,
                        model_arg=kwargs.get('model_arg')
                    ):
                        if content_type == "reasoning":
                            reasoning_content.append(content)
                        elif content_type == "content" and not reasoning_content:
                            reasoning_content.append(f"åˆ†æ: {content}")
                    
                    retry_result = "\n".join(reasoning_content)
                    if retry_result and len(retry_result) > self.min_reasoning_chars:
                        logger.info(f"ä½¿ç”¨æ¨ç†æ¨¡å¼ {reasoning_mode} æˆåŠŸè·å–è¶³å¤Ÿçš„æ¨ç†å†…å®¹")
                        return retry_result
            
            return result or "æ— æ³•è·å–è¶³å¤Ÿçš„æ¨ç†å†…å®¹"
        except Exception as e:
            logger.error(f"ä¸»è¦æ¨ç†æä¾›è€…å¤±è´¥: {e}")
            if isinstance(provider, DeepSeekClient):
                # è·å–å½“å‰æä¾›å•†åç§°
                current_provider = getattr(provider, 'provider', 'unknown')
                logger.info(f"ä» {current_provider} æä¾›å•†åˆ‡æ¢åˆ° Ollama æ¨ç†æä¾›è€…")
                try:
                    provider = OllamaR1Client(api_url=os.getenv('OLLAMA_API_URL'))
                    # é‡è¯•ä½¿ç”¨ Ollama
                    reasoning_content = []
                    async for content_type, content in provider.get_reasoning(
                        messages=messages,
                        model="deepseek-r1:32b"
                    ):
                        if content_type == "reasoning":
                            reasoning_content.append(content)
                    return "\n".join(reasoning_content)
                except Exception as e:
                    logger.error(f"å¤‡ç”¨æ¨ç†æä¾›è€…ä¹Ÿå¤±è´¥: {e}")
                
            return "æ— æ³•è·å–æ¨ç†å†…å®¹"

    async def _retry_operation(self, operation, max_retries=3):
        """é€šç”¨é‡è¯•æœºåˆ¶"""
        for i in range(max_retries):
            try:
                return await operation()
            except Exception as e:
                if i == max_retries - 1:
                    raise
                logger.warning(f"æ“ä½œå¤±è´¥ï¼Œæ­£åœ¨é‡è¯• ({i+1}/{max_retries}): {str(e)}")
                await asyncio.sleep(1 * (i + 1))  # æŒ‡æ•°é€€é¿

    def _validate_model_names(self, deepseek_model: str, claude_model: str):
        """éªŒè¯æ¨¡å‹åç§°çš„æœ‰æ•ˆæ€§"""
        if not deepseek_model or not isinstance(deepseek_model, str):
            raise ValueError("æ— æ•ˆçš„ DeepSeek æ¨¡å‹åç§°")
        
        if not claude_model or not isinstance(claude_model, str):
            raise ValueError("æ— æ•ˆçš„ Claude æ¨¡å‹åç§°")

    def _validate_messages(self, messages: list) -> None:
        """éªŒè¯æ¶ˆæ¯åˆ—è¡¨çš„æœ‰æ•ˆæ€§"""
        if not messages:
            raise ValueError("æ¶ˆæ¯åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
        
        for msg in messages:
            if not isinstance(msg, dict):
                raise ValueError("æ¶ˆæ¯å¿…é¡»æ˜¯å­—å…¸æ ¼å¼")
            if "role" not in msg or "content" not in msg:
                raise ValueError("æ¶ˆæ¯å¿…é¡»åŒ…å« role å’Œ content å­—æ®µ")
            if msg["role"] not in ["user", "assistant", "system"]:
                raise ValueError(f"ä¸æ”¯æŒçš„æ¶ˆæ¯è§’è‰²: {msg['role']}")

    async def _get_reasoning_with_fallback(
        self, 
        messages: list,
        model: str,
        model_arg: tuple[float, float, float, float] = None
    ) -> str:
        """è·å–æ¨ç†å†…å®¹ï¼Œå¸¦æœ‰å¤‡ç”¨æ–¹æ¡ˆ
        
        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°
            model_arg: æ¨¡å‹å‚æ•°å…ƒç»„
            
        Returns:
            str: æ¨ç†å†…å®¹
        """
        try:
            provider = self._get_reasoning_provider()
            reasoning_content = []
            
            # å°è¯•ä¸åŒçš„æ¨ç†æ¨¡å¼
            for reasoning_mode in self.reasoning_modes:
                if reasoning_content and len("".join(reasoning_content)) > self.min_reasoning_chars:
                    # å¦‚æœå·²ç»æ”¶é›†åˆ°è¶³å¤Ÿçš„å†…å®¹ï¼Œç»“æŸå¾ªç¯
                    logger.info(f"å·²æ”¶é›†åˆ°è¶³å¤Ÿæ¨ç†å†…å®¹ ({len(''.join(reasoning_content))}å­—ç¬¦)ï¼Œä¸å†å°è¯•å…¶ä»–æ¨¡å¼")
                    break
                    
                logger.info(f"å°è¯•ä½¿ç”¨æ¨ç†æ¨¡å¼: {reasoning_mode}")
                os.environ["DEEPSEEK_REASONING_MODE"] = reasoning_mode
                provider = self._get_reasoning_provider()  # é‡æ–°åˆå§‹åŒ–æä¾›è€…
                
                temp_content = []
                content_received = False  # æ ‡è®°æ˜¯å¦æ”¶åˆ°æ™®é€šå†…å®¹
                
                try:
                    async for content_type, content in provider.get_reasoning(
                        messages=messages,
                        model=model,
                        model_arg=model_arg
                    ):
                        if content_type == "reasoning":
                            temp_content.append(content)
                            logger.debug(f"æ”¶åˆ°æ¨ç†å†…å®¹ï¼Œå½“å‰ä¸´æ—¶å†…å®¹é•¿åº¦: {len(''.join(temp_content))}")
                        elif content_type == "content" and not temp_content and reasoning_mode in ['early_content', 'any_content']:
                            # åœ¨æŸäº›æ¨¡å¼ä¸‹ï¼Œä¹Ÿå°†æ™®é€šå†…å®¹è§†ä¸ºæ¨ç†
                            temp_content.append(f"åˆ†æ: {content}")
                            logger.debug(f"æ™®é€šå†…å®¹è½¬ä¸ºæ¨ç†å†…å®¹ï¼Œå½“å‰ä¸´æ—¶å†…å®¹é•¿åº¦: {len(''.join(temp_content))}")
                        elif content_type == "content":
                            # æ”¶åˆ°æ™®é€šå†…å®¹ï¼Œå¯èƒ½è¡¨ç¤ºæ¨ç†é˜¶æ®µç»“æŸ
                            content_received = True
                            logger.info("æ”¶åˆ°æ™®é€šå†…å®¹ï¼Œæ¨ç†é˜¶æ®µå¯èƒ½å·²ç»“æŸ")
                            
                        # å¦‚æœæ”¶åˆ°æ™®é€šå†…å®¹ä¸”å·²æœ‰è¶³å¤Ÿæ¨ç†å†…å®¹ï¼Œæå‰ç»ˆæ­¢
                        if content_received and len("".join(temp_content)) > self.min_reasoning_chars:
                            logger.info("æ”¶åˆ°æ™®é€šå†…å®¹ä¸”ä¸´æ—¶æ¨ç†å†…å®¹è¶³å¤Ÿï¼Œæå‰ç»“æŸæ¨ç†è·å–")
                            break
                            
                    if temp_content and len("".join(temp_content)) > len("".join(reasoning_content)):
                        # å¦‚æœæœ¬æ¬¡è·å–çš„å†…å®¹æ›´å¤šï¼Œåˆ™æ›´æ–°ç»“æœ
                        reasoning_content = temp_content
                        if content_received:
                            # å¦‚æœå·²æ”¶åˆ°æ™®é€šå†…å®¹ï¼Œè¡¨ç¤ºæ¨ç†é˜¶æ®µå·²å®Œæˆï¼Œä¸å†å°è¯•å…¶ä»–æ¨¡å¼
                            logger.info("æ¨ç†é˜¶æ®µå·²ç»“æŸä¸”å†…å®¹è¶³å¤Ÿï¼Œåœæ­¢å°è¯•å…¶ä»–æ¨¡å¼")
                            break
                except Exception as mode_e:
                    logger.error(f"ä½¿ç”¨æ¨ç†æ¨¡å¼ {reasoning_mode} æ—¶å‘ç”Ÿé”™è¯¯: {mode_e}")
                    continue
            
            return "".join(reasoning_content) or "æ— æ³•è·å–æ¨ç†å†…å®¹"
        except Exception as e:
            logger.error(f"ä¸»è¦æ¨ç†æä¾›è€…å¤±è´¥: {e}")
            if isinstance(provider, DeepSeekClient):
                # è·å–å½“å‰æä¾›å•†åç§°
                current_provider = getattr(provider, 'provider', 'unknown')
                logger.info(f"ä» {current_provider} æä¾›å•†åˆ‡æ¢åˆ° Ollama æ¨ç†æä¾›è€…")
                try:
                    provider = OllamaR1Client(api_url=os.getenv('OLLAMA_API_URL'))
                    # é‡è¯•ä½¿ç”¨ Ollama
                    reasoning_content = []
                    async for content_type, content in provider.get_reasoning(
                        messages=messages,
                        model="deepseek-r1:32b"
                    ):
                        if content_type == "reasoning":
                            reasoning_content.append(content)
                    return "\n".join(reasoning_content)
                except Exception as e:
                    logger.error(f"å¤‡ç”¨æ¨ç†æä¾›è€…ä¹Ÿå¤±è´¥: {e}")
                
            return "æ— æ³•è·å–æ¨ç†å†…å®¹"

    def _validate_config(self):
        """éªŒè¯é…ç½®çš„å®Œæ•´æ€§"""
        provider = os.getenv('REASONING_PROVIDER', 'deepseek').lower()
        
        # æ£€æŸ¥provideræ˜¯å¦åœ¨æ”¯æŒåˆ—è¡¨ä¸­
        if provider not in self.reasoning_providers:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨ç†æä¾›è€…: {provider}")
            
        # é’ˆå¯¹ä¸åŒæä¾›è€…è¿›è¡ŒéªŒè¯
        if provider == 'deepseek':
            if not os.getenv('DEEPSEEK_API_KEY'):
                raise ValueError("ä½¿ç”¨ DeepSeek æ—¶å¿…é¡»æä¾› API KEY")
            if not os.getenv('DEEPSEEK_API_URL'):
                raise ValueError("ä½¿ç”¨ DeepSeek æ—¶å¿…é¡»æä¾› API URL")
        elif provider == 'ollama':
            if not os.getenv('OLLAMA_API_URL'):
                raise ValueError("ä½¿ç”¨ Ollama æ—¶å¿…é¡»æä¾› API URL")
        elif provider == 'siliconflow':
            if not os.getenv('DEEPSEEK_API_KEY'):
                raise ValueError("ä½¿ç”¨ ç¡…åŸºæµåŠ¨ æ—¶å¿…é¡»æä¾› DeepSeek API KEY")
            if not os.getenv('DEEPSEEK_API_URL'):
                raise ValueError("ä½¿ç”¨ ç¡…åŸºæµåŠ¨ æ—¶å¿…é¡»æä¾› DeepSeek API URL")
        elif provider == 'nvidia':
            if not os.getenv('DEEPSEEK_API_KEY'):
                raise ValueError("ä½¿ç”¨ NVIDIA æ—¶å¿…é¡»æä¾› DeepSeek API KEY")
            if not os.getenv('DEEPSEEK_API_URL'):
                raise ValueError("ä½¿ç”¨ NVIDIA æ—¶å¿…é¡»æä¾› DeepSeek API URL")
                
        # éªŒè¯Claudeé…ç½®
        if not os.getenv('CLAUDE_API_KEY'):
            raise ValueError("å¿…é¡»æä¾› CLAUDE_API_KEY ç¯å¢ƒå˜é‡")

    def _format_stream_response(self, content: str, content_type: str = "content", **kwargs) -> bytes:
        """æ ¼å¼åŒ–æµå¼å“åº”
        
        Args:
            content: è¦å‘é€çš„å†…å®¹
            content_type: å†…å®¹ç±»å‹ï¼Œå¯ä»¥æ˜¯ "reasoning"ã€"content" æˆ– "separator"
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            bytes: æ ¼å¼åŒ–çš„SSEå“åº”
        """
        # åŸºæœ¬å“åº”ç»“æ„
        response = {
            "id": kwargs.get("chat_id", f"chatcmpl-{int(time.time())}"),
            "object": "chat.completion.chunk",
            "created": kwargs.get("created_time", int(time.time())),
            "model": kwargs.get("model", "deepclaude"),
            "choices": [{
                "index": 0,
                "delta": {
                    "content": content
                }
            }]
        }
        
        # ä¸ºä¸åŒå†…å®¹ç±»å‹æ·»åŠ æ˜æ˜¾æ ‡è®°
        if content_type == "reasoning":
            # æ·»åŠ æ€è€ƒæ ‡è®° - åœ¨deltaä¸­å’Œresponseæ ¹çº§åˆ«éƒ½æ·»åŠ æ ‡è®°
            response["choices"][0]["delta"]["reasoning"] = True
            response["is_reasoning"] = True  # æ ¹çº§åˆ«æ·»åŠ æ ‡è®°ï¼Œæ–¹ä¾¿å‰ç«¯è¯†åˆ«
            
            # åªåœ¨é¦–ä¸ªtokenæ·»åŠ è¡¨æƒ…ç¬¦å·ï¼Œåç»­tokenä¿æŒåŸæ ·
            # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯ä»¥è¡¨æƒ…ç¬¦å·å¼€å¤´ï¼Œå¦‚æœä¸æ˜¯ï¼Œå¹¶ä¸”æ˜¯é¦–æ¬¡å‘é€æ€è€ƒå†…å®¹(å¯ä»kwargsä¸­è·å–æ ‡å¿—)ï¼Œåˆ™æ·»åŠ è¡¨æƒ…ç¬¦å·
            is_first_thought = kwargs.get("is_first_thought", False)
            if is_first_thought and not content.startswith("ğŸ¤”"):
                response["choices"][0]["delta"]["content"] = f"ğŸ¤” {content}"
        elif content_type == "separator":
            # åˆ†éš”ç¬¦ç‰¹æ®Šæ ‡è®°
            response["is_separator"] = True
        elif content_type == "error":
            # é”™è¯¯ä¿¡æ¯ç‰¹æ®Šæ ‡è®°
            response["is_error"] = True
            response["choices"][0]["delta"]["content"] = f"âš ï¸ {content}"
        
        return f"data: {json.dumps(response)}\n\n".encode('utf-8')

    def _validate_kwargs(self, kwargs: dict) -> None:
        """éªŒè¯å‚æ•°çš„æœ‰æ•ˆæ€§"""
        # éªŒè¯æ¸©åº¦å‚æ•°
        temperature = kwargs.get('temperature')
        if temperature is not None:
            if not isinstance(temperature, (int, float)) or temperature < 0 or temperature > 1:
                raise ValueError("temperature å¿…é¡»åœ¨ 0 åˆ° 1 ä¹‹é—´")
            
        # éªŒè¯ top_p å‚æ•°
        top_p = kwargs.get('top_p')
        if top_p is not None:
            if not isinstance(top_p, (int, float)) or top_p < 0 or top_p > 1:
                raise ValueError("top_p å¿…é¡»åœ¨ 0 åˆ° 1 ä¹‹é—´")
            
        # éªŒè¯æ¨¡å‹å‚æ•°
        model = kwargs.get('model')
        if model and not isinstance(model, str):
            raise ValueError("model å¿…é¡»æ˜¯å­—ç¬¦ä¸²ç±»å‹")

    def _split_into_tokens(self, text: str) -> list[str]:
        """å°†æ–‡æœ¬åˆ†å‰²æˆæ›´å°çš„token
        
        Args:
            text: è¦åˆ†å‰²çš„æ–‡æœ¬
            
        Returns:
            list[str]: tokenåˆ—è¡¨
        """
        # å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´åˆ†å‰²ç²’åº¦
        # 1. æŒ‰å­—ç¬¦åˆ†å‰²
        return list(text)
        
        # æˆ–è€…æŒ‰è¯åˆ†å‰²
        # return text.split()
        
        # æˆ–è€…ä½¿ç”¨æ›´å¤æ‚çš„åˆ†è¯ç®—æ³•
        # return some_tokenizer(text)

    # æœç´¢å¢å¼ºå‡½æ•°
    async def _enhance_with_search(self, query: str) -> str:
        """é€šç”¨æœç´¢å¢å¼ºå‡½æ•°ï¼Œä¸åŒ…å«ç‰¹å®šæ¨¡å¼åŒ¹é…å’Œç‰¹å®šå·¥å…·å‡è®¾
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢å†…å®¹
            
        Returns:
            str: æœç´¢å¢å¼ºæç¤ºï¼Œä¸å«å…·ä½“æœç´¢ç»“æœ
        """
        if not self.search_enabled:
            logger.info("æœç´¢å¢å¼ºåŠŸèƒ½æœªå¯ç”¨")
            return ""
        
        logger.info(f"è€ƒè™‘ä¸ºæŸ¥è¯¢æä¾›æœç´¢å¢å¼º: {query}")
        
        # ä¸å†è¿›è¡Œç¡¬ç¼–ç çš„æ¨¡å¼åŒ¹é…ï¼Œè€Œæ˜¯ç”±å·¥å…·è°ƒç”¨æœºåˆ¶å†³å®šæ˜¯å¦ä½¿ç”¨æœç´¢
        # è¿”å›ä¸€ä¸ªé€šç”¨æç¤ºï¼Œæç¤ºæ¨¡å‹è€ƒè™‘ä½¿ç”¨æœç´¢å·¥å…·
        hint = "æ­¤é—®é¢˜å¯èƒ½æ¶‰åŠå®æ—¶ä¿¡æ¯ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨æœç´¢å·¥å…·è·å–æœ€æ–°æ•°æ®ã€‚"
        
        logger.info("å·²ä¸ºæŸ¥è¯¢æ·»åŠ æœç´¢å¢å¼ºæç¤º")
        return hint
    
    async def _handle_tool_results(self, original_question: str, reasoning: str, 
                                   tool_calls: List[Dict], tool_results: List[Dict], **kwargs) -> str:
        """å¤„ç†å·¥å…·è°ƒç”¨ç»“æœå¹¶ç”Ÿæˆæœ€ç»ˆå›ç­”
        
        Args:
            original_question: åŸå§‹ç”¨æˆ·é—®é¢˜
            reasoning: æ¨ç†å†…å®¹
            tool_calls: å·¥å…·è°ƒç”¨åˆ—è¡¨
            tool_results: å·¥å…·è°ƒç”¨ç»“æœåˆ—è¡¨
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            str: æœ€ç»ˆå›ç­”
        """
        logger.info(f"å¤„ç†å·¥å…·è°ƒç”¨ç»“æœ - å·¥å…·æ•°: {len(tool_calls)}, ç»“æœæ•°: {len(tool_results)}")
        
        # æ„å»ºå·¥å…·è°ƒç”¨åŠç»“æœçš„è¯¦ç»†æè¿°
        tools_info = ""
        for i, (tool_call, tool_result) in enumerate(zip(tool_calls, tool_results), 1):
            # é€šç”¨æå–å·¥å…·åç§°å’Œå‚æ•°ï¼Œæ”¯æŒå¤šç§æ ¼å¼
            tool_name = "æœªçŸ¥å·¥å…·"
            tool_args = "{}"
            
            # ä»ä¸åŒæ ¼å¼ä¸­æå–å·¥å…·åç§°å’Œå‚æ•°
            if "function" in tool_call:
                # OpenAIæ ¼å¼
                func = tool_call.get("function", {})
                tool_name = func.get("name", "æœªçŸ¥å·¥å…·")
                tool_args = func.get("arguments", "{}")
            elif "name" in tool_call:
                # Claudeæˆ–å…¶ä»–æ ¼å¼
                tool_name = tool_call.get("name", "æœªçŸ¥å·¥å…·")
                tool_args = json.dumps(tool_call.get("input", tool_call.get("arguments", {})), ensure_ascii=False)
            
            # å°è¯•è§£æå‚æ•°ä¸ºæ›´å¯è¯»çš„æ ¼å¼
            try:
                args_dict = json.loads(tool_args) if isinstance(tool_args, str) else tool_args
                args_str = json.dumps(args_dict, ensure_ascii=False, indent=2)
            except:
                args_str = str(tool_args)
                
            # é€šç”¨æå–å·¥å…·ç»“æœ
            result_content = ""
            if isinstance(tool_result, dict):
                # å°è¯•å¤šç§å¯èƒ½çš„å­—æ®µå
                result_content = (tool_result.get("content") or 
                                 tool_result.get("result") or 
                                 tool_result.get("output") or 
                                 tool_result.get("response") or
                                 json.dumps(tool_result, ensure_ascii=False))
            else:
                result_content = str(tool_result)
            
            tools_info += f"""
å·¥å…· {i}: {tool_name}
å‚æ•°:
{args_str}

ç»“æœ:
{result_content}
"""

        # æ„å»ºå®Œæ•´æç¤º
        prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆä¸€ä¸ªå®Œæ•´ã€å‡†ç¡®çš„å›ç­”ï¼š

ç”¨æˆ·é—®é¢˜: {original_question}

æ€è€ƒè¿‡ç¨‹:
{reasoning}

å·¥å…·è°ƒç”¨ç»“æœ:
{tools_info}

è¦æ±‚ï¼š
1. ç›´æ¥ä½¿ç”¨å·¥å…·è¿”å›çš„æ•°æ®å›ç­”é—®é¢˜
2. ç¡®ä¿å›ç­”å®Œå…¨è§£å†³ç”¨æˆ·çš„é—®é¢˜
3. ä½¿ç”¨æ¸…æ™°ã€æ˜“æ‡‚çš„è¯­è¨€
4. å¦‚æœå·¥å…·ç»“æœä¸å®Œæ•´æˆ–æœ‰é”™è¯¯ï¼Œè¦è¯´æ˜æƒ…å†µ
5. å›ç­”è¦æœ‰é€»è¾‘æ€§å’Œè¿è´¯æ€§
6. å¿…è¦æ—¶å¯ä»¥ç»“åˆå¤šä¸ªå·¥å…·çš„ç»“æœ
7. ä¸è¦è§£é‡Šæ¨ç†è¿‡ç¨‹ï¼Œç›´æ¥ç»™å‡ºåŸºäºå·¥å…·ç»“æœçš„ç­”æ¡ˆ
8. ä¸è¦æåŠæ‚¨æ­£åœ¨ä½¿ç”¨å·¥å…·ï¼Œå°±åƒè¿™äº›ä¿¡æ¯æ˜¯æ‚¨æœ¬èº«çŸ¥é“çš„ä¸€æ ·
"""

        logger.info("å‘Claudeå‘é€å·¥å…·ç»“æœæç¤ºç”Ÿæˆæœ€ç»ˆå›ç­”")
        try:
            # å°†å·¥å…·ç»“æœä¹Ÿæ·»åŠ åˆ°æç¤ºæ¶ˆæ¯ä¸­ï¼Œä»¥ä¾¿Claudeèƒ½å¤Ÿå……åˆ†åˆ©ç”¨å·¥å…·è¿”å›çš„ä¿¡æ¯
            messages = [
                {"role": "user", "content": prompt}
            ]
            
            # ä½¿ç”¨Claudeç”Ÿæˆæœ€ç»ˆå›ç­”
            response = await self.claude_client.chat(
                messages=messages,
                model=os.getenv('CLAUDE_MODEL', 'claude-3-7-sonnet-20250219'),
                temperature=kwargs.get('temperature', 0.7),
                top_p=kwargs.get('top_p', 0.9)
            )
            
            # æå–å¹¶è¿”å›å›ç­”å†…å®¹
            if "content" in response:
                answer = response.get("content", "")
                logger.info(f"ç”Ÿæˆæœ€ç»ˆå›ç­”æˆåŠŸ(Claudeæ ¼å¼): {answer[:100]}...")
                return answer
            elif "choices" in response and response["choices"]:
                answer = response["choices"][0].get("message", {}).get("content", "")
                logger.info(f"ç”Ÿæˆæœ€ç»ˆå›ç­”æˆåŠŸ(OpenAIæ ¼å¼): {answer[:100]}...")
                return answer
            else:
                logger.error(f"æœªæ‰¾åˆ°å›ç­”å†…å®¹ï¼Œå“åº”ç»“æ„: {list(response.keys())}")
                return "æŠ±æ­‰ï¼Œå¤„ç†å·¥å…·ç»“æœæ—¶å‡ºç°é”™è¯¯ï¼Œæ— æ³•ç”Ÿæˆå›ç­”ã€‚"
        except Exception as e:
            logger.error(f"å¤„ç†å·¥å…·ç»“æœå¤±è´¥: {e}", exc_info=True)
            return f"æŠ±æ­‰ï¼Œå¤„ç†å·¥å…·ç»“æœæ—¶å‡ºç°é”™è¯¯: {str(e)}"

    def _format_tool_decision_prompt(self, original_question: str, reasoning: str, tools: List[Dict]) -> str:
        """æ ¼å¼åŒ–å·¥å…·å†³ç­–æç¤ºï¼Œç”¨äºClaudeåˆ¤æ–­æ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·
        
        Args:
            original_question: åŸå§‹ç”¨æˆ·é—®é¢˜
            reasoning: æ¨ç†å†…å®¹
            tools: å¯ç”¨å·¥å…·åˆ—è¡¨
            
        Returns:
            str: æ ¼å¼åŒ–çš„æç¤ºæ–‡æœ¬
        """
        # æå–å·¥å…·æè¿°
        tools_description = ""
        for i, tool in enumerate(tools, 1):
            if "function" in tool:
                # å¤„ç†OpenAIæ ¼å¼å·¥å…·
                function = tool["function"]
                name = function.get("name", "æœªå‘½åå·¥å…·")
                description = function.get("description", "æ— æè¿°")
                parameters = function.get("parameters", {})
                required = parameters.get("required", [])
                properties = parameters.get("properties", {})
                
                param_desc = ""
                for param_name, param_info in properties.items():
                    is_required = "å¿…å¡«" if param_name in required else "å¯é€‰"
                    param_type = param_info.get("type", "æœªçŸ¥ç±»å‹")
                    param_description = param_info.get("description", "æ— æè¿°")
                    enum_values = param_info.get("enum", [])
                    
                    enum_desc = ""
                    if enum_values:
                        enum_desc = f"ï¼Œå¯é€‰å€¼: {', '.join([str(v) for v in enum_values])}"
                        
                    param_desc += f"  - {param_name} ({param_type}, {is_required}): {param_description}{enum_desc}\n"
                
                tools_description += f"{i}. å·¥å…·åç§°: {name}\n   æè¿°: {description}\n   å‚æ•°:\n{param_desc}\n"
            # å¤„ç†Claudeæ ¼å¼çš„è‡ªå®šä¹‰å·¥å…·ï¼ˆä½¿ç”¨customå­—æ®µï¼‰
            elif "name" in tool and "custom" in tool:
                name = tool.get("name", "æœªå‘½åå·¥å…·")
                description = tool.get("description", "æ— æè¿°")
                custom = tool.get("custom", {})
                
                # å¤„ç†input_schema
                if "input_schema" in custom:
                    input_schema = custom["input_schema"]
                    required = input_schema.get("required", [])
                    properties = input_schema.get("properties", {})
                else:
                    # å…¼å®¹ç›´æ¥åœ¨customä¸‹çš„å±æ€§
                    required = custom.get("required", [])
                    properties = custom.get("properties", {})
                
                param_desc = ""
                for param_name, param_info in properties.items():
                    is_required = "å¿…å¡«" if param_name in required else "å¯é€‰"
                    param_type = param_info.get("type", "æœªçŸ¥ç±»å‹")
                    param_description = param_info.get("description", "æ— æè¿°")
                    enum_values = param_info.get("enum", [])
                    
                    enum_desc = ""
                    if enum_values:
                        enum_desc = f"ï¼Œå¯é€‰å€¼: {', '.join([str(v) for v in enum_values])}"
                        
                    param_desc += f"  - {param_name} ({param_type}, {is_required}): {param_description}{enum_desc}\n"
                
                tools_description += f"{i}. å·¥å…·åç§°: {name}\n   æè¿°: {description}\n   å‚æ•°:\n{param_desc}\n"
            elif "type" in tool and tool["type"] == "custom":
                # å¤„ç†Claudeæ ¼å¼å·¥å…·
                name = tool.get("name", "æœªå‘½åå·¥å…·")
                description = tool.get("description", "æ— æè¿°")
                
                # å°è¯•è§£æschema
                tool_schema = tool.get("tool_schema", {})
                required = tool_schema.get("required", [])
                properties = tool_schema.get("properties", {})
                
                param_desc = ""
                for param_name, param_info in properties.items():
                    is_required = "å¿…å¡«" if param_name in required else "å¯é€‰"
                    param_type = param_info.get("type", "æœªçŸ¥ç±»å‹")
                    param_description = param_info.get("description", "æ— æè¿°")
                    enum_values = param_info.get("enum", [])
                    
                    enum_desc = ""
                    if enum_values:
                        enum_desc = f"ï¼Œå¯é€‰å€¼: {', '.join([str(v) for v in enum_values])}"
                        
                    param_desc += f"  - {param_name} ({param_type}, {is_required}): {param_description}{enum_desc}\n"
                
                tools_description += f"{i}. å·¥å…·åç§°: {name}\n   æè¿°: {description}\n   å‚æ•°:\n{param_desc}\n"
            elif "name" in tool and "parameters" in tool:
                # å¤„ç†ç®€åŒ–æ ¼å¼å·¥å…·
                name = tool.get("name", "æœªå‘½åå·¥å…·")
                description = tool.get("description", "æ— æè¿°")
                parameters = tool.get("parameters", {})
                required = parameters.get("required", [])
                properties = parameters.get("properties", {})
                
                param_desc = ""
                for param_name, param_info in properties.items():
                    is_required = "å¿…å¡«" if param_name in required else "å¯é€‰"
                    param_type = param_info.get("type", "æœªçŸ¥ç±»å‹") 
                    param_description = param_info.get("description", "æ— æè¿°")
                    enum_values = param_info.get("enum", [])
                    
                    enum_desc = ""
                    if enum_values:
                        enum_desc = f"ï¼Œå¯é€‰å€¼: {', '.join([str(v) for v in enum_values])}"
                        
                    param_desc += f"  - {param_name} ({param_type}, {is_required}): {param_description}{enum_desc}\n"
                
                tools_description += f"{i}. å·¥å…·åç§°: {name}\n   æè¿°: {description}\n   å‚æ•°:\n{param_desc}\n"
            # å¤„ç†Claudeæ ¼å¼çš„è‡ªå®šä¹‰å·¥å…·ï¼ˆä½¿ç”¨input_schemaï¼‰
            elif "name" in tool and "input_schema" in tool:
                name = tool.get("name", "æœªå‘½åå·¥å…·")
                description = tool.get("description", "æ— æè¿°")
                input_schema = tool.get("input_schema", {})
                required = input_schema.get("required", [])
                properties = input_schema.get("properties", {})
                
                param_desc = ""
                for param_name, param_info in properties.items():
                    is_required = "å¿…å¡«" if param_name in required else "å¯é€‰"
                    param_type = param_info.get("type", "æœªçŸ¥ç±»å‹")
                    param_description = param_info.get("description", "æ— æè¿°")
                    enum_values = param_info.get("enum", [])
                    
                    enum_desc = ""
                    if enum_values:
                        enum_desc = f"ï¼Œå¯é€‰å€¼: {', '.join([str(v) for v in enum_values])}"
                        
                    param_desc += f"  - {param_name} ({param_type}, {is_required}): {param_description}{enum_desc}\n"
                    
                tools_description += f"{i}. å·¥å…·åç§°: {name}\n   æè¿°: {description}\n   å‚æ•°:\n{param_desc}\n"
        
        # æ„å»ºå®Œæ•´æç¤º
        prompt = f"""ä½œä¸ºä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œè¯·åˆ†æç”¨æˆ·é—®é¢˜å’Œæˆ‘çš„æ€è€ƒè¿‡ç¨‹ï¼Œå†³å®šæ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·æ¥å®Œæˆå›ç­”ã€‚

ç”¨æˆ·é—®é¢˜: {original_question}

æ€è€ƒè¿‡ç¨‹: 
{reasoning}

å¯ç”¨å·¥å…·åˆ—è¡¨:
{tools_description}

åˆ†æè¦ç‚¹:
1. å¦‚æœé—®é¢˜éœ€è¦å®æ—¶æˆ–æœ€æ–°ä¿¡æ¯(ä¾‹å¦‚å¤©æ°”ã€è‚¡ç¥¨ã€æ–°é—»ç­‰)ï¼Œåº”ä½¿ç”¨å·¥å…·è·å–
2. å¦‚æœé—®é¢˜éœ€è¦æ£€ç´¢ç‰¹å®šæ•°æ®æˆ–æ‰§è¡Œè®¡ç®—ï¼Œåº”ä½¿ç”¨å·¥å…·
3. å¦‚æœé—®é¢˜æ˜¯ä¸€èˆ¬æ€§çŸ¥è¯†æˆ–æ¨ç†ï¼Œä¸éœ€è¦ä½¿ç”¨å·¥å…·
4. å¦‚æœæ€è€ƒè¿‡ç¨‹å·²åŒ…å«è¶³å¤Ÿä¿¡æ¯å›ç­”é—®é¢˜ï¼Œä¸éœ€è¦ä½¿ç”¨å·¥å…·

è¯·ä»”ç»†åˆ¤æ–­æ˜¯å¦ä½¿ç”¨å·¥å…·ï¼Œå¹¶ç»™å‡ºç¬¦åˆä»¥ä¸‹æ ¼å¼çš„å›å¤:

å¦‚æœå†³å®šä½¿ç”¨å·¥å…·ï¼Œè¯·æä¾›ä¸€ä¸ªæœ‰æ•ˆçš„å·¥å…·è°ƒç”¨JSON:
```json
{
  "name": "å·¥å…·åç§°",
  "arguments": {
    "å‚æ•°1": "å€¼1",
    "å‚æ•°2": "å€¼2"
  }
}
```

å¦‚æœä¸éœ€è¦ä½¿ç”¨å·¥å…·ï¼Œåªéœ€ç›´æ¥å›å¤: "ä¸éœ€è¦ä½¿ç”¨å·¥å…·"

è¯·æ³¨æ„ï¼Œä½ çš„å›å¤å¿…é¡»æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„JSONå¯¹è±¡(å¦‚æœä½¿ç”¨å·¥å…·)æˆ–çº¯æ–‡æœ¬çŸ­è¯­(å¦‚æœä¸ä½¿ç”¨å·¥å…·)ã€‚ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–è¯„è®ºã€‚"""

        logger.info(f"ç”Ÿæˆå·¥å…·å†³ç­–æç¤º - é—®é¢˜: '{original_question[:30]}...'")
        return prompt

    def _format_tool_call_response(self, tool_call: Dict, **kwargs) -> bytes:
        """æ ¼å¼åŒ–å·¥å…·è°ƒç”¨å“åº”ï¼Œç¡®ä¿å®Œå…¨ç¬¦åˆOpenAI APIè§„èŒƒ
        
        Args:
            tool_call: å·¥å…·è°ƒç”¨ä¿¡æ¯
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            bytes: æ ¼å¼åŒ–çš„SSEå“åº”
        """
        try:
            # ç¡®ä¿å·¥å…·è°ƒç”¨IDå­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®
            tool_call_id = tool_call.get("id")
            if not tool_call_id or not isinstance(tool_call_id, str) or len(tool_call_id) < 8:
                tool_call_id = f"call_{uuid.uuid4().hex[:8]}"
            
            # ç¡®ä¿å‡½æ•°åå’Œå‚æ•°æ ¼å¼æ­£ç¡®
            function = tool_call.get("function", {})
            function_name = function.get("name", "")
            function_args = function.get("arguments", "{}")
            
            # å¦‚æœå‚æ•°ä¸æ˜¯å­—ç¬¦ä¸²æ ¼å¼ï¼Œè½¬æ¢ä¸ºæ­£ç¡®çš„JSONå­—ç¬¦ä¸²
            if not isinstance(function_args, str):
                try:
                    function_args = json.dumps(function_args, ensure_ascii=False)
                except Exception as e:
                    logger.error(f"å‚æ•°åºåˆ—åŒ–å¤±è´¥: {e}")
                    function_args = "{}"
            
            # æ„é€ æ ‡å‡†çš„OpenAI APIå“åº”æ ¼å¼
            # æ³¨æ„ï¼šOpenAIæœ€æ–°è§„èŒƒè¦æ±‚tool_callsä½œä¸ºä¸€ä¸ªå®Œæ•´çš„æ•°ç»„
            response = {
                "id": kwargs.get("chat_id", f"chatcmpl-{uuid.uuid4()}"),
                "object": "chat.completion.chunk",
                "created": kwargs.get("created_time", int(time.time())),
                "model": kwargs.get("model", "deepclaude"),
                "choices": [{
                    "index": 0,
                    "delta": {
                        "role": "assistant",
                        "content": None,
                        "tool_calls": [
                            {
                                "index": 0,
                                "id": tool_call_id,
                                "type": "function",
                                "function": {
                                    "name": function_name,
                                    "arguments": function_args
                                }
                            }
                        ]
                    },
                    "finish_reason": "tool_calls"
                }]
            }
            
            logger.info(f"å·¥å…·è°ƒç”¨å“åº”æ ¼å¼åŒ–å®Œæˆ - å·¥å…·: {function_name}, ID: {tool_call_id}")
            return f"data: {json.dumps(response, ensure_ascii=False)}\n\n".encode('utf-8')
        except Exception as e:
            logger.error(f"å·¥å…·è°ƒç”¨å“åº”æ ¼å¼åŒ–å¤±è´¥: {e}", exc_info=True)
            error_response = {
                "id": kwargs.get("chat_id", f"chatcmpl-{uuid.uuid4()}"),
                "object": "chat.completion.chunk",
                "created": kwargs.get("created_time", int(time.time())),
                "model": kwargs.get("model", "deepclaude"),
                "choices": [{
                    "index": 0,
                    "delta": {
                        "role": "assistant",
                        "content": f"å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}"
                    },
                    "finish_reason": "error"
                }]
            }
            return f"data: {json.dumps(error_response, ensure_ascii=False)}\n\n".encode('utf-8')
    
    def _format_tool_result_response(self, tool_result: Dict, **kwargs) -> bytes:
        """æ ¼å¼åŒ–å·¥å…·ç»“æœå“åº”ï¼Œç”¨äºæµå¼è¾“å‡º
        
        Args:
            tool_result: å·¥å…·æ‰§è¡Œç»“æœ
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            bytes: æ ¼å¼åŒ–çš„SSEå“åº”
        """
        try:
            # éªŒè¯å·¥å…·ç»“æœæ ¼å¼
            if not isinstance(tool_result, dict):
                raise ValueError("å·¥å…·ç»“æœå¿…é¡»æ˜¯å­—å…¸æ ¼å¼")
            
            tool_call_id = tool_result.get("tool_call_id")
            if not tool_call_id:
                raise ValueError("å·¥å…·ç»“æœå¿…é¡»åŒ…å«tool_call_id")
            
            content = tool_result.get("content")
            if content is None:
                raise ValueError("å·¥å…·ç»“æœå¿…é¡»åŒ…å«content")
            
            # æ„é€ æ ‡å‡†çš„OpenAI APIå“åº”æ ¼å¼
            response = {
                "id": kwargs.get("chat_id", f"chatcmpl-{uuid.uuid4()}"),
                "object": "chat.completion.chunk",
                "created": kwargs.get("created_time", int(time.time())),
                "model": kwargs.get("model", "deepclaude"),
                "choices": [{
                    "index": 0,
                    "delta": {
                        "role": "tool",
                        "content": content,
                        "tool_call_id": tool_call_id
                    },
                    "finish_reason": None
                }]
            }
            
            logger.info(f"å·¥å…·ç»“æœå“åº”æ ¼å¼åŒ–å®Œæˆ - ID: {tool_call_id}")
            return f"data: {json.dumps(response, ensure_ascii=False)}\n\n".encode('utf-8')
            
        except Exception as e:
            logger.error(f"å·¥å…·ç»“æœå“åº”æ ¼å¼åŒ–å¤±è´¥: {e}")
            # è¿”å›ä¸€ä¸ªé”™è¯¯å“åº”
            error_response = {
                "id": kwargs.get("chat_id", f"chatcmpl-{uuid.uuid4()}"),
                "object": "chat.completion.chunk",
                "created": kwargs.get("created_time", int(time.time())),
                "model": kwargs.get("model", "deepclaude"),
                "choices": [{
                    "index": 0,
                    "delta": {
                        "role": "assistant",
                        "content": f"å·¥å…·ç»“æœå¤„ç†å¤±è´¥: {str(e)}"
                    },
                    "finish_reason": "error"
                }]
            }
            return f"data: {json.dumps(error_response, ensure_ascii=False)}\n\n".encode('utf-8')

    def _validate_and_convert_tools(self, tools: List[Dict], target_format: str = 'claude-3') -> List[Dict]:
        """éªŒè¯å¹¶è½¬æ¢å·¥å…·åˆ—è¡¨ï¼Œæ”¯æŒå¤šç§æ ¼å¼è½¬æ¢
        
        Args:
            tools: åŸå§‹å·¥å…·åˆ—è¡¨
            target_format: ç›®æ ‡æ ¼å¼
            
        Returns:
            List[Dict]: éªŒè¯å¹¶è½¬æ¢åçš„å·¥å…·åˆ—è¡¨
        """
        if not tools:
            return []
        
        valid_tools = []
        for i, tool in enumerate(tools):
            # åŸºæœ¬æ ¼å¼æ£€æŸ¥ 
            if not isinstance(tool, dict):
                logger.warning(f"å·¥å…·æ ¼å¼é”™è¯¯: {tool}")
                continue
            
            # å¤„ç†å·²ç»æ˜¯Claudeæ ¼å¼çš„å·¥å…·
            if "type" in tool and tool["type"] in ["custom", "bash_20250124", "text_editor_20250124"]:
                # ç¡®ä¿å·¥å…·æ²¡æœ‰customå­—æ®µï¼Œè¿™æ˜¯ä¸€ä¸ªå¸¸è§é”™è¯¯
                if "custom" in tool:
                    logger.warning(f"æ£€æµ‹åˆ°å·¥å…·ä¸­çš„customå­—æ®µï¼Œè¿™ä¸ç¬¦åˆClaude APIè§„èŒƒï¼Œæ­£åœ¨ç§»é™¤: {tool.get('name', 'æœªå‘½åå·¥å…·')}")
                    # åˆ›å»ºå·¥å…·çš„å‰¯æœ¬é¿å…ä¿®æ”¹åŸå¯¹è±¡
                    fixed_tool = tool.copy()
                    fixed_tool.pop("custom", None)
                    valid_tools.append(fixed_tool)
                else:
                    valid_tools.append(tool)
                logger.info(f"æ£€æµ‹åˆ°å·²æ˜¯Claudeæ ¼å¼çš„å·¥å…·: {tool.get('name', 'æœªå‘½åå·¥å…·')}")
                continue
                
            # å¤„ç†OpenAIæ ¼å¼çš„å·¥å…·
            if "function" in tool:
                if target_format == 'claude-3':
                    function_data = tool["function"]
                    name = function_data.get("name", "æœªå‘½åå·¥å…·")
                    description = function_data.get("description", "")
                    parameters = function_data.get("parameters", {})
                    
                    # åˆ›å»ºClaudeæ ¼å¼çš„è‡ªå®šä¹‰å·¥å…·
                    claude_tool = {
                        "type": "custom",
                        "name": name,
                        "description": description,
                        "tool_schema": parameters
                    }
                    logger.info(f"å°†OpenAIæ ¼å¼å·¥å…· '{name}' è½¬æ¢ä¸ºClaude customæ ¼å¼")
                    valid_tools.append(claude_tool)
                else:
                    # ä¿æŒOpenAIæ ¼å¼ï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®
                    # ç¡®ä¿æœ‰typeå­—æ®µ
                    if "type" not in tool:
                        tool = {"type": "function", "function": tool["function"]}
                    valid_tools.append(tool)
                    logger.info(f"ä¿æŒOpenAIæ ¼å¼å·¥å…·: {tool['function'].get('name', 'æœªå‘½åå·¥å…·')}")
                continue
                
            # å¤„ç†Difyæ ¼å¼çš„å·¥å…· (å¯èƒ½ç”¨nameå’Œapi_typeå­—æ®µ)
            if "name" in tool and "api_type" in tool:
                logger.info(f"æ£€æµ‹åˆ°Difyæ ¼å¼å·¥å…·: {tool.get('name', 'æœªå‘½åå·¥å…·')}")
                if target_format == 'claude-3':
                    # å°è¯•ä»Difyæ ¼å¼è½¬æ¢ä¸ºClaudeæ ¼å¼
                    dify_tool = {
                        "type": "custom",
                        "name": tool.get("name", "æœªå‘½åå·¥å…·"),
                        "description": tool.get("description", ""),
                        "tool_schema": tool.get("parameters", {})
                    }
                    valid_tools.append(dify_tool)
                    logger.info(f"å·²å°†Difyå·¥å…· '{tool.get('name', 'æœªå‘½åå·¥å…·')}' è½¬æ¢ä¸ºClaudeæ ¼å¼")
                else:
                    # è½¬æ¢ä¸ºOpenAIæ ¼å¼
                    openai_tool = {
                        "type": "function",
                        "function": {
                            "name": tool.get("name", "æœªå‘½åå·¥å…·"),
                            "description": tool.get("description", ""),
                            "parameters": tool.get("parameters", {})
                        }
                    }
                    valid_tools.append(openai_tool)
                    logger.info(f"å·²å°†Difyå·¥å…· '{tool.get('name', 'æœªå‘½åå·¥å…·')}' è½¬æ¢ä¸ºOpenAIæ ¼å¼")
                continue
                
            # å¤„ç†ç®€åŒ–æ ¼å¼å·¥å…· (ä»…æœ‰nameå’Œparameters)
            if "name" in tool and "parameters" in tool:
                logger.info(f"æ£€æµ‹åˆ°ç®€åŒ–æ ¼å¼å·¥å…·: {tool.get('name', 'æœªå‘½åå·¥å…·')}")
                if target_format == 'claude-3':
                    simple_tool = {
                        "type": "custom",
                        "name": tool.get("name", "æœªå‘½åå·¥å…·"),
                        "description": tool.get("description", ""),
                        "tool_schema": tool.get("parameters", {})
                    }
                    valid_tools.append(simple_tool)
                    logger.info(f"å·²å°†ç®€åŒ–æ ¼å¼å·¥å…·è½¬ä¸ºClaudeæ ¼å¼: {tool.get('name', 'æœªå‘½åå·¥å…·')}")
                else:
                    openai_tool = {
                        "type": "function",
                        "function": {
                            "name": tool.get("name", "æœªå‘½åå·¥å…·"),
                            "description": tool.get("description", ""),
                            "parameters": tool.get("parameters", {})
                        }
                    }
                    valid_tools.append(openai_tool)
                    logger.info(f"å·²å°†ç®€åŒ–æ ¼å¼å·¥å…·è½¬ä¸ºOpenAIæ ¼å¼: {tool.get('name', 'æœªå‘½åå·¥å…·')}")
                continue
                
            # å¤„ç†å…¶ä»–å¯èƒ½çš„å˜ä½“æ ¼å¼ (å°è¯•æå–å…³é”®å­—æ®µ)
            if set(["name", "description"]).issubset(set(tool.keys())):
                logger.info(f"æ£€æµ‹åˆ°å¯èƒ½çš„å˜ä½“æ ¼å¼å·¥å…·: {tool.get('name', 'æœªå‘½åå·¥å…·')}")
                
                # å°è¯•ä»å„ç§å¯èƒ½çš„å­—æ®µä¸­æå–å‚æ•°
                parameters = tool.get("parameters", 
                            tool.get("schema", 
                            tool.get("parameter_schema", 
                            tool.get("tool_schema", {}))))
                
                if target_format == 'claude-3':
                    variant_tool = {
                        "type": "custom",
                        "name": tool.get("name", "æœªå‘½åå·¥å…·"),
                        "description": tool.get("description", ""),
                        "tool_schema": parameters
                    }
                    valid_tools.append(variant_tool)
                    logger.info(f"å·²å°†å˜ä½“æ ¼å¼å·¥å…·è½¬ä¸ºClaudeæ ¼å¼: {tool.get('name', 'æœªå‘½åå·¥å…·')}")
                else:
                    openai_tool = {
                        "type": "function",
                        "function": {
                            "name": tool.get("name", "æœªå‘½åå·¥å…·"),
                            "description": tool.get("description", ""),
                            "parameters": parameters
                        }
                    }
                    valid_tools.append(openai_tool)
                    logger.info(f"å·²å°†å˜ä½“æ ¼å¼å·¥å…·è½¬ä¸ºOpenAIæ ¼å¼: {tool.get('name', 'æœªå‘½åå·¥å…·')}")
                continue
                
            logger.warning(f"å·¥å…·æ ¼å¼æ— æ³•è¯†åˆ«: {json.dumps(tool, ensure_ascii=False)[:100]}...")
        
        # æ—¥å¿—è®°å½•è½¬æ¢ç»“æœ
        logger.info(f"å·¥å…·éªŒè¯å’Œè½¬æ¢å®Œæˆï¼ŒåŸæœ‰ {len(tools)} ä¸ªå·¥å…·ï¼Œæœ‰æ•ˆ {len(valid_tools)} ä¸ªå·¥å…·")
        if valid_tools:
            for i, tool in enumerate(valid_tools):
                if "type" in tool and tool["type"] == "custom":
                    logger.debug(f"æœ‰æ•ˆå·¥å…·[{i}]: {tool.get('name', 'æœªå‘½åå·¥å…·')} (Claudeæ ¼å¼)")
                else:
                    logger.debug(f"æœ‰æ•ˆå·¥å…·[{i}]: {tool.get('name', tool.get('function', {}).get('name', 'æœªå‘½åå·¥å…·'))} (OpenAIæ ¼å¼)")
                
        return valid_tools

    def _format_claude_prompt(self, original_question: str, reasoning: str) -> str:
        """æ ¼å¼åŒ–ç»™Claudeçš„æç¤ºè¯"""
        return f"""
åŸå§‹é—®é¢˜:
{original_question}

æ€è€ƒè¿‡ç¨‹:
{reasoning}

è¯·åŸºäºä»¥ä¸Šæ€è€ƒè¿‡ç¨‹å’ŒåŸå§‹é—®é¢˜,ç»™å‡ºè¯¦ç»†çš„ç­”æ¡ˆã€‚è¦æ±‚:
1. åˆ†æ­¥éª¤è¯¦ç»†è§£ç­”
2. ç¡®ä¿ç†è§£é—®é¢˜çš„æ¯ä¸ªéƒ¨åˆ†
3. ç»™å‡ºå®Œæ•´çš„è§£å†³æ–¹æ¡ˆ
4. å¦‚æœæ€è€ƒè¿‡ç¨‹æœ‰é”™è¯¯æˆ–ä¸å®Œæ•´ï¼Œè¯·æŒ‡å‡ºå¹¶è¡¥å……æ­£ç¡®çš„è§£ç­”
5. ä¿æŒå›ç­”çš„ä¸“ä¸šæ€§å’Œå‡†ç¡®æ€§
"""

    async def chat_completions_without_stream(
        self,
        messages: list,
        model_arg: tuple[float, float, float, float],
        tools: list = None,
        tool_choice = "auto",
        deepseek_model: str = "deepseek-reasoner",
        claude_model: str = os.getenv('CLAUDE_MODEL', 'claude-3-7-sonnet-20250219'),
        **kwargs
    ) -> dict:
        """å¤„ç†éæµå¼è¯·æ±‚ï¼Œæ”¯æŒå·¥å…·è°ƒç”¨
        
        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
            model_arg: æ¨ç†æ¨¡å‹å‚æ•°å…ƒç»„ (temperature, top_p, presence_penalty, frequency_penalty)
            tools: å·¥å…·åˆ—è¡¨
            tool_choice: å·¥å…·é€‰æ‹©ç­–ç•¥
            deepseek_model: DeepSeekæ¨ç†æ¨¡å‹
            claude_model: Claudeå›ç­”æ¨¡å‹
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            dict: å®Œæ•´çš„å“åº”æ•°æ®
        """
        logger.info("å¼€å§‹å¤„ç†éæµå¼è¯·æ±‚...")
        logger.debug(f"è¾“å…¥æ¶ˆæ¯: {messages}")
        
        # é…ç½®ç›´æ¥é€ä¼ æ¨¡å¼
        direct_tool_pass = os.getenv('CLAUDE_DIRECT_TOOL_PASS', 'true').lower() == 'true'
        
        # æ„é€ åŸºæœ¬å“åº”æ¨¡æ¿
        chat_id = kwargs.get("chat_id", f"chatcmpl-{uuid.uuid4()}")
        created_time = kwargs.get("created_time", int(time.time()))
        model = kwargs.get("model", "deepclaude")
        
        # å¦‚æœå¯ç”¨ç›´æ¥é€ä¼ ä¸”æœ‰å·¥å…·ï¼Œç›´æ¥ä½¿ç”¨Claudeå¤„ç†
        if direct_tool_pass and tools and len(tools) > 0:
            logger.info(f"ç›´æ¥é€ä¼ æ¨¡å¼(éæµå¼): åŒ…å« {len(tools)} ä¸ªå·¥å…·")
            
            # è®°å½•å·¥å…·é€‰æ‹©ç­–ç•¥
            if isinstance(tool_choice, str):
                logger.info(f"å·¥å…·é€‰æ‹©ç­–ç•¥: {tool_choice}")
            elif isinstance(tool_choice, dict):
                logger.info(f"å·¥å…·é€‰æ‹©ç­–ç•¥: {json.dumps(tool_choice, ensure_ascii=False)}")
            else:
                logger.info(f"å·¥å…·é€‰æ‹©ç­–ç•¥: {tool_choice}")
            
            # è½¬æ¢å·¥å…·æ ¼å¼
            converted_tools = self._validate_and_convert_tools(tools, target_format='claude-3')
            
            if not converted_tools:
                logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„å·¥å…·å¯ç”¨ï¼Œå°†ä½œä¸ºæ™®é€šå¯¹è¯å¤„ç†")
                return {
                    "id": chat_id,
                    "object": "chat.completion",
                    "created": created_time,
                    "model": model,
                    "choices": [{
                        "index": 0,
                        "message": {
                            "role": "assistant",
                            "content": "æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å·¥å…·å®šä¹‰ï¼Œå°†ä½œä¸ºæ™®é€šå¯¹è¯å¤„ç†ã€‚"
                        },
                        "finish_reason": "stop"
                    }]
                }
            
            logger.info(f"ç›´æ¥ä½¿ç”¨Claudeæ¨¡å‹: {claude_model}")
            
            # å‡†å¤‡Claudeè°ƒç”¨å‚æ•°
            claude_kwargs = {
                "messages": messages,
                "model": claude_model,
                "temperature": kwargs.get("temperature", 0.7),
                "top_p": kwargs.get("top_p", 0.9),
                "tools": converted_tools
            }
            
            # å·¥å…·é€‰æ‹©ç­–ç•¥è½¬æ¢
            if isinstance(tool_choice, str):
                if tool_choice == "auto":
                    claude_kwargs["tool_choice"] = {"type": "auto"}
                elif tool_choice == "none":
                    # Claudeä¸æ”¯æŒnoneï¼Œå°†ä½¿ç”¨ç©ºå·¥å…·åˆ—è¡¨
                    logger.info("æ£€æµ‹åˆ°'none'å·¥å…·é€‰æ‹©ç­–ç•¥ï¼Œå°†ä¸ä½¿ç”¨å·¥å…·")
                    claude_kwargs.pop("tools")
            elif isinstance(tool_choice, dict):
                if tool_choice.get("type") == "function" and "function" in tool_choice:
                    # OpenAIæ ¼å¼è½¬ä¸ºClaudeæ ¼å¼
                    func_name = tool_choice["function"].get("name")
                    if func_name:
                        logger.info(f"æŒ‡å®šä½¿ç”¨å·¥å…·: {func_name}")
                        claude_kwargs["tool_choice"] = {
                            "type": "tool",
                            "name": func_name
                        }
                else:
                    # å·²æ˜¯Claudeæ ¼å¼æˆ–å…¶ä»–æ ¼å¼
                    claude_kwargs["tool_choice"] = tool_choice
            
            try:
                # éæµå¼è°ƒç”¨Claude API
                response = await self.claude_client.chat(**claude_kwargs)
                
                # å¤„ç†å·¥å…·è°ƒç”¨å“åº”
                if "tool_calls" in response:
                    tool_calls = response["tool_calls"]
                    logger.info(f"Claudeè¿”å›äº† {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")
                    
                    # æ„é€ æ ‡å‡†çš„OpenAIæ ¼å¼å“åº”
                    result = {
                        "id": chat_id,
                        "object": "chat.completion",
                        "created": created_time,
                        "model": model,
                        "choices": [{
                            "index": 0,
                            "message": {
                                "role": "assistant",
                                "content": None,
                                "tool_calls": tool_calls
                            },
                            "finish_reason": "tool_calls"
                        }],
                        "usage": {
                            "prompt_tokens": response.get("usage", {}).get("prompt_tokens", 0),
                            "completion_tokens": response.get("usage", {}).get("completion_tokens", 0),
                            "total_tokens": response.get("usage", {}).get("total_tokens", 0)
                        }
                    }
                    return result
                else:
                    # å¤„ç†æ™®é€šå›ç­”å“åº”
                    content = response.get("content", "")
                    if not content and "choices" in response and response["choices"]:
                        content = response["choices"][0].get("message", {}).get("content", "")
                        
                    result = {
                        "id": chat_id,
                        "object": "chat.completion",
                        "created": created_time,
                        "model": model,
                        "choices": [{
                            "index": 0,
                            "message": {
                                "role": "assistant",
                                "content": content
                            },
                            "finish_reason": "stop"
                        }],
                        "usage": {
                            "prompt_tokens": response.get("usage", {}).get("prompt_tokens", 0),
                            "completion_tokens": response.get("usage", {}).get("completion_tokens", 0),
                            "total_tokens": response.get("usage", {}).get("total_tokens", 0)
                        }
                    }
                    return result
            except Exception as e:
                logger.error(f"ç›´æ¥é€ä¼ æ¨¡å¼ä¸‹APIè°ƒç”¨å¤±è´¥: {e}", exc_info=True)
                # æ­¤å¤„é€‰æ‹©å›é€€åˆ°æ¨ç†-å›ç­”æ¨¡å¼ï¼Œè€Œä¸æ˜¯ç«‹å³è¿”å›é”™è¯¯
                logger.info("å°†å°è¯•ä½¿ç”¨æ¨ç†-å›ç­”æ¨¡å¼å¤„ç†è¯·æ±‚")
        
        # å‰©ä½™çš„ä»£ç ä¿æŒä¸å˜...