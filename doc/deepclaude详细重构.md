# DeepClaudeé¡¹ç›®é”™è¯¯ä¿®å¤ä¸é‡æ„æ–¹æ¡ˆ

## ä¸€ã€å½“å‰é”™è¯¯åˆ†æ

ä»é”™è¯¯ä¿¡æ¯æ¥çœ‹ï¼Œé—®é¢˜å‡ºåœ¨`deepclaude.py`æ–‡ä»¶çš„`_validate_and_convert_tools`æ–¹æ³•ä¸­ï¼š

```
[2025-03-04 12:57:12] [ERROR] [deepclaude.py:434] å¤„ç†æµå¼è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: 'custom'
Traceback (most recent call last):
  File "/Users/wanglei/code/DeepClaude/app/deepclaude/deepclaude.py", line 316, in chat_completions_with_stream
    converted_tools = self._validate_and_convert_tools(tools, target_format='claude-3')
  File "/Users/wanglei/code/DeepClaude/app/deepclaude/deepclaude.py", line 1398, in _validate_and_convert_tools
    if tool["type"] == "custom" and isinstance(tool.get("custom", {}), dict) and "type" in tool["custom"]:
                                                                                           ~~~~^^^^^^^^^^
KeyError: 'custom'
```

**é”™è¯¯åŸå› **ï¼šå·¥å…·ç±»å‹è¢«æ ‡è®°ä¸º`"custom"`ï¼Œä½†æ²¡æœ‰åŒ…å«å®é™…çš„`"custom"`å­—æ®µæ•°æ®ã€‚ä»£ç ä¸­å‡è®¾`tool["type"] == "custom"`çš„å·¥å…·ä¸€å®šä¼šæœ‰`tool["custom"]`å­—æ®µï¼Œç„¶è€Œè¿™ä¸ªå‡è®¾æ˜¯é”™è¯¯çš„ã€‚

## äºŒã€å³æ—¶é”™è¯¯ä¿®å¤æ–¹æ¡ˆ

ä¿®æ”¹`_validate_and_convert_tools`æ–¹æ³•ä¸­çš„æ¡ä»¶åˆ¤æ–­ï¼Œç¡®ä¿åœ¨æ£€æŸ¥`"custom"`å­—æ®µå†…éƒ¨å±æ€§å‰å…ˆç¡®è®¤è¯¥å­—æ®µå­˜åœ¨ï¼š

```python
# ä¿®æ”¹å‰
if tool["type"] == "custom" and isinstance(tool.get("custom", {}), dict) and "type" in tool["custom"]:

# ä¿®æ”¹å
if tool["type"] == "custom" and "custom" in tool and isinstance(tool["custom"], dict) and "type" in tool["custom"]:
```

æˆ–è€…æ›´å®‰å…¨çš„å†™æ³•ï¼š

```python
custom_field = tool.get("custom", {})
if tool["type"] == "custom" and isinstance(custom_field, dict) and "type" in custom_field:
```

## ä¸‰ã€ç³»ç»Ÿé‡æ„æ–¹æ¡ˆ

### 1. æ€»ä½“æ¶æ„è®¾è®¡

æŒ‰ç…§ç­–ç•¥æ¨¡å¼é‡æ„ç³»ç»Ÿï¼Œå°†`deepclaude.py`æ–‡ä»¶æ‹†åˆ†æˆå¤šä¸ªæ¨¡å—ï¼Œæ¯ä¸ªæ¨¡å—å¤„ç†ç‰¹å®šçš„åŠŸèƒ½ï¼š

```
app/
â”œâ”€â”€ deepclaude/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core.py                  # æ ¸å¿ƒåè°ƒç±»
â”‚   â”œâ”€â”€ interfaces.py            # æ¥å£å®šä¹‰
â”‚   â”œâ”€â”€ reasoning/               # æ¨ç†æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py              # æ¨ç†åŸºç¡€æ¥å£
â”‚   â”‚   â”œâ”€â”€ deepseek.py          # DeepSeekæ¨ç†å®ç°
â”‚   â”‚   â”œâ”€â”€ ollama.py            # Ollamaæ¨ç†å®ç°
â”‚   â”‚   â””â”€â”€ factory.py           # æ¨ç†ç­–ç•¥å·¥å‚
â”‚   â”œâ”€â”€ generation/              # ç”Ÿæˆæ¨¡å—
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py              # ç”ŸæˆåŸºç¡€æ¥å£
â”‚   â”‚   â”œâ”€â”€ claude.py            # Claudeç”Ÿæˆå®ç°
â”‚   â”‚   â””â”€â”€ factory.py           # ç”Ÿæˆç­–ç•¥å·¥å‚
â”‚   â”œâ”€â”€ tools/                   # å·¥å…·æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py              # å·¥å…·åŸºç¡€æ¥å£
â”‚   â”‚   â”œâ”€â”€ converters.py        # å·¥å…·æ ¼å¼è½¬æ¢
â”‚   â”‚   â”œâ”€â”€ handlers.py          # å·¥å…·å¤„ç†å®ç°
â”‚   â”‚   â””â”€â”€ validators.py        # å·¥å…·éªŒè¯é€»è¾‘
â”‚   â””â”€â”€ utils/                   # å·¥å…·å‡½æ•°
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ formatting.py        # æ ¼å¼åŒ–å·¥å…·
â”‚       â”œâ”€â”€ prompts.py           # æç¤ºè¯æ¨¡æ¿
â”‚       â””â”€â”€ streaming.py         # æµå¼å¤„ç†å·¥å…·
```

### 2. æ¥å£å®šä¹‰

åˆ›å»ºæ˜ç¡®çš„æ¥å£å®šä¹‰ï¼Œä»¥ä¿è¯å„ç»„ä»¶ä¹‹é—´çš„ä¸€è‡´æ€§ï¼š

```python
# app/deepclaude/interfaces.py

from abc import ABC, abstractmethod
from typing import AsyncGenerator, Dict, List, Any, Tuple, Optional

class ReasoningProvider(ABC):
    """æ¨ç†æœåŠ¡æä¾›è€…çš„æ¥å£å®šä¹‰"""
    
    @abstractmethod
    async def get_reasoning(self, messages: List[Dict], model: str, **kwargs) -> str:
        """è·å–æ¨ç†å†…å®¹"""
        pass

class GenerationProvider(ABC):
    """ç”ŸæˆæœåŠ¡æä¾›è€…çš„æ¥å£å®šä¹‰"""
    
    @abstractmethod
    async def generate_response(self, messages: List[Dict], model: str, **kwargs) -> Dict:
        """ç”Ÿæˆå›ç­”å†…å®¹"""
        pass
    
    @abstractmethod
    async def stream_response(self, messages: List[Dict], model: str, **kwargs) -> AsyncGenerator[Tuple[str, str], None]:
        """æµå¼ç”Ÿæˆå›ç­”å†…å®¹"""
        pass

class ToolProcessor(ABC):
    """å·¥å…·å¤„ç†å™¨çš„æ¥å£å®šä¹‰"""
    
    @abstractmethod
    def validate_and_convert(self, tools: List[Dict], target_format: str) -> List[Dict]:
        """éªŒè¯å¹¶è½¬æ¢å·¥å…·æ ¼å¼"""
        pass
    
    @abstractmethod
    async def process_tool_call(self, tool_call: Dict, **kwargs) -> Dict:
        """å¤„ç†å·¥å…·è°ƒç”¨"""
        pass
```

### 3. å…·ä½“å®ç°ç±»

#### æ¨ç†æ¨¡å—

```python
# app/deepclaude/reasoning/base.py
from ..interfaces import ReasoningProvider
from abc import abstractmethod
from typing import AsyncGenerator, Dict, List, Any, Tuple, Optional

class BaseReasoningProvider(ReasoningProvider):
    """æ¨ç†æä¾›è€…åŸºç±»"""
    
    def __init__(self, api_key: str = None, api_url: str = None):
        self.api_key = api_key
        self.api_url = api_url
        
    async def extract_reasoning_content(self, raw_content: str) -> str:
        """æå–æ¨ç†å†…å®¹çš„æ–¹æ³•ï¼Œå¯è¢«å­ç±»é‡å†™"""
        return raw_content
        
    @abstractmethod
    async def get_reasoning(self, messages: List[Dict], model: str, **kwargs) -> str:
        """è·å–æ¨ç†å†…å®¹çš„æŠ½è±¡æ–¹æ³•ï¼Œå¿…é¡»ç”±å­ç±»å®ç°"""
        pass
```

```python
# app/deepclaude/reasoning/deepseek.py
from .base import BaseReasoningProvider
from typing import AsyncGenerator, Dict, List, Any, Tuple, Optional
import os
import json
import aiohttp
from app.utils.logger import logger

class DeepSeekReasoningProvider(BaseReasoningProvider):
    """åŸºäºDeepSeekçš„æ¨ç†æä¾›è€…"""
    
    def __init__(self, api_key: str, api_url: str, provider: str = "deepseek"):
        super().__init__(api_key, api_url)
        self.provider = provider
        self.reasoning_mode = os.getenv('DEEPSEEK_REASONING_MODE', 'auto')
        
    async def extract_reasoning_from_think_tags(self, content: str) -> str:
        """ä»<think>æ ‡ç­¾ä¸­æå–æ¨ç†å†…å®¹"""
        if "<think>" in content and "</think>" in content:
            start = content.find("<think>") + 7
            end = content.find("</think>")
            if start < end:
                return content[start:end].strip()
        return ""
        
    async def get_reasoning(self, messages: List[Dict], model: str, **kwargs) -> str:
        """è·å–DeepSeekæ¨ç†å†…å®¹"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "Accept": "text/event-stream",
        }
        
        data = {
            "model": model,
            "messages": messages,
            "stream": True,
        }
        
        # é’ˆå¯¹ä¸åŒæä¾›å•†çš„é…ç½®è°ƒæ•´
        if self.provider == 'nvidia':
            temperature = kwargs.get('temperature', 0.6)
            top_p = kwargs.get('top_p', 0.7)
            data.update({
                "temperature": temperature,
                "top_p": top_p,
                "max_tokens": 4096
            })
            
        reasoning_content = []
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    self.api_url,
                    headers=headers,
                    json=data,
                    timeout=aiohttp.ClientTimeout(total=60)
                ) as response:
                    if response.status != 200:
                        error_text = await response.text()
                        logger.error(f"APIè¯·æ±‚å¤±è´¥: HTTP {response.status}\n{error_text}")
                        raise Exception(f"HTTP {response.status}: {error_text}")
                    
                    async for line in response.content.iter_lines():
                        line_str = line.decode('utf-8')
                        if not line_str.strip() or not line_str.startswith('data:'):
                            continue
                        
                        data_json = line_str[5:].strip()
                        if data_json == "[DONE]":
                            continue
                            
                        try:
                            data = json.loads(data_json)
                            if not data.get("choices"):
                                continue
                                
                            delta = data["choices"][0].get("delta", {})
                            
                            # æ ¹æ®æ¨ç†æ¨¡å¼æå–å†…å®¹
                            if self.reasoning_mode == 'reasoning_field':
                                reasoning = data["choices"][0].get("reasoning_content")
                                if reasoning:
                                    reasoning_content.append(reasoning)
                            elif self.reasoning_mode == 'think_tags':
                                content = delta.get("content", "")
                                if "<think>" in content:
                                    reasoning = await self.extract_reasoning_from_think_tags(content)
                                    if reasoning:
                                        reasoning_content.append(reasoning)
                            else:  # auto or any_content
                                content = delta.get("content", "")
                                if content:
                                    reasoning_content.append(content)
                        except json.JSONDecodeError:
                            continue
                            
            return "".join(reasoning_content)
        except Exception as e:
            logger.error(f"è·å–æ¨ç†å†…å®¹å¤±è´¥: {e}", exc_info=True)
            raise
```

```python
# app/deepclaude/reasoning/factory.py
from .base import BaseReasoningProvider
from .deepseek import DeepSeekReasoningProvider
from .ollama import OllamaReasoningProvider
import os
from app.utils.logger import logger

class ReasoningProviderFactory:
    """æ¨ç†æä¾›è€…å·¥å‚"""
    
    @staticmethod
    def create(provider_type: str = None) -> BaseReasoningProvider:
        """åˆ›å»ºæ¨ç†æä¾›è€…å®ä¾‹"""
        provider_type = provider_type or os.getenv('REASONING_PROVIDER', 'deepseek').lower()
        
        if provider_type == 'deepseek':
            api_key = os.getenv('DEEPSEEK_API_KEY')
            api_url = os.getenv('DEEPSEEK_API_URL')
            return DeepSeekReasoningProvider(api_key, api_url, provider='deepseek')
        elif provider_type == 'siliconflow':
            api_key = os.getenv('DEEPSEEK_API_KEY')
            api_url = os.getenv('DEEPSEEK_API_URL', 'https://api.siliconflow.cn/v1/chat/completions')
            return DeepSeekReasoningProvider(api_key, api_url, provider='siliconflow')
        elif provider_type == 'nvidia':
            api_key = os.getenv('DEEPSEEK_API_KEY')
            api_url = os.getenv('DEEPSEEK_API_URL')
            return DeepSeekReasoningProvider(api_key, api_url, provider='nvidia')
        elif provider_type == 'ollama':
            api_url = os.getenv('OLLAMA_API_URL')
            return OllamaReasoningProvider(api_url=api_url)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨ç†æä¾›è€…ç±»å‹: {provider_type}")
```

#### å·¥å…·æ¨¡å—

```python
# app/deepclaude/tools/base.py
from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional

class ToolProcessor(ABC):
    """å·¥å…·å¤„ç†å™¨åŸºç±»"""
    
    @abstractmethod
    def validate_and_convert(self, tools: List[Dict], target_format: str) -> List[Dict]:
        """éªŒè¯å¹¶è½¬æ¢å·¥å…·æ ¼å¼"""
        pass
```

```python
# app/deepclaude/tools/validators.py
from typing import Dict, List, Any, Optional
from app.utils.logger import logger

class ToolValidator:
    """å·¥å…·éªŒè¯å™¨ï¼Œç”¨äºéªŒè¯å·¥å…·æ ¼å¼çš„æœ‰æ•ˆæ€§"""
    
    @staticmethod
    def is_valid_openai_function(tool: Dict) -> bool:
        """éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆçš„OpenAIå‡½æ•°å·¥å…·æ ¼å¼"""
        if not isinstance(tool, dict):
            return False
            
        if "function" not in tool:
            return False
            
        function = tool["function"]
        if not isinstance(function, dict):
            return False
            
        if "name" not in function:
            return False
            
        return True
        
    @staticmethod
    def is_valid_claude_custom_tool(tool: Dict) -> bool:
        """éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆçš„Claudeè‡ªå®šä¹‰å·¥å…·æ ¼å¼"""
        if not isinstance(tool, dict):
            return False
            
        if "type" not in tool or tool["type"] != "custom":
            return False
            
        if "name" not in tool:
            return False
            
        return True
        
    @staticmethod
    def has_nested_custom_type(tool: Dict) -> bool:
        """æ£€æŸ¥Claudeè‡ªå®šä¹‰å·¥å…·ä¸­æ˜¯å¦æœ‰åµŒå¥—çš„typeå­—æ®µ"""
        if not isinstance(tool, dict) or "type" not in tool or tool["type"] != "custom":
            return False
            
        custom_field = tool.get("custom", {})
        return isinstance(custom_field, dict) and "type" in custom_field
```

```python
# app/deepclaude/tools/converters.py
from typing import Dict, List, Any, Optional
from app.utils.logger import logger
from .validators import ToolValidator

class ToolConverter:
    """å·¥å…·è½¬æ¢å™¨ï¼Œç”¨äºåœ¨ä¸åŒæ ¼å¼é—´è½¬æ¢å·¥å…·å®šä¹‰"""
    
    @staticmethod
    def openai_to_claude(tool: Dict) -> Dict:
        """å°†OpenAIæ ¼å¼å·¥å…·è½¬æ¢ä¸ºClaudeæ ¼å¼"""
        if not ToolValidator.is_valid_openai_function(tool):
            logger.warning(f"å·¥å…·æ ¼å¼é”™è¯¯ï¼Œæ— æ³•è½¬æ¢: {tool}")
            return None
            
        function_data = tool["function"]
        name = function_data.get("name", "æœªå‘½åå·¥å…·")
        description = function_data.get("description", "")
        parameters = function_data.get("parameters", {})
        
        claude_tool = {
            "type": "custom",
            "name": name,
            "description": description,
            "tool_schema": parameters
        }
        
        return claude_tool
        
    @staticmethod
    def claude_to_openai(tool: Dict) -> Dict:
        """å°†Claudeæ ¼å¼å·¥å…·è½¬æ¢ä¸ºOpenAIæ ¼å¼"""
        if not ToolValidator.is_valid_claude_custom_tool(tool):
            logger.warning(f"å·¥å…·æ ¼å¼é”™è¯¯ï¼Œæ— æ³•è½¬æ¢: {tool}")
            return None
            
        name = tool.get("name", "æœªå‘½åå·¥å…·")
        description = tool.get("description", "")
        schema = tool.get("tool_schema", {})
        
        openai_tool = {
            "type": "function",
            "function": {
                "name": name,
                "description": description,
                "parameters": schema
            }
        }
        
        return openai_tool
        
    @staticmethod
    def fix_claude_custom_tool(tool: Dict) -> Dict:
        """ä¿®å¤Claudeè‡ªå®šä¹‰å·¥å…·ä¸­çš„åµŒå¥—typeå­—æ®µé—®é¢˜"""
        if not ToolValidator.is_valid_claude_custom_tool(tool):
            return tool
            
        if ToolValidator.has_nested_custom_type(tool):
            fixed_tool = tool.copy()
            fixed_tool["custom"] = tool["custom"].copy()
            fixed_tool["custom"].pop("type", None)
            logger.debug(f"å·²ä¿®å¤å·¥å…·ä¸­çš„åµŒå¥—typeå­—æ®µ: {tool.get('name', 'æœªå‘½åå·¥å…·')}")
            return fixed_tool
            
        return tool
```

```python
# app/deepclaude/tools/handlers.py
from typing import Dict, List, Any, Optional
from app.utils.logger import logger
from .validators import ToolValidator
from .converters import ToolConverter
import uuid

class ToolHandler:
    """å·¥å…·å¤„ç†å™¨ï¼Œç”¨äºå¤„ç†å·¥å…·è°ƒç”¨å’Œç»“æœ"""
    
    @staticmethod
    def validate_and_convert_tools(tools: List[Dict], target_format: str = 'claude-3') -> List[Dict]:
        """éªŒè¯å¹¶è½¬æ¢å·¥å…·æ ¼å¼"""
        if not tools:
            return []
            
        valid_tools = []
        for tool in tools:
            if not isinstance(tool, dict):
                logger.warning(f"å·¥å…·æ ¼å¼é”™è¯¯: {tool}")
                continue
                
            # å¤„ç†å·²ç»æ˜¯Claudeæ ¼å¼çš„å·¥å…·
            if "type" in tool and tool["type"] in ["custom", "bash_20250124", "text_editor_20250124"]:
                if tool["type"] == "custom":
                    # ä¿®å¤å¯èƒ½å­˜åœ¨çš„åµŒå¥—typeå­—æ®µé—®é¢˜
                    fixed_tool = ToolConverter.fix_claude_custom_tool(tool)
                    valid_tools.append(fixed_tool)
                else:
                    valid_tools.append(tool)
                logger.info(f"æ£€æµ‹åˆ°å·²æ˜¯Claudeæ ¼å¼çš„å·¥å…·: {tool.get('name', 'æœªå‘½åå·¥å…·')}")
                continue
                
            # å¤„ç†OpenAIæ ¼å¼å·¥å…·
            if "function" in tool:
                if target_format == 'claude-3':
                    claude_tool = ToolConverter.openai_to_claude(tool)
                    if claude_tool:
                        valid_tools.append(claude_tool)
                        logger.info(f"å°†OpenAIæ ¼å¼å·¥å…·è½¬æ¢ä¸ºClaudeæ ¼å¼: {claude_tool.get('name', 'æœªå‘½åå·¥å…·')}")
                else:
                    if "type" not in tool:
                        tool = {"type": "function", "function": tool["function"]}
                    valid_tools.append(tool)
                    logger.info(f"ä¿æŒOpenAIæ ¼å¼å·¥å…·: {tool['function'].get('name', 'æœªå‘½åå·¥å…·')}")
                continue
                
            # å¤„ç†ç®€åŒ–æ ¼å¼å·¥å…·
            if "name" in tool and "parameters" in tool:
                if target_format == 'claude-3':
                    simple_tool = {
                        "type": "custom",
                        "name": tool.get("name", "æœªå‘½åå·¥å…·"),
                        "description": tool.get("description", ""),
                        "tool_schema": tool.get("parameters", {})
                    }
                    valid_tools.append(simple_tool)
                    logger.info(f"å·²å°†ç®€åŒ–æ ¼å¼å·¥å…·è½¬ä¸ºClaudeæ ¼å¼: {tool.get('name', 'æœªå‘½åå·¥å…·')}")
                else:
                    openai_tool = {
                        "type": "function",
                        "function": {
                            "name": tool.get("name", "æœªå‘½åå·¥å…·"),
                            "description": tool.get("description", ""),
                            "parameters": tool.get("parameters", {})
                        }
                    }
                    valid_tools.append(openai_tool)
                    logger.info(f"å·²å°†ç®€åŒ–æ ¼å¼å·¥å…·è½¬ä¸ºOpenAIæ ¼å¼: {tool.get('name', 'æœªå‘½åå·¥å…·')}")
                continue
                
            logger.warning(f"å·¥å…·æ ¼å¼æ— æ³•è¯†åˆ«: {tool}")
            
        logger.info(f"å·¥å…·éªŒè¯å’Œè½¬æ¢å®Œæˆï¼ŒåŸæœ‰ {len(tools)} ä¸ªå·¥å…·ï¼Œæœ‰æ•ˆ {len(valid_tools)} ä¸ªå·¥å…·")
        return valid_tools
    
    @staticmethod
    def format_tool_call_for_streaming(tool_call: Dict, chat_id: str = None, created_time: int = None) -> Dict:
        """æ ¼å¼åŒ–å·¥å…·è°ƒç”¨ä¸ºæµå¼å“åº”æ ¼å¼"""
        tool_call_id = tool_call.get("id")
        if not tool_call_id:
            tool_call_id = f"call_{uuid.uuid4().hex[:8]}"
            
        function = tool_call.get("function", {})
        function_name = function.get("name", "")
        function_args = function.get("arguments", "{}")
        
        response = {
            "id": chat_id or f"chatcmpl-{uuid.uuid4()}",
            "object": "chat.completion.chunk",
            "created": created_time or 0,
            "model": "deepclaude",
            "choices": [{
                "index": 0,
                "delta": {
                    "role": "assistant",
                    "content": None,
                    "tool_calls": [
                        {
                            "index": 0,
                            "id": tool_call_id,
                            "type": "function",
                            "function": {
                                "name": function_name,
                                "arguments": function_args
                            }
                        }
                    ]
                },
                "finish_reason": "tool_calls"
            }]
        }
        
        return response
```

### 4. æ ¸å¿ƒåè°ƒç±»

```python
# app/deepclaude/core.py
from typing import AsyncGenerator, Dict, List, Any, Tuple, Optional
import os
import json
import uuid
import time
from app.utils.logger import logger
from .reasoning.factory import ReasoningProviderFactory
from .tools.handlers import ToolHandler
from app.clients.claude_client import ClaudeClient

class DeepClaude:
    """DeepClaudeæ ¸å¿ƒåè°ƒç±»ï¼Œæ•´åˆæ¨ç†ä¸ç”ŸæˆåŠŸèƒ½"""
    
    def __init__(self, **kwargs):
        logger.info("åˆå§‹åŒ–DeepClaudeæœåŠ¡...")
        
        # é…ç½®å‚æ•°
        self.claude_api_key = kwargs.get('claude_api_key', os.getenv('CLAUDE_API_KEY', ''))
        self.claude_api_url = kwargs.get('claude_api_url', os.getenv('CLAUDE_API_URL', 'https://api.anthropic.com/v1/messages'))
        self.claude_provider = kwargs.get('claude_provider', os.getenv('CLAUDE_PROVIDER', 'anthropic'))
        self.is_origin_reasoning = kwargs.get('is_origin_reasoning', os.getenv('IS_ORIGIN_REASONING', 'false').lower() == 'true')
        self.min_reasoning_chars = 100
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.claude_client = ClaudeClient(
            api_key=self.claude_api_key,
            api_url=self.claude_api_url,
            provider=self.claude_provider
        )
        
        self.tool_handler = ToolHandler()
        
        # åˆå§‹åŒ–æ¨ç†æä¾›è€…
        provider_type = os.getenv('REASONING_PROVIDER', 'deepseek').lower()
        self.thinker_client = ReasoningProviderFactory.create(provider_type)
        
        # æ•°æ®åº“å­˜å‚¨é…ç½®
        self.save_to_db = kwargs.get('save_to_db', os.getenv('SAVE_TO_DB', 'false').lower() == 'true')
        if self.save_to_db:
            logger.info("å¯ç”¨æ•°æ®åº“å­˜å‚¨...")
            from app.database.db_operations import DatabaseOperations
            self.db_ops = kwargs.get('db_ops', DatabaseOperations())
            self.current_conversation_id = None
        else:
            logger.info("æ•°æ®åº“å­˜å‚¨å·²ç¦ç”¨")
            self.db_ops = None
            
        logger.info("DeepClaudeæœåŠ¡åˆå§‹åŒ–å®Œæˆ")
        
    async def chat_completions_with_stream(self, messages: list, tools: list = None, tool_choice = "auto", **kwargs):
        """å¤„ç†æµå¼èŠå¤©è¯·æ±‚"""
        chat_id = kwargs.get("chat_id", f"chatcmpl-{uuid.uuid4()}")
        created_time = kwargs.get("created_time", int(time.time()))
        model = kwargs.get("model", "deepclaude")
        claude_model = os.getenv('CLAUDE_MODEL', 'claude-3-7-sonnet-20250219')
        deepseek_model = kwargs.get("deepseek_model", "deepseek-reasoner")
        
        try:
            logger.info("å¼€å§‹æµå¼å¤„ç†è¯·æ±‚...")
            
            # å¦‚æœæœ‰å·¥å…·ä¸”ç›´æ¥é€ä¼ æ¨¡å¼å¼€å¯ï¼Œåˆ™ç›´æ¥ä½¿ç”¨Claudeå¤„ç†
            direct_tool_pass = os.getenv('CLAUDE_DIRECT_TOOL_PASS', 'true').lower() == 'true'
            if direct_tool_pass and tools and len(tools) > 0:
                logger.info(f"ç›´æ¥é€ä¼ æ¨¡å¼(æµå¼): åŒ…å« {len(tools)} ä¸ªå·¥å…·")
                
                # éªŒè¯å¹¶è½¬æ¢å·¥å…·æ ¼å¼
                converted_tools = self.tool_handler.validate_and_convert_tools(tools, target_format='claude-3')
                if not converted_tools:
                    logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„å·¥å…·å¯ç”¨ï¼Œå°†ä½œä¸ºæ™®é€šå¯¹è¯å¤„ç†")
                    result = {
                        "id": chat_id,
                        "object": "chat.completion",
                        "created": created_time,
                        "model": model,
                        "choices": [{
                            "index": 0,
                            "message": {
                                "role": "assistant",
                                "content": "æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å·¥å…·å®šä¹‰ï¼Œå°†ä½œä¸ºæ™®é€šå¯¹è¯å¤„ç†ã€‚"
                            },
                            "finish_reason": "stop"
                        }]
                    }
                    yield f"data: {json.dumps(result, ensure_ascii=False)}\n\ndata: [DONE]\n\n".encode("utf-8")
                    return
                
                # å‡†å¤‡Claude APIè°ƒç”¨å‚æ•°
                claude_kwargs = {
                    "messages": messages,
                    "model": claude_model,
                    "temperature": kwargs.get("temperature", 0.7),
                    "top_p": kwargs.get("top_p", 0.9),
                    "tools": converted_tools
                }
                
                # é…ç½®å·¥å…·é€‰æ‹©ç­–ç•¥
                if isinstance(tool_choice, str):
                    if tool_choice == "auto":
                        claude_kwargs["tool_choice"] = {"type": "auto"}
                    elif tool_choice == "none":
                        logger.info("æ£€æµ‹åˆ°'none'å·¥å…·é€‰æ‹©ç­–ç•¥ï¼Œå°†ä¸ä½¿ç”¨å·¥å…·")
                        claude_kwargs.pop("tools")
                elif isinstance(tool_choice, dict):
                    claude_kwargs["tool_choice"] = tool_choice
                
                # ç›´æ¥æµå¼è°ƒç”¨Claudeå¹¶é€ä¼ å“åº”
                async for content_type, content in self.claude_client.stream_chat(**claude_kwargs):
                    if content_type == "content":
                        response = {
                            "id": chat_id,
                            "object": "chat.completion.chunk",
                            "created": created_time,
                            "model": model,
                            # "choices": [{
                            #     "index": 0,
                            #     "delta": {
                            #         "role": "assistant",
                            #         "content": content
                            #     }
                            # }]
```python
                            "choices": [{
                                "index": 0,
                                "delta": {
                                    "role": "assistant",
                                    "content": content
                                }
                            }]
                        }
                        yield f"data: {json.dumps(response, ensure_ascii=False)}\n\n".encode("utf-8")
                    elif content_type == "tool_call":
                        tool_call_response = self.tool_handler.format_tool_call_for_streaming(
                            content, chat_id=chat_id, created_time=created_time
                        )
                        yield f"data: {json.dumps(tool_call_response, ensure_ascii=False)}\n\n".encode("utf-8")
                        
                yield f"data: [DONE]\n\n".encode("utf-8")
                return
            
            # æ¨ç†-ç”Ÿæˆæ¨¡å¼å¤„ç†
            original_question = messages[-1]["content"] if messages and messages[-1]["role"] == "user" else ""
            
            # ä¿å­˜å¯¹è¯åˆ°æ•°æ®åº“
            if self.save_to_db:
                try:
                    user_id = None
                    title = original_question[:20] + "..." if original_question else None
                    self.current_conversation_id = self.db_ops.create_conversation(
                        user_id=user_id,
                        title=title
                    )
                    logger.info(f"åˆ›å»ºæ–°å¯¹è¯ï¼ŒID: {self.current_conversation_id}")
                    self.db_ops.add_conversation_history(
                        conversation_id=self.current_conversation_id,
                        role="user",
                        content=original_question
                    )
                except Exception as db_e:
                    logger.error(f"ä¿å­˜å¯¹è¯æ•°æ®å¤±è´¥: {db_e}")
            
            # è·å–æ¨ç†å†…å®¹
            logger.info("æ­£åœ¨è·å–æ¨ç†å†…å®¹...")
            try:
                reasoning = await self.thinker_client.get_reasoning(
                    messages=messages,
                    model=deepseek_model
                )
            except Exception as e:
                logger.error(f"è·å–æ¨ç†å†…å®¹å¤±è´¥: {e}")
                reasoning = "æ— æ³•è·å–æ¨ç†å†…å®¹"
            
            # è¾“å‡ºæ¨ç†è¿‡ç¨‹
            if reasoning:
                reasoning_response = {
                    "id": chat_id,
                    "object": "chat.completion.chunk",
                    "created": created_time,
                    "model": model,
                    "is_reasoning": True,
                    "choices": [{
                        "index": 0,
                        "delta": {
                            "role": "assistant",
                            "content": f"ğŸ¤” æ€è€ƒè¿‡ç¨‹:\n{reasoning}\n",
                            "reasoning": True
                        }
                    }]
                }
                yield f"data: {json.dumps(reasoning_response, ensure_ascii=False)}\n\n".encode("utf-8")
            
            # å¤„ç†å·¥å…·è°ƒç”¨
            has_tool_decision = False
            if tools and len(tools) > 0:
                try:
                    decision_prompt = self._format_tool_decision_prompt(original_question, reasoning, tools)
                    logger.debug(f"å·¥å…·å†³ç­–æç¤º: {decision_prompt[:200]}...")
                    
                    tool_decision_response = await self.claude_client.chat(
                        messages=[{"role": "user", "content": decision_prompt}],
                        model=claude_model,
                        tools=tools,
                        tool_choice=tool_choice,
                        temperature=kwargs.get("temperature", 0.7),
                        top_p=kwargs.get("top_p", 0.9)
                    )
                    
                    if "tool_calls" in tool_decision_response:
                        tool_calls = tool_decision_response.get("tool_calls", [])
                        has_tool_decision = True
                        logger.info(f"Claudeå†³å®šä½¿ç”¨å·¥å…·: {len(tool_calls)}ä¸ªå·¥å…·è°ƒç”¨")
                        
                        response = {
                            "id": chat_id,
                            "object": "chat.completion",
                            "created": created_time,
                            "model": model,
                            "choices": [{
                                "index": 0,
                                "message": {
                                    "role": "assistant",
                                    "content": None,
                                    "tool_calls": tool_calls
                                },
                                "finish_reason": "tool_calls"
                            }]
                        }
                        yield f"data: {json.dumps(response, ensure_ascii=False)}\n\ndata: [DONE]\n\n".encode("utf-8")
                        return
                except Exception as tool_e:
                    logger.error(f"å·¥å…·è°ƒç”¨æµç¨‹å¤±è´¥: {tool_e}", exc_info=True)
            
            # å¦‚æœæ²¡æœ‰ä½¿ç”¨å·¥å…·ï¼Œæ­£å¸¸ç”Ÿæˆæ–‡æœ¬å›ç­”
            if not has_tool_decision:
                combined_prompt = f"æˆ‘å·²ç»æ€è€ƒäº†ä»¥ä¸‹é—®é¢˜ï¼š\n\n{original_question}\n\næˆ‘çš„æ€è€ƒè¿‡ç¨‹æ˜¯ï¼š\n{reasoning}\n\nç°åœ¨ï¼Œç»™å‡ºæ¸…æ™°ã€å‡†ç¡®ã€æœ‰å¸®åŠ©çš„å›ç­”ï¼Œä¸è¦æåŠä¸Šé¢çš„æ€è€ƒè¿‡ç¨‹ï¼Œç›´æ¥å¼€å§‹å›ç­”ã€‚"
                claude_messages = [{"role": "user", "content": combined_prompt}]
                
                logger.info("æ­£åœ¨è·å–Claudeå›ç­”...")
                
                full_content = ""
                async for content_type, content in self.claude_client.stream_chat(
                    messages=claude_messages,
                    model=claude_model,
                    temperature=kwargs.get("temperature", 0.7),
                    top_p=kwargs.get("top_p", 0.9)
                ):
                    if content_type in ["answer", "content"]:
                        response = {
                            "id": chat_id,
                            "object": "chat.completion.chunk",
                            "created": created_time,
                            "model": model,
                            "choices": [{
                                "index": 0,
                                "delta": {
                                    "role": "assistant",
                                    "content": content
                                }
                            }]
                        }
                        full_content += content
                        yield f"data: {json.dumps(response, ensure_ascii=False)}\n\n".encode("utf-8")
                
                # ä¿å­˜å›ç­”åˆ°æ•°æ®åº“
                if self.save_to_db and self.current_conversation_id:
                    try:
                        tokens = len(reasoning.split()) + len(full_content.split())
                        self.db_ops.add_conversation_history(
                            conversation_id=self.current_conversation_id,
                            role="ai",
                            content=full_content,
                            reasoning=reasoning,
                            model_name=claude_model,
                            tokens=tokens
                        )
                        logger.info("AIå›ç­”å’Œæ€è€ƒè¿‡ç¨‹å·²ä¿å­˜åˆ°æ•°æ®åº“")
                    except Exception as db_e:
                        logger.error(f"ä¿å­˜AIå›ç­”æ•°æ®å¤±è´¥: {db_e}")
                
                yield f"data: [DONE]\n\n".encode("utf-8")
        
        except Exception as e:
            logger.error(f"å¤„ç†æµå¼è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
            error_response = {
                "error": {
                    "message": str(e),
                    "type": "server_error",
                    "code": "internal_error"
                }
            }
            yield f"data: {json.dumps(error_response, ensure_ascii=False)}\n\ndata: [DONE]\n\n".encode("utf-8")
    
    async def chat_completions_without_stream(
        self,
        messages: list,
        model_arg: tuple,
        tools: list = None,
        tool_choice = "auto",
        deepseek_model: str = "deepseek-reasoner",
        claude_model: str = os.getenv('CLAUDE_MODEL', 'claude-3-7-sonnet-20250219'),
        **kwargs
    ) -> dict:
        """å¤„ç†éæµå¼èŠå¤©è¯·æ±‚"""
        logger.info("å¼€å§‹å¤„ç†éæµå¼è¯·æ±‚...")
        
        try:
            # ç›´æ¥å·¥å…·é€ä¼ æ¨¡å¼
            direct_tool_pass = os.getenv('CLAUDE_DIRECT_TOOL_PASS', 'true').lower() == 'true'
            if direct_tool_pass and tools and len(tools) > 0:
                logger.info(f"ç›´æ¥é€ä¼ æ¨¡å¼(éæµå¼): åŒ…å« {len(tools)} ä¸ªå·¥å…·")
                
                # éªŒè¯å¹¶è½¬æ¢å·¥å…·
                converted_tools = self.tool_handler.validate_and_convert_tools(tools, target_format='claude-3')
                if not converted_tools:
                    return {
                        "choices": [{
                            "index": 0,
                            "message": {
                                "role": "assistant",
                                "content": "æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å·¥å…·å®šä¹‰ï¼Œå°†ä½œä¸ºæ™®é€šå¯¹è¯å¤„ç†ã€‚"
                            },
                            "finish_reason": "stop"
                        }]
                    }
                
                # å‡†å¤‡Claude APIè°ƒç”¨å‚æ•°
                claude_kwargs = {
                    "messages": messages,
                    "model": claude_model,
                    "temperature": kwargs.get("temperature", 0.7),
                    "top_p": kwargs.get("top_p", 0.9),
                    "tools": converted_tools,
                    "stream": False
                }
                
                # é…ç½®å·¥å…·é€‰æ‹©ç­–ç•¥
                if isinstance(tool_choice, str):
                    if tool_choice == "auto":
                        claude_kwargs["tool_choice"] = {"type": "auto"}
                    elif tool_choice == "none":
                        logger.info("æ£€æµ‹åˆ°'none'å·¥å…·é€‰æ‹©ç­–ç•¥ï¼Œå°†ä¸ä½¿ç”¨å·¥å…·")
                        claude_kwargs.pop("tools")
                elif isinstance(tool_choice, dict):
                    claude_kwargs["tool_choice"] = tool_choice
                
                # è°ƒç”¨Claude API
                response = await self.claude_client.chat(**claude_kwargs)
                return response
            
            # æ¨ç†-å›ç­”æ¨¡å¼
            original_question = messages[-1]["content"] if messages and messages[-1]["role"] == "user" else ""
            
            # è·å–æ¨ç†å†…å®¹
            logger.info("æ­£åœ¨è·å–æ¨ç†å†…å®¹...")
            reasoning = await self.thinker_client.get_reasoning(
                messages=messages,
                model=deepseek_model,
                model_arg=model_arg
            )
            logger.debug(f"è·å–åˆ°æ¨ç†å†…å®¹: {reasoning[:200] if reasoning else 'æ— '}...")
            
            # ç”Ÿæˆæœ€ç»ˆå›ç­”
            combined_prompt = f"æˆ‘å·²ç»æ€è€ƒäº†ä»¥ä¸‹é—®é¢˜ï¼š\n\n{original_question}\n\næˆ‘çš„æ€è€ƒè¿‡ç¨‹æ˜¯ï¼š\n{reasoning}\n\nç°åœ¨ï¼Œç»™å‡ºæ¸…æ™°ã€å‡†ç¡®ã€æœ‰å¸®åŠ©çš„å›ç­”ï¼Œä¸è¦æåŠä¸Šé¢çš„æ€è€ƒè¿‡ç¨‹ï¼Œç›´æ¥å¼€å§‹å›ç­”ã€‚"
            claude_messages = [{"role": "user", "content": combined_prompt}]
            
            logger.info("æ­£åœ¨è·å–Claudeå›ç­”...")
            answer_response = await self.claude_client.chat(
                messages=claude_messages,
                model=claude_model,
                temperature=model_arg[0] if model_arg else 0.7,
                top_p=model_arg[1] if model_arg else 0.9,
                stream=False
            )
            
            content = answer_response.get("content", "")
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            if self.save_to_db and self.current_conversation_id:
                try:
                    tokens = len(reasoning.split()) + len(content.split())
                    self.db_ops.add_conversation_history(
                        conversation_id=self.current_conversation_id,
                        role="ai",
                        content=content,
                        reasoning=reasoning,
                        model_name=claude_model,
                        tokens=tokens
                    )
                    logger.info("AIå›ç­”å’Œæ€è€ƒè¿‡ç¨‹å·²ä¿å­˜åˆ°æ•°æ®åº“")
                except Exception as db_e:
                    logger.error(f"ä¿å­˜AIå›ç­”æ•°æ®å¤±è´¥: {db_e}")
            
            return {
                "role": "assistant",
                "content": content,
                "reasoning": reasoning
            }
            
        except Exception as e:
            logger.error(f"å¤„ç†éæµå¼è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
            return {
                "role": "assistant",
                "content": f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}",
                "error": True
            }
            
    def _format_tool_decision_prompt(self, original_question: str, reasoning: str, tools: List[Dict]) -> str:
        """æ ¼å¼åŒ–å·¥å…·å†³ç­–æç¤º"""
        tools_description = ""
        
        for i, tool in enumerate(tools, 1):
            if "function" in tool:
                function = tool["function"]
                name = function.get("name", "æœªå‘½åå·¥å…·")
                description = function.get("description", "æ— æè¿°")
                parameters = function.get("parameters", {})
                required = parameters.get("required", [])
                properties = parameters.get("properties", {})
                
                param_desc = ""
                for param_name, param_info in properties.items():
                    is_required = "å¿…å¡«" if param_name in required else "å¯é€‰"
                    param_type = param_info.get("type", "æœªçŸ¥ç±»å‹")
                    param_description = param_info.get("description", "æ— æè¿°")
                    enum_values = param_info.get("enum", [])
                    
                    enum_desc = ""
                    if enum_values:
                        enum_desc = f"ï¼Œå¯é€‰å€¼: {', '.join([str(v) for v in enum_values])}"
                        
                    param_desc += f"  - {param_name} ({param_type}, {is_required}): {param_description}{enum_desc}\n"
                    
                tools_description += f"{i}. å·¥å…·åç§°: {name}\n   æè¿°: {description}\n   å‚æ•°:\n{param_desc}\n"
            
            elif "type" in tool and tool["type"] == "custom":
                name = tool.get("name", "æœªå‘½åå·¥å…·")
                description = tool.get("description", "æ— æè¿°")
                tool_schema = tool.get("tool_schema", {})
                required = tool_schema.get("required", [])
                properties = tool_schema.get("properties", {})
                
                param_desc = ""
                for param_name, param_info in properties.items():
                    is_required = "å¿…å¡«" if param_name in required else "å¯é€‰"
                    param_type = param_info.get("type", "æœªçŸ¥ç±»å‹")
                    param_description = param_info.get("description", "æ— æè¿°")
                    enum_values = param_info.get("enum", [])
                    
                    enum_desc = ""
                    if enum_values:
                        enum_desc = f"ï¼Œå¯é€‰å€¼: {', '.join([str(v) for v in enum_values])}"
                        
                    param_desc += f"  - {param_name} ({param_type}, {is_required}): {param_description}{enum_desc}\n"
                    
                tools_description += f"{i}. å·¥å…·åç§°: {name}\n   æè¿°: {description}\n   å‚æ•°:\n{param_desc}\n"
        
        prompt = f"""ç”¨æˆ·é—®é¢˜ï¼š{original_question}

æˆ‘çš„æ€è€ƒè¿‡ç¨‹ï¼š
{reasoning}

å¯ç”¨å·¥å…·ï¼š
{tools_description}

1. ä»”ç»†åˆ†æç”¨æˆ·é—®é¢˜å’Œæ€è€ƒè¿‡ç¨‹ã€‚
2. åˆ¤æ–­æ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·æ¥å›ç­”é—®é¢˜ã€‚
3. å¦‚æœéœ€è¦ä½¿ç”¨å·¥å…·ï¼Œè¯·ä½¿ç”¨æœ€åˆé€‚çš„å·¥å…·å¹¶æä¾›æ‰€æœ‰å¿…è¦çš„å‚æ•°ã€‚
4. å¦‚æœä¸éœ€è¦ä½¿ç”¨å·¥å…·ï¼Œç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"""

        return prompt
```

### 5. å·¥å…·å‡½æ•°ä¸è¾…åŠ©æ¨¡å—

```python
# app/deepclaude/utils/prompts.py
"""æä¾›å„ç§æç¤ºè¯æ¨¡æ¿"""

class PromptTemplates:
    """æç¤ºè¯æ¨¡æ¿é›†åˆ"""
    
    @staticmethod
    def reasoning_prompt(question: str) -> str:
        """ç”Ÿæˆæ¨ç†æç¤ºæ¨¡æ¿"""
        return f"""è¯·æ€è€ƒä¸‹é¢è¿™ä¸ªé—®é¢˜ï¼Œç»™å‡ºè¯¦ç»†çš„åˆ†æè¿‡ç¨‹ï¼š

{question}

åˆ†ææ€è·¯ï¼š
"""

    @staticmethod
    def tool_decision_prompt(question: str, reasoning: str, tools_description: str) -> str:
        """ç”Ÿæˆå·¥å…·å†³ç­–æç¤ºæ¨¡æ¿"""
        return f"""ç”¨æˆ·é—®é¢˜ï¼š{question}

æˆ‘çš„æ€è€ƒè¿‡ç¨‹ï¼š
{reasoning}

å¯ç”¨å·¥å…·ï¼š
{tools_description}

1. ä»”ç»†åˆ†æç”¨æˆ·é—®é¢˜å’Œæ€è€ƒè¿‡ç¨‹ã€‚
2. åˆ¤æ–­æ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·æ¥å›ç­”é—®é¢˜ã€‚
3. å¦‚æœéœ€è¦ä½¿ç”¨å·¥å…·ï¼Œè¯·ä½¿ç”¨æœ€åˆé€‚çš„å·¥å…·å¹¶æä¾›æ‰€æœ‰å¿…è¦çš„å‚æ•°ã€‚
4. å¦‚æœä¸éœ€è¦ä½¿ç”¨å·¥å…·ï¼Œç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"""

    @staticmethod
    def final_answer_prompt(question: str, reasoning: str, tool_results: str = None) -> str:
        """ç”Ÿæˆæœ€ç»ˆå›ç­”æç¤ºæ¨¡æ¿"""
        tool_part = f"\n\nå·¥å…·è°ƒç”¨ç»“æœï¼š\n{tool_results}" if tool_results else ""
        
        return f"""ç”¨æˆ·é—®é¢˜ï¼š{question}

æˆ‘çš„æ€è€ƒè¿‡ç¨‹ï¼š
{reasoning}{tool_part}

è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯ï¼Œç»™å‡ºæ¸…æ™°ã€å‡†ç¡®ã€æœ‰å¸®åŠ©çš„å›ç­”ã€‚ä¸è¦åœ¨å›ç­”ä¸­æåŠä½ çš„æ€è€ƒè¿‡ç¨‹æˆ–å·¥å…·è°ƒç”¨ç»†èŠ‚ï¼Œç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"""
```

```python
# app/deepclaude/utils/streaming.py
"""æµå¼å“åº”å¤„ç†å·¥å…·"""

import json
from typing import Dict, Any

class StreamingHelper:
    """æµå¼å“åº”è¾…åŠ©å·¥å…·"""
    
    @staticmethod
    def format_chunk_response(content: str, role: str = "assistant", chat_id: str = None, 
                             created_time: int = None, model: str = "deepclaude", 
                             is_reasoning: bool = False, finish_reason: str = None) -> str:
        """æ ¼å¼åŒ–æµå¼å“åº”å—"""
        response = {
            "id": chat_id,
            "object": "chat.completion.chunk",
            "created": created_time,
            "model": model,
            "choices": [{
                "index": 0,
                "delta": {
                    "role": role,
                    "content": content
                },
                "finish_reason": finish_reason
            }]
        }
        
        if is_reasoning:
            response["is_reasoning"] = True
            response["choices"][0]["delta"]["reasoning"] = True
            
        return f"data: {json.dumps(response, ensure_ascii=False)}\n\n"
    
    @staticmethod
    def format_done_marker() -> str:
        """ç”Ÿæˆæµå¼å“åº”ç»“æŸæ ‡è®°"""
        return "data: [DONE]\n\n"
```

## å››ã€é‡æ„å…³é”®é”™è¯¯ä¿®å¤ç‚¹æ±‡æ€»

1. **å·¥å…·éªŒè¯ä¸è½¬æ¢**ï¼š
   - ä¿®å¤`_validate_and_convert_tools`ä¸­çš„`KeyError: 'custom'`é”™è¯¯
   - å®ç°ä¸¥æ ¼çš„ç±»å‹æ£€æŸ¥å’Œå®‰å…¨çš„å­—æ®µè®¿é—®
   - å°†å·¥å…·éªŒè¯é€»è¾‘æ‹†åˆ†ä¸ºå•ç‹¬çš„æ¨¡å—ï¼Œæé«˜å¯ç»´æŠ¤æ€§

2. **æµå¼å¤„ç†ä¼˜åŒ–**ï¼š
   - ä½¿ç”¨æ˜ç¡®çš„æ¥å£å®šä¹‰å’Œé”™è¯¯å¤„ç†
   - è§„èŒƒæµå¼å“åº”æ ¼å¼ï¼Œç¡®ä¿ä¸OpenAIå’ŒClaude APIå…¼å®¹
   - ç®€åŒ–æµç¨‹ä»£ç ï¼Œå‡å°‘åµŒå¥—å±‚çº§

3. **æ¨ç†æä¾›è€…æŠ½è±¡**ï¼š
   - ä½¿ç”¨ç­–ç•¥æ¨¡å¼éš”ç¦»ä¸åŒæ¨ç†æœåŠ¡çš„å®ç°ç»†èŠ‚
   - é€šè¿‡å·¥å‚æ–¹æ³•æ ¹æ®é…ç½®åŠ¨æ€é€‰æ‹©å®ç°
   - æ˜ç¡®å®šä¹‰æ¥å£åè®®ï¼Œä¾¿äºæ·»åŠ æ–°çš„æ¨ç†æä¾›è€…

4. **é”™è¯¯æ¢å¤æœºåˆ¶**ï¼š
   - æ·»åŠ åˆç†çš„å›é€€ç­–ç•¥ç¡®ä¿æœåŠ¡å¯ç”¨æ€§
   - åŠ å¼ºæ—¥å¿—è®°å½•ï¼Œä¾¿äºæ’æŸ¥é—®é¢˜
   - ç»Ÿä¸€é”™è¯¯å¤„ç†æµç¨‹ï¼Œæä¾›ç”¨æˆ·å‹å¥½çš„é”™è¯¯ä¿¡æ¯

## äº”ã€é‡æ„å®æ–½æ­¥éª¤

1. åˆ›å»ºæ–°çš„é¡¹ç›®ç»“æ„å’Œç›®å½•
2. å®ç°å„ä¸ªæ¥å£å®šä¹‰å’ŒåŸºç¡€ç±»
3. é€æ­¥å®ç°å„ä¸ªåŠŸèƒ½æ¨¡å—ï¼š
   - å…ˆå®ç°å·¥å…·éªŒè¯å’Œè½¬æ¢æ¨¡å—
   - ç„¶åå®ç°æ¨ç†æä¾›è€…
   - æœ€åå®ç°æ ¸å¿ƒåè°ƒç±»
4. ç¼–å†™å•å…ƒæµ‹è¯•ç¡®ä¿å„ç»„ä»¶æ­£å¸¸å·¥ä½œ
5. é€æ­¥æ›¿æ¢åŸæœ‰å®ç°ï¼Œç¡®ä¿åŠŸèƒ½å¹³æ»‘è¿‡æ¸¡

## å…­ã€é‡æ„å»ºè®®

1. **å½“å³å¯åº”ç”¨çš„ä¿®å¤**ï¼šå…ˆä¿®å¤`_validate_and_convert_tools`æ–¹æ³•ä¸­çš„`KeyError: 'custom'`é”™è¯¯ï¼š

```python
# å°†è¿™è¡Œä»£ç 
if tool["type"] == "custom" and isinstance(tool.get("custom", {}), dict) and "type" in tool["custom"]:

# ä¿®æ”¹ä¸º
custom_field = tool.get("custom", {})
if tool["type"] == "custom" and isinstance(custom_field, dict) and "type" in custom_field:
```

2. **é€æ­¥æ‹†åˆ†æ¨¡å—**ï¼šæŒ‰ç…§é‡æ„æ–¹æ¡ˆé€æ­¥å°†åŠŸèƒ½æ‹†åˆ†åˆ°ç‹¬ç«‹æ¨¡å—ï¼Œæ¯æ¬¡ä¿®æ”¹åç¡®ä¿ç³»ç»Ÿä»èƒ½æ­£å¸¸å·¥ä½œã€‚

3. **å¢å¼ºæµ‹è¯•è¦†ç›–**ï¼šä¸ºæ¯ä¸ªé‡æ„çš„æ¨¡å—æ·»åŠ å•å…ƒæµ‹è¯•ï¼Œç¡®ä¿é‡æ„ä¸å¼•å…¥æ–°é—®é¢˜ã€‚

4. **æ–‡æ¡£æ›´æ–°**ï¼šéšç€é‡æ„è¿›å±•ï¼Œæ›´æ–°é¡¹ç›®æ–‡æ¡£ï¼Œç¡®ä¿å›¢é˜Ÿæˆå‘˜ç†è§£æ–°çš„æ¶æ„å’Œè®¾è®¡æ¨¡å¼ã€‚

é€šè¿‡è¿™æ¬¡é‡æ„ï¼ŒDeepClaudeé¡¹ç›®å°†è·å¾—æ›´å¥½çš„æ¨¡å—åŒ–ç»“æ„ï¼Œæ›´æ¸…æ™°çš„è´£ä»»åˆ†ç¦»ï¼Œä»¥åŠæ›´å¼ºçš„å¯ç»´æŠ¤æ€§å’Œæ‰©å±•æ€§ã€‚åŒæ—¶ï¼Œå…³é”®çš„Bugå°†å¾—åˆ°ä¿®å¤ï¼Œæé«˜ç³»ç»Ÿçš„ç¨³å®šæ€§å’Œå¯é æ€§ã€‚